{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Model\n",
    "2. Test Model\n",
    "3. Print Raw Results i.e generated refactorings\n",
    "4. CodeBLEU Evaluation\n",
    "5. ROGUE1, ROGUE2 and ROGUE-LCS Evaluation\n",
    "6. METEOR Evaluation\n",
    "7. Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python39\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\python39\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\python39\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python39\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\python39\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\python39\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python39\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python39\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python39\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\python39\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\python39\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python39\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.3.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python39\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: datasets in c:\\python39\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\python39\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\python39\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\python39\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python39\\lib\\site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\python39\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\python39\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\python39\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\python39\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\python39\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\python39\\lib\\site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in c:\\python39\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\python39\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python39\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.3.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python39\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "\n",
    "!pip3 install torch\n",
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preparation for Training (Part 1/2)\n",
    "    --> Performing Data Split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation for Training\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your generated dataset\n",
    "# Replace 'your_dataset_path' with the actual path to your dataset\n",
    "dataset_path = os.path.join(\"data\", \"analyzed_dataset_test.jsonl\")\n",
    "\n",
    "# Load data from the JSONL file\n",
    "with open(dataset_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Extract input and target values\n",
    "magic_number_smells = [item['magic_number_smell'] for item in data]\n",
    "refactored_codes = [item['refactored_code'] for item in data]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_magic_number_smells, test_magic_number_smells, train_refactored_codes, test_refactored_codes = train_test_split(\n",
    "    magic_number_smells, refactored_codes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create dictionaries for training and testing datasets\n",
    "train_dataset = [{'magic_number_smell': magic_number_smell, 'refactored_code': refactored_code} for magic_number_smell, refactored_code in zip(train_magic_number_smells, train_refactored_codes)]\n",
    "test_dataset = [{'magic_number_smell': magic_number_smell, 'refactored_code': refactored_code} for magic_number_smell, refactored_code in zip(test_magic_number_smells, test_refactored_codes)]\n",
    "\n",
    "# Save the datasets to JSONL files\n",
    "train_file_path = os.path.join(\"data\", \"train_dataset.jsonl\")\n",
    "test_file_path = os.path.join(\"data\", \"test_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preparation for Training (Part 2/2)\n",
    "    --> Initializing Tokenizer - CodeT5Tokenizer\n",
    "    --> Initializing Optimizer - AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
    "\n",
    "with open(train_file_path, 'w') as f:\n",
    "    for item in train_dataset:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "with open(test_file_path, 'w') as f:\n",
    "    for item in test_dataset:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        magic_number_smell = item['magic_number_smell']\n",
    "        refactored_code = item['refactored_code']\n",
    "\n",
    "        # Tokenize and convert to PyTorch tensors\n",
    "        inputs = self.tokenizer.encode_plus(magic_number_smell, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        targets = self.tokenizer.encode_plus(refactored_code, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': targets['input_ids'].squeeze(),\n",
    "        }\n",
    "\n",
    "# Initialize the T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CodeDataset(train_dataset, tokenizer)\n",
    "test_dataset = CodeDataset(test_dataset, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Define training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Loading onto processor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print Expected Refactored Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Expected Refactored Code\n",
    "print(refactored_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "last_3_test_losses = []  # Track last 5 test losses for early stopping\n",
    "max_overfit_epochs = 3  # Maximum consecutive epochs for which test loss can increase before stopping\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 40\n",
    "stop_training = False  # Flag to indicate if training should stop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_losses = []\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} (Training)'):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_losses.append(loss.item())\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluate the model on the test dataset\n",
    "    model.eval()\n",
    "    epoch_test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} (Testing)'):\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            epoch_test_losses.append(loss.item())\n",
    "\n",
    "    # Calculate average testing loss for the epoch\n",
    "    test_loss = sum(epoch_test_losses) / len(epoch_test_losses)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Print and/or log the training and testing losses for monitoring\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    checkpoint_path = f'magic_smell_model_s_3lines_700_e40_b4_epoch_{epoch + 1}.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # Early stopping condition for same test losses\n",
    "    if len(last_3_test_losses) == 3:\n",
    "        if all(loss == last_3_test_losses[0] for loss in last_3_test_losses):\n",
    "            print(\"Early stopping: Test losses remained the same for 3 epochs.\")\n",
    "            stop_training = True\n",
    "            break\n",
    "        else:\n",
    "            last_3_test_losses.pop(0)\n",
    "    last_3_test_losses.append(test_loss)\n",
    "    \n",
    "    # Early stopping condition for overfitting\n",
    "    if epoch > 0 and test_loss > test_losses[-2]:\n",
    "        overfit_epochs += 1\n",
    "        if overfit_epochs >= max_overfit_epochs:\n",
    "            print(f\"Early stopping: Test loss increased continuously for {max_overfit_epochs} epochs.\")\n",
    "            stop_training = True\n",
    "            break\n",
    "    else:\n",
    "        overfit_epochs = 0\n",
    "\n",
    "\n",
    "    if stop_training:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Can be used this trained model to deploy of the huggingface or use locally\n",
    "    \n",
    "# Save the trained model\n",
    "model.save_pretrained('magic_smell_model_s_3lines_700_e40_b4')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('magic_smell_model_s_3lines_700_e40_b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "all_references = []  # List to store reference sequences\n",
    "all_predictions = []  # List to store predicted sequences\n",
    "all_prediction_ids = []\n",
    "all_prediction_ids_labelled = []\n",
    "all_predictions_decoded = []\n",
    "all_predictions_decoded_labelled = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc='Evaluating on Test Dataset'):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Generate predictions\n",
    "        predicted_ids = model.generate(**inputs, max_length=512)\n",
    "        predicted_code = [tokenizer.decode(ids, skip_special_tokens=True) for ids in predicted_ids]\n",
    "\n",
    "        # Append to reference and prediction lists\n",
    "        all_references.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted_code)\n",
    "\n",
    "        all_prediction_ids.extend(predicted_ids)\n",
    "        all_prediction_ids_labelled.extend(predicted_ids.cpu().numpy())\n",
    "\n",
    "        tokenized_predicted_code = [tokenizer.encode_plus(code, return_tensors='pt', padding='max_length', truncation=True, max_length=512) for code in predicted_code]\n",
    "        all_predictions_decoded.extend(tokenized_predicted_code)\n",
    "        labels_predicted = torch.stack([item['input_ids'].squeeze() for item in tokenized_predicted_code])\n",
    "        # all_predictions_decoded_labelled.extend(labels_predicted.cpu.numpy())\n",
    "        all_predictions_decoded_labelled.extend(labels_predicted.numpy())\n",
    "\n",
    "\n",
    "# Save the results to a text file\n",
    "with open('test_results.txt', 'w') as file:\n",
    "    for reference, prediction in zip(all_references, all_predictions):\n",
    "        file.write(f\"Reference: {reference}\\n\")\n",
    "        file.write(f\"Prediction: {prediction}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.9/57.9 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in c:\\python39\\lib\\site-packages (from sacrebleu) (2022.10.31)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from sacrebleu) (1.24.2)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from sacrebleu) (0.3.9)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-5.2.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\python39\\lib\\site-packages (from portalocker->sacrebleu) (306)\n",
      "Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/106.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 106.6/106.6 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading lxml-5.2.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.4/3.8 MB 7.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/3.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.8 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.8/3.8 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.1/3.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.7/3.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.2/3.8 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, sacrebleu\n",
      "Successfully installed lxml-5.2.0 portalocker-2.8.2 sacrebleu-2.4.1 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeBLEU Evaluation\n",
    "\n",
    "\n",
    "\n",
    "import sacrebleu\n",
    "\n",
    "# Check if the lists are not empty\n",
    "if all_predictions and refactored_codes:\n",
    "    # Convert NumPy arrays to Python lists of strings\n",
    "    references = [str(ref) for ref in refactored_codes]\n",
    "    predictions = [str(pred) for pred in all_predictions]\n",
    "\n",
    "    # Calculate CodeBLEU\n",
    "    codebleu = sacrebleu.corpus_bleu(predictions, [references])\n",
    "    print(f\"CodeBLEU: {codebleu.score}\")\n",
    "    print(refactored_codes)\n",
    "    print(all_predictions)\n",
    "else:\n",
    "    print(\"Error: Empty prediction or reference list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROGUE1, ROGUE2 and ROGUE-LCS Evaluation\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Initialize lists to store individual ROUGE scores\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "# Iterate over refactored_codes and all_predictions\n",
    "for ref_code, pred_code in zip(refactored_codes, all_predictions):\n",
    "    # Calculate ROUGE scores\n",
    "    scores = scorer.score(ref_code, pred_code)\n",
    "    \n",
    "    # Append individual ROUGE scores\n",
    "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "\n",
    "# Calculate mean ROUGE scores\n",
    "mean_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "mean_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "mean_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "\n",
    "# Print mean ROUGE scores\n",
    "print(\"Mean ROUGE-1:\", mean_rouge1)\n",
    "print(\"Mean ROUGE-2:\", mean_rouge2)\n",
    "print(\"Mean ROUGE-L:\", mean_rougeL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METEOR Evaluation\n",
    "\n",
    "import nltk\n",
    "from nltk.translate import meteor_score\n",
    "\n",
    "# Download WordNet data\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Check if the lists are not empty\n",
    "if all_predictions and refactored_codes:\n",
    "    # Convert NumPy arrays to strings\n",
    "    hypothesis_strings = str(str(pred) for pred in all_predictions)\n",
    "\n",
    "    # Preprocess references by converting to strings\n",
    "    references_strings = []\n",
    "    for ref in refactored_codes:\n",
    "        # Convert each tokenized reference to a single string\n",
    "        ref_string = ' '.join([str(token) for token in ref])\n",
    "        references_strings.append(ref_string)\n",
    "\n",
    "    # Calculate METEOR score\n",
    "    meteor_avg_score = meteor_score.meteor_score(references_strings, hypothesis_strings)\n",
    "    print(f\"METEOR: {meteor_avg_score}\")\n",
    "else:\n",
    "    print(\"Error: Empty prediction or reference list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'METEOR']\n",
    "\n",
    "final_scores = [codebleu.score,  mean_rouge1,  mean_rouge2, mean_rougeL, meteor_avg_score]\n",
    "\n",
    "# Plotting final scores\n",
    "plt.bar(metrics, final_scores)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Final Evaluation Metrics')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
