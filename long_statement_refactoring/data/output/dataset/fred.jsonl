{"Smelly Sample":"/*\n * Dijjer - A Peer to Peer HTTP Cache\n * Copyright (C) 2004,2005 Change.Tv, Inc\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n * \n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n */\n\npackage freenet.io.comm;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport freenet.node.PrioRunnable;\nimport freenet.support.Executor;\nimport freenet.support.Logger;\n\n/**\n * @author ian\n *\n * To change the template for this generated type comment go to Window - Preferences - Java - Code Generation - Code and\n * Comments\n */\npublic final class MessageFilter {\n\n\tprivate static volatile boolean logMINOR;\n\n\tstatic {\n\t\tLogger.registerClass(MessageFilter.class);\n\t}\n\n    public static final String VERSION = \"$Id: MessageFilter.java,v 1.7 2005/08/25 17:28:19 amphibian Exp $\";\n\n    private boolean _matched;\n    private PeerContext _droppedConnection;\n    private MessageType _type;\n    private final List<Object> _fields = new ArrayList<Object>();\n    private final List<String> _fieldNames = new ArrayList<String>();\n    private PeerContext _source;\n    private long _timeout;\n    /** If true, timeouts are relative to the start of waiting, if false, they are relative to\n     * the time of calling setTimeout() */\n    private boolean _timeoutFromWait;\n    private long _initialTimeout;\n    private MessageFilter _or;\n    private Message _message;\n    private long _oldBootID;\n    private AsyncMessageFilterCallback _callback;\n    private ByteCounter _ctr;\n    private boolean _setTimeout = false;\n\n    private MessageFilter() {\n        _timeoutFromWait = true;\n    }\n\n    public static MessageFilter create() {\n        return new MessageFilter();\n    }\n\n    void onStartWaiting(boolean waitFor) {\n    \tsynchronized(this) {\n    \t\t/* We cannot wait on a MessageFilter with a callback, because onMatched() calls clearMatched()\n    \t\t * if we have a callback. The solution would be to:\n    \t\t * - Set a flag indicating we are waitFor()ing a filter here.\n    \t\t * - On matching a message (setMessage), call the callback immediately if not waitFor()ing.\n    \t\t * - If we are waitFor()ing, call the callback when we exit waitFor() (onStopWaiting()???).\n    \t\t */\n        \tif(waitFor && _callback != null)\n        \t\tthrow new IllegalStateException(\"Cannot wait on a MessageFilter with a callback!\");\n    \t\tif(!_setTimeout)\n\t\t\tthrow new IllegalStateException(\"No timeout set on filter \" + this + \"; cannot wait.\");\n    \t\tif(_initialTimeout > 0 && _timeoutFromWait)\n    \t\t\t_timeout = System.currentTimeMillis() + _initialTimeout;\n    \t}\n    \tif(_or != null)\n    \t\t_or.onStartWaiting(waitFor);\n    }\n    \n    /**\n     * Set whether the timeout is relative to the creation of the filter, or the start of\n     * waitFor().\n     * @param b If true, the timeout is relative to the time at which setTimeout() was called,\n     * if false, it's relative to the start of waitFor().\n     */\n    public MessageFilter setTimeoutRelativeToCreation(boolean b) {\n    \t_timeoutFromWait = !b;\n    \treturn this;\n    }\n    \n    /**\n     * This filter will expire after the specificed amount of time. Note also that where two or more filters match the\n     * same message, the one with the nearer expiry time will get priority\n     *\n     * @param timeout The time before this filter expires in ms\n     * @return This message filter\n     */\n\tpublic MessageFilter setTimeout(long timeout) {\n\t\t_setTimeout = true;\n\t\t_initialTimeout = timeout;\n\t\t_timeout = System.currentTimeMillis() + timeout;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setNoTimeout() {\n\t\t_setTimeout = true;\n\t\t_timeout = Long.MAX_VALUE;\n\t\t_initialTimeout = 0;\n\t\treturn this;\n\t}\n\t\n\tpublic MessageFilter setType(MessageType type) {\n\t\t_type = type;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setSource(PeerContext source) {\n\t\t_source = source;\n\t\tif(source != null)\n\t\t\t_oldBootID = source.getBootID();\n\t\treturn this;\n\t}\n\t\n\t/**\n\t Returns the source that this filter (or chain) matches\n\t */\n\tpublic PeerContext getSource() {\n\t\treturn _source;\n\t}\n\n\tpublic MessageFilter setField(String fieldName, boolean value) {\n\t\treturn setField(fieldName, Boolean.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, byte value) {\n\t\treturn setField(fieldName, Byte.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, short value) {\n\t\treturn setField(fieldName, Short.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, int value) {\n\t\treturn setField(fieldName, Integer.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, long value) {\n\t\treturn setField(fieldName, Long.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, Object fieldValue) {\n\t\tif ((_type != null) && (!_type.checkType(fieldName, fieldValue))) {\n\t\t\tthrow new IncorrectTypeException(\"Got \" + fieldValue.getClass() + \", expected \" + _type.typeOf(fieldName) + \" for \" + _type.getName());\n\t\t}\n\t\tsynchronized (_fields) {\n\t\t    final int i = _fieldNames.indexOf(fieldName);\n\t\t    if (i >= 0) {\n\t\t        _fields.set(i, fieldValue);\n\t\t    } else {\n\t\t        _fieldNames.add(fieldName);\n\t\t        _fields.add(fieldValue);\n\t\t    }\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Modifies the filter so that it returns true if either it or the filter in the argument returns true.\n\t * Multiple combinations must be nested: such as filter1.or(filter2.or(filter3))).\n\t * filter2 will be checked before filter1, so make sure to add the most common last.\n\t * @return reference to this, the modified filter.\n\t */\n\tpublic MessageFilter or(MessageFilter or) {\n\t\tif((or != null) && (_or != null) && or != _or) {\n\t\t\tthrow new IllegalStateException(\"Setting a second .or() on the same filter will replace the \" +\n\t\t\t    \"existing one, not add another. \" + _or + \" would be replaced by \" + or + \".\");\n\t\t}\n\t\tif(or._initialTimeout != _initialTimeout) {\n\t\t\tLogger.error(this, \"Message filters being or()ed have different timeouts! This is very dangerous! This is \"+this+\" or is \"+or);\n\t\t\t// FIXME throw new IllegalArgumentException()\n\t\t}\n\t\t_or = or;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setAsyncCallback(AsyncMessageFilterCallback cb, ByteCounter ctr) {\n\t\t_callback = cb;\n\t\t_ctr = ctr;\n\t\treturn this;\n\t}\n\t\n\tenum MATCHED {\n\t\tMATCHED,\n\t\tTIMED_OUT,\n\t\tTIMED_OUT_AND_MATCHED,\n\t\tNONE\n\t}\n\t\n\tpublic MATCHED match(Message m, long now) {\n\t\treturn match(m, false, now);\n\t}\n\t\n\tpublic MATCHED match(Message m, boolean noTimeout, long now) {\n\t\tif(_or != null) {\n\t\t\tMATCHED matched = _or.match(m, noTimeout, now);\n\t\t\tif(matched != MATCHED.NONE)\n\t\t\t\treturn matched; // Filter is matched once only. That includes timeouts.\n\t\t}\n\n\t\tfinal MATCHED resultNoMatch = _timeout < now ? MATCHED.TIMED_OUT : MATCHED.NONE;\n\t\tif ((_type != null && !_type.equals(m.getSpec())) ||\n\t\t\t\t(_source != null && !_source.equals(m.getSource()))) {\n\t\t\t// Timeout immediately, but don't check the callback, so we still need the periodic check.\n\t\t\treturn resultNoMatch;\n\t\t}\n\t\tsynchronized (_fields) {\n\t\t\tfor (int i = 0; i < _fieldNames.size(); i++) {\n\t\t\t\tfinal String fieldName = _fieldNames.get(i);\n\t\t\t\tif (!m.isSet(fieldName)) {\n\t\t\t\t\treturn resultNoMatch;\n\t\t\t\t}\n\t\t\t\tfinal Object fieldValue = _fields.get(i);\n\t\t\t\tif (!fieldValue.equals(m.getFromPayload(fieldName))) {\n\t\t\t\t\treturn resultNoMatch;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif((!noTimeout) && reallyTimedOut(now)) {\n\t\t\tif(logMINOR) Logger.minor(this, \"Matched but timed out: \"+this);\n\t\t\treturn MATCHED.TIMED_OUT_AND_MATCHED;\n\t\t}\n\t\treturn MATCHED.MATCHED;\n\t}\n\n\tpublic boolean matched() {\n\t\treturn _matched;\n\t}\n\n\t/**\n\t * Which connection dropped or was restarted?\n\t */\n\tpublic PeerContext droppedConnection() {\n\t    return _droppedConnection;\n\t}\n\t\n\tboolean reallyTimedOut(long time) {\n\t\tif(_callback != null && _callback.shouldTimeout())\n\t\t\t_timeout = -1; // timeout immediately\n\t\treturn _timeout < time;\n\t}\n\t\n\t/**\n\t * @param time The current time in milliseconds.\n\t * @return True if the filter has timed out, or if it has been matched already. Caller will\n\t * remove the filter from _filters if we return true.\n\t */\n\tboolean timedOut(long time) {\n\t\tif(_matched) {\n\t\t\tLogger.error(this, \"Impossible: filter already matched in timedOut(): \"+this, new Exception(\"error\"));\n\t\t\treturn true; // Remove it.\n\t\t}\n\t\treturn reallyTimedOut(time);\n\t}\n\n    public Message getMessage() {\n        return _message;\n    }\n\n    public synchronized void setMessage(Message message) {\n        //Logger.debug(this, \"setMessage(\"+message+\") on \"+this, new Exception(\"debug\"));\n        _message = message;\n        // Avoid race conditions where it is removed from the filter list because of a timeout but not woken up.\n        _matched = true;\n        notifyAll();\n    }\n\n    public long getInitialTimeout() {\n        return _initialTimeout;\n    }\n    \n    public long getTimeout() {\n        return _timeout;\n    }\n\n    @Override\n\tpublic String toString() {\n    \treturn super.toString()+\":\"+_type.getName();\n    }\n\n    public void clearMatched() {\n    \t// If the filter matched in an _or, and it is re-used, then\n    \t// we need to clear all the _or's.\n    \tMessageFilter or;\n    \tsynchronized(this) {\n    \t\t_matched = false;\n    \t\t_message = null;\n    \t\tor = _or;\n    \t}\n    \tif(or != null)\n    \t\tor.clearMatched();\n    }\n\n    public void clearOr() {\n        _or = null;\n    }\n    \n    public boolean matchesDroppedConnection(PeerContext ctx) {\n    \tif(_source == ctx) return true;\n    \tif(_or != null) return _or.matchesDroppedConnection(ctx);\n    \treturn false;\n    }\n    \n    public boolean matchesRestartedConnection(PeerContext ctx) {\n    \tif(_source == ctx) return true;\n    \tif(_or != null) return _or.matchesRestartedConnection(ctx);\n    \treturn false;\n    }\n    \n    /**\n     * Notify because of a dropped connection.\n     * Caller must verify _matchesDroppedConnection and _source.\n     * @param ctx\n     */\n    public void onDroppedConnection(final PeerContext ctx, Executor executor) {\n    \tfinal AsyncMessageFilterCallback cb;\n    \tsynchronized(this) {\n    \t\tcb = _callback;\n    \t\t_droppedConnection = ctx;\n    \t\tnotifyAll();\n    \t\t_ctr = null;\n    \t}\n    \tif(cb != null) {\n    \t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n    \t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onDisconnect(ctx);\n\t\t\t\t\t}\n\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n    \t\t\t});\n    \t\t} else {\n    \t\t\tcb.onDisconnect(ctx);\n    \t\t}\n    \t}\n    }\n\n    /**\n     * Notify because of a restarted connection.\n     * Caller must verify _matchesDroppedConnection and _source.\n     * @param ctx\n     */\n    public void onRestartedConnection(final PeerContext ctx, Executor executor) {\n    \tfinal AsyncMessageFilterCallback cb;\n    \tsynchronized(this) {\n    \t\t_droppedConnection = ctx;\n    \t\tcb = _callback;\n    \t\tnotifyAll();\n    \t\t_ctr = null;\n    \t}\n    \tif(cb != null) {\n    \t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n    \t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onRestarted(ctx);\n\t\t\t\t\t}\n\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n    \t\t\t});\n    \t\t} else {\n    \t\t\tcb.onRestarted(ctx);\n    \t\t}\n    \t}\n    }\n\n    /**\n     * Notify waiters that we have been matched.\n     * Hopefully no locks will be held at this point by the caller.\n     */\n\tpublic void onMatched(Executor executor) {\n\t\tfinal Message msg;\n\t\tfinal AsyncMessageFilterCallback cb;\n\t\tByteCounter ctr;\n\t\tsynchronized(this) {\n\t\t\tmsg = _message;\n\t\t\tcb = _callback;\n\t\t\tctr = _ctr;\n\t\t\t// Clear matched before calling callback in case we are re-added.\n\t\t\tif(_callback != null)\n\t\t\t\tclearMatched();\n\t\t}\n\t\tif(cb != null) {\n\t\t\tif(cb instanceof SlowAsyncMessageFilterCallback)\n\t\t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onMatched(msg);\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t}, \"Slow callback for \"+cb);\n\t\t\telse\n\t\t\t\tcb.onMatched(msg);\n\t\t\tif(ctr != null)\n\t\t\t\tctr.receivedBytes(msg._receivedByteCount);\n\t\t}\n\t}\n\n\t/**\n\t * Notify waiters that we have timed out.\n\t */\n\tpublic void onTimedOut(Executor executor) {\n\t\tfinal AsyncMessageFilterCallback cb;\n\t\tsynchronized(this) {\n\t\t\tnotifyAll();\n\t\t\tcb = _callback;\n\t\t}\n\t\tif(cb != null) {\n\t\t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n\t\t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onTimeout();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t});\n\t\t\t} else\n\t\t\t\tcb.onTimeout();\n\t\t}\n\t}\n\n\t/**\n\t * Returns true if a connection related to this filter has been dropped or restarted.\n\t */\n\tpublic boolean anyConnectionsDropped() {\n\t\tif(_matched) return false;\n\t\tif(_source != null) {\n\t\t\tif(!_source.isConnected()) {\n\t\t\t\treturn true;\n\t\t\t} else if(_source.getBootID() != _oldBootID) {\n\t\t\t\treturn true; // Counts as a disconnect.\n\t\t\t}\n\t\t}\n\t\tif(_or != null)\n\t\t\treturn _or.anyConnectionsDropped();\n\t\treturn false;\n\t}\n\n\tpublic synchronized boolean hasCallback() {\n\t\treturn _callback != null;\n\t}\n}\n","Method after Refactoring":"/*\n * Dijjer - A Peer to Peer HTTP Cache\n * Copyright (C) 2004,2005 Change.Tv, Inc\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n * \n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n */\n\npackage freenet.io.comm;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport freenet.node.PrioRunnable;\nimport freenet.support.Executor;\nimport freenet.support.Logger;\n\n/**\n * @author ian\n *\n * To change the template for this generated type comment go to Window - Preferences - Java - Code Generation - Code and\n * Comments\n */\npublic final class MessageFilter {\n\n\tprivate static volatile boolean logMINOR;\n\n\tstatic {\n\t\tLogger.registerClass(MessageFilter.class);\n\t}\n\n    public static final String VERSION = \"$Id: MessageFilter.java,v 1.7 2005/08/25 17:28:19 amphibian Exp $\";\n\n    private boolean _matched;\n    private PeerContext _droppedConnection;\n    private MessageType _type;\n    private final List<Object> _fields = new ArrayList<Object>();\n    private final List<String> _fieldNames = new ArrayList<String>();\n    private PeerContext _source;\n    private long _timeout;\n    /** If true, timeouts are relative to the start of waiting, if false, they are relative to\n     * the time of calling setTimeout() */\n    private boolean _timeoutFromWait;\n    private long _initialTimeout;\n    private MessageFilter _or;\n    private Message _message;\n    private long _oldBootID;\n    private AsyncMessageFilterCallback _callback;\n    private ByteCounter _ctr;\n    private boolean _setTimeout = false;\n\n    private MessageFilter() {\n        _timeoutFromWait = true;\n    }\n\n    public static MessageFilter create() {\n        return new MessageFilter();\n    }\n\n    void onStartWaiting(boolean waitFor) {\n    \tsynchronized(this) {\n    \t\t/* We cannot wait on a MessageFilter with a callback, because onMatched() calls clearMatched()\n    \t\t * if we have a callback. The solution would be to:\n    \t\t * - Set a flag indicating we are waitFor()ing a filter here.\n    \t\t * - On matching a message (setMessage), call the callback immediately if not waitFor()ing.\n    \t\t * - If we are waitFor()ing, call the callback when we exit waitFor() (onStopWaiting()???).\n    \t\t */\n        \tif(waitFor && _callback != null)\n        \t\tthrow new IllegalStateException(\"Cannot wait on a MessageFilter with a callback!\");\n    \t\tif(!_setTimeout)\n\t\t\tthrow new IllegalStateException(\"No timeout set on filter \" + this + \"; cannot wait.\");\n    \t\tif(_initialTimeout > 0 && _timeoutFromWait)\n    \t\t\t_timeout = System.currentTimeMillis() + _initialTimeout;\n    \t}\n    \tif(_or != null)\n    \t\t_or.onStartWaiting(waitFor);\n    }\n    \n    /**\n     * Set whether the timeout is relative to the creation of the filter, or the start of\n     * waitFor().\n     * @param b If true, the timeout is relative to the time at which setTimeout() was called,\n     * if false, it's relative to the start of waitFor().\n     */\n    public MessageFilter setTimeoutRelativeToCreation(boolean b) {\n    \t_timeoutFromWait = !b;\n    \treturn this;\n    }\n    \n    /**\n     * This filter will expire after the specificed amount of time. Note also that where two or more filters match the\n     * same message, the one with the nearer expiry time will get priority\n     *\n     * @param timeout The time before this filter expires in ms\n     * @return This message filter\n     */\n\tpublic MessageFilter setTimeout(long timeout) {\n\t\t_setTimeout = true;\n\t\t_initialTimeout = timeout;\n\t\t_timeout = System.currentTimeMillis() + timeout;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setNoTimeout() {\n\t\t_setTimeout = true;\n\t\t_timeout = Long.MAX_VALUE;\n\t\t_initialTimeout = 0;\n\t\treturn this;\n\t}\n\t\n\tpublic MessageFilter setType(MessageType type) {\n\t\t_type = type;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setSource(PeerContext source) {\n\t\t_source = source;\n\t\tif(source != null)\n\t\t\t_oldBootID = source.getBootID();\n\t\treturn this;\n\t}\n\t\n\t/**\n\t Returns the source that this filter (or chain) matches\n\t */\n\tpublic PeerContext getSource() {\n\t\treturn _source;\n\t}\n\n\tpublic MessageFilter setField(String fieldName, boolean value) {\n\t\treturn setField(fieldName, Boolean.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, byte value) {\n\t\treturn setField(fieldName, Byte.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, short value) {\n\t\treturn setField(fieldName, Short.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, int value) {\n\t\treturn setField(fieldName, Integer.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, long value) {\n\t\treturn setField(fieldName, Long.valueOf(value));\n\t}\n\n\tpublic MessageFilter setField(String fieldName, Object fieldValue) {\n\t\tif ((_type != null) && (!_type.checkType(fieldName, fieldValue))) {\n\t\t\tthrow new IncorrectTypeException(\"Got \" + fieldValue.getClass() + \", expected \" + _type.typeOf(fieldName) + \" for \" + _type.getName());\n\t\t}\n\t\tsynchronized (_fields) {\n\t\t    final int i = _fieldNames.indexOf(fieldName);\n\t\t    if (i >= 0) {\n\t\t        _fields.set(i, fieldValue);\n\t\t    } else {\n\t\t        _fieldNames.add(fieldName);\n\t\t        _fields.add(fieldValue);\n\t\t    }\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Modifies the filter so that it returns true if either it or the filter in the argument returns true.\n\t * Multiple combinations must be nested: such as filter1.or(filter2.or(filter3))).\n\t * filter2 will be checked before filter1, so make sure to add the most common last.\n\t * @return reference to this, the modified filter.\n\t */\n\tpublic MessageFilter or(MessageFilter or) {\n\t\tif((or != null) && (_or != null) && or != _or) {\n\t\t\tthrow new IllegalStateException(\"Setting a second .or() on the same filter will replace the \" +\n\t\t\t    \"existing one, not add another. \" + _or + \" would be replaced by \" + or + \".\");\n\t\t}\n\t\tif(or._initialTimeout != _initialTimeout) {\n\t\t\tLogger.error(this, \"Message filters being or()ed have different timeouts! This is very dangerous! This is \"+this+\" or is \"+or);\n\t\t\t// FIXME throw new IllegalArgumentException()\n\t\t}\n\t\t_or = or;\n\t\treturn this;\n\t}\n\n\tpublic MessageFilter setAsyncCallback(AsyncMessageFilterCallback cb, ByteCounter ctr) {\n\t\t_callback = cb;\n\t\t_ctr = ctr;\n\t\treturn this;\n\t}\n\t\n\tenum MATCHED {\n\t\tMATCHED,\n\t\tTIMED_OUT,\n\t\tTIMED_OUT_AND_MATCHED,\n\t\tNONE\n\t}\n\t\n\tpublic MATCHED match(Message m, long now) {\n\t\treturn match(m, false, now);\n\t}\n\t\n\tpublic MATCHED match(Message m, boolean noTimeout, long now) {\n\t\tif(_or != null) {\n\t\t\tMATCHED matched = _or.match(m, noTimeout, now);\n\t\t\tif(matched != MATCHED.NONE)\n\t\t\t\treturn matched; // Filter is matched once only. That includes timeouts.\n\t\t}\n\n\t\tfinal MATCHED resultNoMatch = _timeout < now ? MATCHED.TIMED_OUT : MATCHED.NONE;\n\t\tif ((_type != null && !_type.equals(m.getSpec())) ||\n\t\t\t\t(_source != null && !_source.equals(m.getSource()))) {\n\t\t\t// Timeout immediately, but don't check the callback, so we still need the periodic check.\n\t\t\treturn resultNoMatch;\n\t\t}\n\t\tsynchronized (_fields) {\n\t\t\tfor (int i = 0; i < _fieldNames.size(); i++) {\n\t\t\t\tfinal String fieldName = _fieldNames.get(i);\n\t\t\t\tif (!m.isSet(fieldName)) {\n\t\t\t\t\treturn resultNoMatch;\n\t\t\t\t}\n\t\t\t\tfinal Object fieldValue = _fields.get(i);\n\t\t\t\tfinal Object messageValue = m.getFromPayload(fieldName);\n\t\t\t\t// check the cheaper hashCode before the full equals, because this is one of the\n\t\t\t\t// most frequently called methods. Reduces the CPU time by about 25%.\n\t\t\t\tif (fieldValue.hashCode() != messageValue.hashCode() || !fieldValue.equals(messageValue)) {\n\t\t\t\t\treturn resultNoMatch;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif((!noTimeout) && reallyTimedOut(now)) {\n\t\t\tif(logMINOR) Logger.minor(this, \"Matched but timed out: \"+this);\n\t\t\treturn MATCHED.TIMED_OUT_AND_MATCHED;\n\t\t}\n\t\treturn MATCHED.MATCHED;\n\t}\n\n\tpublic boolean matched() {\n\t\treturn _matched;\n\t}\n\n\t/**\n\t * Which connection dropped or was restarted?\n\t */\n\tpublic PeerContext droppedConnection() {\n\t    return _droppedConnection;\n\t}\n\t\n\tboolean reallyTimedOut(long time) {\n\t\tif(_callback != null && _callback.shouldTimeout())\n\t\t\t_timeout = -1; // timeout immediately\n\t\treturn _timeout < time;\n\t}\n\t\n\t/**\n\t * @param time The current time in milliseconds.\n\t * @return True if the filter has timed out, or if it has been matched already. Caller will\n\t * remove the filter from _filters if we return true.\n\t */\n\tboolean timedOut(long time) {\n\t\tif(_matched) {\n\t\t\tLogger.error(this, \"Impossible: filter already matched in timedOut(): \"+this, new Exception(\"error\"));\n\t\t\treturn true; // Remove it.\n\t\t}\n\t\treturn reallyTimedOut(time);\n\t}\n\n    public Message getMessage() {\n        return _message;\n    }\n\n    public synchronized void setMessage(Message message) {\n        //Logger.debug(this, \"setMessage(\"+message+\") on \"+this, new Exception(\"debug\"));\n        _message = message;\n        // Avoid race conditions where it is removed from the filter list because of a timeout but not woken up.\n        _matched = true;\n        notifyAll();\n    }\n\n    public long getInitialTimeout() {\n        return _initialTimeout;\n    }\n    \n    public long getTimeout() {\n        return _timeout;\n    }\n\n    @Override\n\tpublic String toString() {\n    \treturn super.toString()+\":\"+_type.getName();\n    }\n\n    public void clearMatched() {\n    \t// If the filter matched in an _or, and it is re-used, then\n    \t// we need to clear all the _or's.\n    \tMessageFilter or;\n    \tsynchronized(this) {\n    \t\t_matched = false;\n    \t\t_message = null;\n    \t\tor = _or;\n    \t}\n    \tif(or != null)\n    \t\tor.clearMatched();\n    }\n\n    public void clearOr() {\n        _or = null;\n    }\n    \n    public boolean matchesDroppedConnection(PeerContext ctx) {\n    \tif(_source == ctx) return true;\n    \tif(_or != null) return _or.matchesDroppedConnection(ctx);\n    \treturn false;\n    }\n    \n    public boolean matchesRestartedConnection(PeerContext ctx) {\n    \tif(_source == ctx) return true;\n    \tif(_or != null) return _or.matchesRestartedConnection(ctx);\n    \treturn false;\n    }\n    \n    /**\n     * Notify because of a dropped connection.\n     * Caller must verify _matchesDroppedConnection and _source.\n     * @param ctx\n     */\n    public void onDroppedConnection(final PeerContext ctx, Executor executor) {\n    \tfinal AsyncMessageFilterCallback cb;\n    \tsynchronized(this) {\n    \t\tcb = _callback;\n    \t\t_droppedConnection = ctx;\n    \t\tnotifyAll();\n    \t\t_ctr = null;\n    \t}\n    \tif(cb != null) {\n    \t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n    \t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onDisconnect(ctx);\n\t\t\t\t\t}\n\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n    \t\t\t});\n    \t\t} else {\n    \t\t\tcb.onDisconnect(ctx);\n    \t\t}\n    \t}\n    }\n\n    /**\n     * Notify because of a restarted connection.\n     * Caller must verify _matchesDroppedConnection and _source.\n     * @param ctx\n     */\n    public void onRestartedConnection(final PeerContext ctx, Executor executor) {\n    \tfinal AsyncMessageFilterCallback cb;\n    \tsynchronized(this) {\n    \t\t_droppedConnection = ctx;\n    \t\tcb = _callback;\n    \t\tnotifyAll();\n    \t\t_ctr = null;\n    \t}\n    \tif(cb != null) {\n    \t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n    \t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onRestarted(ctx);\n\t\t\t\t\t}\n\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n    \t\t\t});\n    \t\t} else {\n    \t\t\tcb.onRestarted(ctx);\n    \t\t}\n    \t}\n    }\n\n    /**\n     * Notify waiters that we have been matched.\n     * Hopefully no locks will be held at this point by the caller.\n     */\n\tpublic void onMatched(Executor executor) {\n\t\tfinal Message msg;\n\t\tfinal AsyncMessageFilterCallback cb;\n\t\tByteCounter ctr;\n\t\tsynchronized(this) {\n\t\t\tmsg = _message;\n\t\t\tcb = _callback;\n\t\t\tctr = _ctr;\n\t\t\t// Clear matched before calling callback in case we are re-added.\n\t\t\tif(_callback != null)\n\t\t\t\tclearMatched();\n\t\t}\n\t\tif(cb != null) {\n\t\t\tif(cb instanceof SlowAsyncMessageFilterCallback)\n\t\t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onMatched(msg);\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t}, \"Slow callback for \"+cb);\n\t\t\telse\n\t\t\t\tcb.onMatched(msg);\n\t\t\tif(ctr != null)\n\t\t\t\tctr.receivedBytes(msg._receivedByteCount);\n\t\t}\n\t}\n\n\t/**\n\t * Notify waiters that we have timed out.\n\t */\n\tpublic void onTimedOut(Executor executor) {\n\t\tfinal AsyncMessageFilterCallback cb;\n\t\tsynchronized(this) {\n\t\t\tnotifyAll();\n\t\t\tcb = _callback;\n\t\t}\n\t\tif(cb != null) {\n\t\t\tif(cb instanceof SlowAsyncMessageFilterCallback) {\n\t\t\t\texecutor.execute(new PrioRunnable() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tcb.onTimeout();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic int getPriority() {\n\t\t\t\t\t\treturn ((SlowAsyncMessageFilterCallback)cb).getPriority();\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t});\n\t\t\t} else\n\t\t\t\tcb.onTimeout();\n\t\t}\n\t}\n\n\t/**\n\t * Returns true if a connection related to this filter has been dropped or restarted.\n\t */\n\tpublic boolean anyConnectionsDropped() {\n\t\tif(_matched) return false;\n\t\tif(_source != null) {\n\t\t\tif(!_source.isConnected()) {\n\t\t\t\treturn true;\n\t\t\t} else if(_source.getBootID() != _oldBootID) {\n\t\t\t\treturn true; // Counts as a disconnect.\n\t\t\t}\n\t\t}\n\t\tif(_or != null)\n\t\t\treturn _or.anyConnectionsDropped();\n\t\treturn false;\n\t}\n\n\tpublic synchronized boolean hasCallback() {\n\t\treturn _callback != null;\n\t}\n}\n","lineNo":233}
{"Smelly Sample":"package freenet.client.async;\n\nimport java.io.DataInputStream;\nimport java.io.DataOutputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.Serializable;\nimport java.util.List;\n\nimport freenet.client.ClientMetadata;\nimport freenet.client.FetchContext;\nimport freenet.client.FetchException;\nimport freenet.client.FetchException.FetchExceptionMode;\nimport freenet.client.InsertContext.CompatibilityMode;\nimport freenet.client.Metadata;\nimport freenet.client.MetadataParseException;\nimport freenet.crypt.CRCChecksumChecker;\nimport freenet.crypt.ChecksumChecker;\nimport freenet.crypt.ChecksumFailedException;\nimport freenet.keys.ClientCHKBlock;\nimport freenet.keys.FreenetURI;\nimport freenet.node.BaseSendableGet;\nimport freenet.support.Logger;\nimport freenet.support.api.LockableRandomAccessBuffer;\nimport freenet.support.compress.Compressor.COMPRESSOR_TYPE;\nimport freenet.support.io.BucketTools;\nimport freenet.support.io.FileUtil;\nimport freenet.support.io.InsufficientDiskSpaceException;\nimport freenet.support.io.PooledFileRandomAccessBuffer;\nimport freenet.support.io.ResumeFailedException;\nimport freenet.support.io.StorageFormatException;\n\n/** Splitfile fetcher based on keeping as much state as possible, and in particular the downloaded blocks,\n * in a single file.\n * \n * The main goals here are:\n * 1) Minimising disk seeks. E.g. in the older versions we abstracted out block storage, this \n * caused a lot of unnecessary seeking and copying. It's better to keep the downloaded data close \n * together on disk. \n * 2) Robustness. This should be robust even against moderate levels of on-disk data corruption. \n * And it's separate for each splitfile. And it has fixed disk usage, until it completes. Some of \n * this robustness violates layering e.g. checking blocks against the CHKs they are supposed to \n * represent. This actually simplifies matters e.g. when decoding a segment, and allows us to not \n * only recover from almost any error (at least in the parts that change, which are most likely to \n * be corrupted), but also to do so efficiently.\n * \n * The SplitFileFetcher*Storage classes manage storing the data and FEC decoding. This class deals \n * with everything else: The interface to the rest of the client layer, selection of keys to fetch, \n * listening for blocks, etc.\n * \n * PERSISTENCE ROADMAP:\n * Now: Currently this class does not support persistence.\n * \n * Near future goal: Support persistence within the database. Stay in memory, do not deactivate.\n * Store this class in the database but not its *Storage classes. Load the SplitFileFetcherStorage \n * on loading Freenet, resuming existing downloads.\n * => Significant improvement in reliability and disk I/O. In principle we could resume downloads\n * separately from the database e.g. if it breaks. Too complicated in practice because of other\n * data structures.\n * - Require: Add \"persistence\", hashCode, force no deactivation, activate where necessary (when\n * dealing with other stuff). Fill in context and load storage when activated on startup.\n * \n * Longer term goal: Implement similar code for inserts. Eliminate db4o and persist everything that\n * remains with simple checkpointed serialisation.\n * \n * LOCKING: (this) should be taken last, because it is used by e.g. SplitFileFetcherGet.isCancelled().\n * \n * @author toad\n */\npublic class SplitFileFetcher implements ClientGetState, SplitFileFetcherStorageCallback, Serializable {\n    \n    private static final long serialVersionUID = 1L;\n    private static volatile boolean logMINOR;\n    static {\n        Logger.registerClass(SplitFileFetcher.class);\n    }\n\n    /** Stores the progress of the download, including the actual data, in a separate file. \n     * Created in onResume() or in the constructor, so must be volatile. */\n    private transient volatile SplitFileFetcherStorage storage;\n    /** Kept here so we can resume from storage */\n    private LockableRandomAccessBuffer raf;\n    final ClientRequester parent;\n    final GetCompletionCallback cb;\n    /** If non-null, we will complete via truncation. */\n    final FileGetCompletionCallback callbackCompleteViaTruncation;\n    /** If non-null, this is the temporary file we have allocated for completion via truncation.\n     * The download will be stored in this file until it is complete, at which point the storage\n     * will truncate it and we will feed it to the callback. */\n    final File fileCompleteViaTruncation;\n    final boolean realTimeFlag;\n    final FetchContext blockFetchContext;\n    final long token;\n    /** Storage doesn't have a ClientContext so we need one here. */\n    private transient ClientContext context;\n    /** Does the actual requests. \n     * Created in onResume() or in the constructor, so must be volatile. */\n    private transient volatile SplitFileFetcherGet getter;\n    private boolean failed;\n    private boolean succeeded;\n    private final boolean wantBinaryBlob;\n    private final boolean persistent;\n    \n    public SplitFileFetcher(Metadata metadata, GetCompletionCallback rcb, ClientRequester parent,\n            FetchContext fetchContext, boolean realTimeFlag, List<COMPRESSOR_TYPE> decompressors, \n            ClientMetadata clientMetadata, long token, boolean topDontCompress, \n            short topCompatibilityMode, boolean persistent, FreenetURI thisKey, boolean isFinalFetch,\n            ClientContext context) \n            throws FetchException, MetadataParseException {\n        this.persistent = persistent;\n        this.cb = rcb;\n        this.parent = parent;\n        this.realTimeFlag = realTimeFlag;\n        this.token = token;\n        this.context = context;\n        if(parent instanceof ClientGetter) {\n            wantBinaryBlob = ((ClientGetter)parent).collectingBinaryBlob();\n        } else {\n            wantBinaryBlob = false;\n        }\n        blockFetchContext = new FetchContext(fetchContext, FetchContext.SPLITFILE_DEFAULT_BLOCK_MASK, true, null);\n        if(parent.isCancelled())\n            throw new FetchException(FetchExceptionMode.CANCELLED);\n        \n        try {\n            // Completion via truncation.\n            if(isFinalFetch && cb instanceof FileGetCompletionCallback && \n                    (decompressors == null || decompressors.size() == 0) &&\n                    !fetchContext.filterData) {\n                FileGetCompletionCallback fileCallback = ((FileGetCompletionCallback)cb);\n                File targetFile = fileCallback.getCompletionFile();\n                if(targetFile != null) {\n                    callbackCompleteViaTruncation = fileCallback;\n                    fileCompleteViaTruncation = FileUtil.createTempFile(targetFile.getName(), \".freenet-tmp\", targetFile.getParentFile());\n                    // Storage must actually create the RAF since it knows the length.\n                } else {\n                    callbackCompleteViaTruncation = null;\n                    fileCompleteViaTruncation = null;\n                }\n            } else {\n                callbackCompleteViaTruncation = null;\n                fileCompleteViaTruncation = null;\n            }\n            // Construct the storage.\n            ChecksumChecker checker = new CRCChecksumChecker();\n            storage = new SplitFileFetcherStorage(metadata, this, decompressors, clientMetadata, \n                    topDontCompress, topCompatibilityMode, fetchContext, realTimeFlag, getSalter(),\n                    thisKey, parent.getURI(), isFinalFetch, parent.getClientDetail(checker), \n                    context.random, context.tempBucketFactory, \n                    persistent ? context.persistentRAFFactory : context.tempRAFFactory, \n                    persistent ? context.jobRunner : context.dummyJobRunner, \n                    context.ticker, context.memoryLimitedJobRunner, checker, persistent,\n                    fileCompleteViaTruncation, context.getFileRandomAccessBufferFactory(persistent), \n                    context.getChkFetchScheduler(realTimeFlag).fetchingKeys());\n        } catch (InsufficientDiskSpaceException e) {\n            throw new FetchException(FetchExceptionMode.NOT_ENOUGH_DISK_SPACE);\n        } catch (IOException e) {\n            Logger.error(this, \"Failed to start splitfile fetcher because of disk I/O error?: \"+e, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        }\n        long eventualLength = Math.max(storage.decompressedLength, metadata.uncompressedDataLength());\n        cb.onExpectedSize(eventualLength, context);\n        if(metadata.uncompressedDataLength() > 0)\n            cb.onFinalizedMetadata();\n        if(eventualLength > 0 && fetchContext.maxOutputLength > 0 && eventualLength > fetchContext.maxOutputLength)\n            throw new FetchException(FetchExceptionMode.TOO_BIG, eventualLength, true, clientMetadata.getMIMEType());\n        getter = new SplitFileFetcherGet(this, storage);\n        raf = storage.getRAF();\n        if(logMINOR)\n            Logger.minor(this, \"Created \"+(persistent?\"persistent\" : \"transient\")+\" download for \"+\n                    thisKey+\" on \"+raf+\" for \"+this);\n        lastNotifiedStoreFetch = System.currentTimeMillis();\n    }\n    \n    protected SplitFileFetcher() {\n        // For serialization.\n        parent = null;\n        cb = null;\n        realTimeFlag = false;\n        blockFetchContext = null;\n        token = 0;\n        wantBinaryBlob = false;\n        persistent = true;\n        callbackCompleteViaTruncation = null;\n        fileCompleteViaTruncation = null;\n    }\n\n    @Override\n    public void schedule(ClientContext context) {\n        if(storage.start(false))\n            getter.schedule(context, false);\n    }\n    \n    /** Fail the whole splitfile request when we get an IOException on writing to or reading from \n     * the on-disk storage. Can be called asynchronously by SplitFileFetcher*Storage if an \n     * off-thread job (e.g. FEC decoding) breaks, or may be called when SplitFileFetcher*Storage\n     * throws.\n     * @param e The IOException, generated when accessing the on-disk storage.\n     */\n    @Override\n    public void failOnDiskError(IOException e) {\n        fail(new FetchException(FetchExceptionMode.BUCKET_ERROR));\n    }\n    \n    /** Fail the whole splitfile request when we get unrecoverable data corruption, e.g. can't \n     * read the keys. FIXME ROBUSTNESS in some cases this could actually be recovered by \n     * restarting from the metadata or the original URI. */\n    @Override\n    public void failOnDiskError(ChecksumFailedException e) {\n        fail(new FetchException(FetchExceptionMode.BUCKET_ERROR));\n    }\n    \n    public void fail(FetchException e) {\n        synchronized(this) {\n            if(succeeded || failed) return;\n            failed = true;\n        }\n        if(storage != null)\n            context.getChkFetchScheduler(realTimeFlag).removePendingKeys(storage.keyListener, true);\n        if(getter != null)\n            getter.cancel(context);\n        if(storage != null)\n            storage.cancel();\n        cb.onFailure(e, this, context);\n    }\n\n    @Override\n    public void cancel(ClientContext context) {\n        fail(new FetchException(FetchExceptionMode.CANCELLED));\n    }\n\n    @Override\n    public long getToken() {\n        return token;\n    }\n\n    /** The splitfile download succeeded. Generate a stream and send it to the \n     * GetCompletionCallback. See bug #6063 for a better way that probably is too much complexity\n     * for the benefit. */\n    @Override\n    public void onSuccess() {\n        boolean fail = false;\n        synchronized(this) {\n            if(failed) {\n                fail = true;\n            } else {\n                if(succeeded) {\n                    Logger.error(this, \"Called onSuccess() twice on \"+this, new Exception(\"debug\"));\n                    return;\n                } else {\n                    if(logMINOR) Logger.minor(this, \"onSuccess() on \"+this, new Exception(\"debug\"));\n                }\n                succeeded = true;\n            }\n        }\n        if(fail) {\n            storage.finishedFetcher();\n            return;\n        }\n        context.getChkFetchScheduler(realTimeFlag).removePendingKeys(storage.keyListener, true);\n        getter.cancel(context);\n        if(this.callbackCompleteViaTruncation != null) {\n            long finalLength = storage.finalLength;\n            this.callbackCompleteViaTruncation.onSuccess(fileCompleteViaTruncation, \n                    finalLength, storage.clientMetadata, this, context);\n            // Don't need to call storage.finishedFetcher().\n        } else {\n            cb.onSuccess(storage.streamGenerator(), storage.clientMetadata, storage.decompressors, \n                    this, context);\n            storage.finishedFetcher();\n        }\n    }\n    \n    @Override\n    public void onClosed() {\n        // Don't need to do anything.\n    }\n\n    public short getPriorityClass() {\n        return this.parent.getPriorityClass();\n    }\n\n    @Override\n    public void setSplitfileBlocks(int requiredBlocks, int remainingBlocks) {\n        parent.addMustSucceedBlocks(requiredBlocks);\n        parent.addBlocks(remainingBlocks);\n        parent.notifyClients(context);\n    }\n\n    @Override\n    public void onSplitfileCompatibilityMode(CompatibilityMode min, CompatibilityMode max,\n            byte[] customSplitfileKey, boolean compressed, boolean bottomLayer,\n            boolean definitiveAnyway) {\n        cb.onSplitfileCompatibilityMode(min, max, customSplitfileKey, compressed, bottomLayer, definitiveAnyway, context);\n    }\n\n    @Override\n    public void queueHeal(byte[] data, byte[] cryptoKey, byte cryptoAlgorithm) {\n        try {\n            context.healingQueue.queue(BucketTools.makeImmutableBucket(context.tempBucketFactory, data), cryptoKey, cryptoAlgorithm, context);\n        } catch (IOException e) {\n            // Nothing to be done, but need to log the error.\n            Logger.error(this, \"I/O error, failed to queue healing block: \"+e, e);\n        }\n    }\n\n    public boolean localRequestOnly() {\n        return blockFetchContext.localRequestOnly;\n    }\n\n    public void toNetwork() {\n        parent.toNetwork(context);\n    }\n\n    public boolean hasFinished() {\n        return failed || succeeded;\n    }\n    \n    /** Incremented whenever we fetch a block from the store */\n    private int storeFetchCounter;\n    /** Time when we last passed through a block fetch from the store */\n    private long lastNotifiedStoreFetch;\n    static final int STORE_NOTIFY_BLOCKS = 100;\n    static final long STORE_NOTIFY_INTERVAL = 200;\n\n    @Override\n    public void onFetchedBlock() {\n        boolean dontNotify = true;\n        if(getter.hasQueued()) {\n            dontNotify = false;\n        } else {\n            synchronized(this) {\n                if(storeFetchCounter++ == STORE_NOTIFY_BLOCKS) {\n                    storeFetchCounter = 0;\n                    dontNotify = false;\n                    lastNotifiedStoreFetch = System.currentTimeMillis();\n                } else {\n                    long now = System.currentTimeMillis();\n                    if(now - lastNotifiedStoreFetch >= STORE_NOTIFY_INTERVAL) {\n                        dontNotify = false;\n                        lastNotifiedStoreFetch = now;\n                    }\n                }\n            }\n        }\n        parent.completedBlock(dontNotify, context);\n    }\n\n    @Override\n    public void onFailedBlock() {\n        parent.failedBlock(context);\n    }\n    \n    @Override\n    public void onResume(int succeededBlocks, int failedBlocks, ClientMetadata meta, long finalSize) {\n        for(int i=0;i<succeededBlocks-1;i++)\n            parent.completedBlock(true, context);\n        if(succeededBlocks > 0)\n            parent.completedBlock(false, context);\n        for(int i=0;i<failedBlocks-1;i++)\n            parent.failedBlock(true, context);\n        if(failedBlocks > 0)\n            parent.failedBlock(false, context);\n        parent.blockSetFinalized(context);\n        try {\n            cb.onExpectedMIME(meta, context);\n        } catch (FetchException e) {\n            fail(e);\n            return;\n        }\n        cb.onExpectedSize(finalSize, context);\n    }\n\n    @Override\n    public void maybeAddToBinaryBlob(ClientCHKBlock block) {\n        if(parent instanceof ClientGetter) {\n            ((ClientGetter)parent).addKeyToBinaryBlob(block, context);\n        }\n    }\n\n    @Override\n    public boolean wantBinaryBlob() {\n        return wantBinaryBlob;\n    }\n\n    @Override\n    public BaseSendableGet getSendableGet() {\n        return getter;\n    }\n\n    @Override\n    public void restartedAfterDataCorruption() {\n        if(hasFinished()) return;\n        Logger.error(this, \"Restarting download \"+this+\" after data corruption\");\n        // We need to fetch more blocks. Some of them may even be in the datastore.\n        getter.unregister(context, getPriorityClass());\n        getter.schedule(context, false);\n        context.jobRunner.setCheckpointASAP();\n    }\n\n    @Override\n    public void clearCooldown() {\n        if(hasFinished()) return;\n        getter.clearWakeupTime(context);\n    }\n\n    @Override\n    public void reduceCooldown(long wakeupTime) {\n        getter.reduceWakeupTime(wakeupTime, context);\n    }\n\n    @Override\n    public HasKeyListener getHasKeyListener() {\n        return getter;\n    }\n\n    @Override\n    public void onResume(ClientContext context) throws FetchException {\n        if(logMINOR) Logger.minor(this, \"Restarting SplitFileFetcher from storage...\");\n        boolean resumed = parent instanceof ClientGetter && ((ClientGetter)parent).resumedFetcher();\n        this.context = context;\n        try {\n            KeySalter salter = getSalter();\n            raf.onResume(context);\n            this.storage = new SplitFileFetcherStorage(raf, realTimeFlag, this, blockFetchContext, \n                    context.random, context.jobRunner, \n                    context.getChkFetchScheduler(realTimeFlag).fetchingKeys(), context.ticker, \n                    context.memoryLimitedJobRunner, new CRCChecksumChecker(), \n                    context.jobRunner.newSalt(), salter, resumed, \n                    callbackCompleteViaTruncation != null);\n        } catch (ResumeFailedException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume storage file: \"+e+\" for \"+raf, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        } catch (IOException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume due to I/O error: \"+e+\" raf = \"+raf, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        } catch (StorageFormatException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume due to storage error: \"+e+\" raf = \"+raf, e);\n            throw new FetchException(FetchExceptionMode.INTERNAL_ERROR, \"Resume failed: \"+e, e);\n        } catch (FetchException e) {\n            raf.free();\n            throw e;\n        }\n        synchronized(this) {\n            lastNotifiedStoreFetch = System.currentTimeMillis();\n        }\n        getter = new SplitFileFetcherGet(this, storage);\n        if (storage.start(resumed)) {\n            getter.schedule(context, storage.hasCheckedStore());\n        }\n    }\n\n    @Override\n    public KeySalter getSalter() {\n        return context.getChkFetchScheduler(realTimeFlag).getGlobalKeySalter(persistent);\n    }\n\n    public boolean writeTrivialProgress(DataOutputStream dos) throws IOException {\n        boolean done = false;\n        synchronized(this) {\n            done = failed || succeeded;\n        }\n        if(done) {\n            dos.writeBoolean(false);\n            return false;\n        }\n        dos.writeBoolean(true);\n        if(callbackCompleteViaTruncation == null) {\n            dos.writeBoolean(false);\n            raf.storeTo(dos);\n        } else {\n            dos.writeBoolean(true);\n            dos.writeUTF(fileCompleteViaTruncation.toString());\n            dos.writeLong(raf.size());\n        }\n        dos.writeLong(token);\n        return true;\n    }\n    \n    public SplitFileFetcher(ClientGetter getter, DataInputStream dis, ClientContext context) \n    throws StorageFormatException, ResumeFailedException, IOException {\n        Logger.normal(this, \"Resuming splitfile download for \"+this);\n        boolean completeViaTruncation = dis.readBoolean();\n        if(completeViaTruncation) {\n            fileCompleteViaTruncation = new File(dis.readUTF());\n            if(!fileCompleteViaTruncation.exists())\n                throw new ResumeFailedException(\"Storage file does not exist: \"+fileCompleteViaTruncation);\n            callbackCompleteViaTruncation = (FileGetCompletionCallback) getter;\n            long rafSize = dis.readLong();\n            if(fileCompleteViaTruncation.length() != rafSize)\n                throw new ResumeFailedException(\"Storage file is not of the correct length\");\n            // FIXME check against finalLength too, maybe we can finish straight away.\n            this.raf = new PooledFileRandomAccessBuffer(fileCompleteViaTruncation, false, rafSize, null, -1, true);\n        } else {\n            this.raf = BucketTools.restoreRAFFrom(dis, context.persistentFG, context.persistentFileTracker, context.getPersistentMasterSecret());\n            fileCompleteViaTruncation = null;\n            callbackCompleteViaTruncation = null;\n        }\n        this.parent = getter;\n        this.cb = getter;\n        this.persistent = true;\n        this.realTimeFlag = parent.realTimeFlag();\n        token = dis.readLong();\n        this.blockFetchContext = getter.ctx;\n        this.wantBinaryBlob = getter.collectingBinaryBlob();\n        // onResume() will do the rest.\n        Logger.normal(this, \"Resumed splitfile download for \"+this);\n        lastNotifiedStoreFetch = System.currentTimeMillis();\n    }\n\n    @Override\n    public void onShutdown(ClientContext context) {\n        storage.onShutdown(context);\n    }\n\n}\n","Method after Refactoring":"package freenet.client.async;\n\nimport java.io.DataInputStream;\nimport java.io.DataOutputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.Serializable;\nimport java.util.List;\n\nimport freenet.client.ClientMetadata;\nimport freenet.client.FetchContext;\nimport freenet.client.FetchException;\nimport freenet.client.FetchException.FetchExceptionMode;\nimport freenet.client.InsertContext.CompatibilityMode;\nimport freenet.client.Metadata;\nimport freenet.client.MetadataParseException;\nimport freenet.crypt.CRCChecksumChecker;\nimport freenet.crypt.ChecksumChecker;\nimport freenet.crypt.ChecksumFailedException;\nimport freenet.keys.ClientCHKBlock;\nimport freenet.keys.FreenetURI;\nimport freenet.node.BaseSendableGet;\nimport freenet.support.Logger;\nimport freenet.support.api.LockableRandomAccessBuffer;\nimport freenet.support.api.RandomAccessBucket;\nimport freenet.support.compress.Compressor.COMPRESSOR_TYPE;\nimport freenet.support.io.BucketTools;\nimport freenet.support.io.FileUtil;\nimport freenet.support.io.InsufficientDiskSpaceException;\nimport freenet.support.io.PooledFileRandomAccessBuffer;\nimport freenet.support.io.ResumeFailedException;\nimport freenet.support.io.StorageFormatException;\n\n/** Splitfile fetcher based on keeping as much state as possible, and in particular the downloaded blocks,\n * in a single file.\n * \n * The main goals here are:\n * 1) Minimising disk seeks. E.g. in the older versions we abstracted out block storage, this \n * caused a lot of unnecessary seeking and copying. It's better to keep the downloaded data close \n * together on disk. \n * 2) Robustness. This should be robust even against moderate levels of on-disk data corruption. \n * And it's separate for each splitfile. And it has fixed disk usage, until it completes. Some of \n * this robustness violates layering e.g. checking blocks against the CHKs they are supposed to \n * represent. This actually simplifies matters e.g. when decoding a segment, and allows us to not \n * only recover from almost any error (at least in the parts that change, which are most likely to \n * be corrupted), but also to do so efficiently.\n * \n * The SplitFileFetcher*Storage classes manage storing the data and FEC decoding. This class deals \n * with everything else: The interface to the rest of the client layer, selection of keys to fetch, \n * listening for blocks, etc.\n * \n * PERSISTENCE ROADMAP:\n * Now: Currently this class does not support persistence.\n * \n * Near future goal: Support persistence within the database. Stay in memory, do not deactivate.\n * Store this class in the database but not its *Storage classes. Load the SplitFileFetcherStorage \n * on loading Freenet, resuming existing downloads.\n * => Significant improvement in reliability and disk I/O. In principle we could resume downloads\n * separately from the database e.g. if it breaks. Too complicated in practice because of other\n * data structures.\n * - Require: Add \"persistence\", hashCode, force no deactivation, activate where necessary (when\n * dealing with other stuff). Fill in context and load storage when activated on startup.\n * \n * Longer term goal: Implement similar code for inserts. Eliminate db4o and persist everything that\n * remains with simple checkpointed serialisation.\n * \n * LOCKING: (this) should be taken last, because it is used by e.g. SplitFileFetcherGet.isCancelled().\n * \n * @author toad\n */\npublic class SplitFileFetcher implements ClientGetState, SplitFileFetcherStorageCallback, Serializable {\n    \n    private static final long serialVersionUID = 1L;\n    private static volatile boolean logMINOR;\n    static {\n        Logger.registerClass(SplitFileFetcher.class);\n    }\n\n    /** Stores the progress of the download, including the actual data, in a separate file. \n     * Created in onResume() or in the constructor, so must be volatile. */\n    private transient volatile SplitFileFetcherStorage storage;\n    /** Kept here so we can resume from storage */\n    private LockableRandomAccessBuffer raf;\n    final ClientRequester parent;\n    final GetCompletionCallback cb;\n    /** If non-null, we will complete via truncation. */\n    final FileGetCompletionCallback callbackCompleteViaTruncation;\n    /** If non-null, this is the temporary file we have allocated for completion via truncation.\n     * The download will be stored in this file until it is complete, at which point the storage\n     * will truncate it and we will feed it to the callback. */\n    final File fileCompleteViaTruncation;\n    final boolean realTimeFlag;\n    final FetchContext blockFetchContext;\n    final long token;\n    /** Storage doesn't have a ClientContext so we need one here. */\n    private transient ClientContext context;\n    /** Does the actual requests. \n     * Created in onResume() or in the constructor, so must be volatile. */\n    private transient volatile SplitFileFetcherGet getter;\n    private boolean failed;\n    private boolean succeeded;\n    private final boolean wantBinaryBlob;\n    private final boolean persistent;\n    \n    public SplitFileFetcher(Metadata metadata, GetCompletionCallback rcb, ClientRequester parent,\n            FetchContext fetchContext, boolean realTimeFlag, List<COMPRESSOR_TYPE> decompressors, \n            ClientMetadata clientMetadata, long token, boolean topDontCompress, \n            short topCompatibilityMode, boolean persistent, FreenetURI thisKey, boolean isFinalFetch,\n            ClientContext context) \n            throws FetchException, MetadataParseException {\n        this.persistent = persistent;\n        this.cb = rcb;\n        this.parent = parent;\n        this.realTimeFlag = realTimeFlag;\n        this.token = token;\n        this.context = context;\n        if(parent instanceof ClientGetter) {\n            wantBinaryBlob = ((ClientGetter)parent).collectingBinaryBlob();\n        } else {\n            wantBinaryBlob = false;\n        }\n        blockFetchContext = new FetchContext(fetchContext, FetchContext.SPLITFILE_DEFAULT_BLOCK_MASK, true, null);\n        if(parent.isCancelled())\n            throw new FetchException(FetchExceptionMode.CANCELLED);\n        \n        try {\n            // Completion via truncation.\n            if(isFinalFetch && cb instanceof FileGetCompletionCallback && \n                    (decompressors == null || decompressors.size() == 0) &&\n                    !fetchContext.filterData) {\n                FileGetCompletionCallback fileCallback = ((FileGetCompletionCallback)cb);\n                File targetFile = fileCallback.getCompletionFile();\n                if(targetFile != null) {\n                    callbackCompleteViaTruncation = fileCallback;\n                    fileCompleteViaTruncation = FileUtil.createTempFile(targetFile.getName(), \".freenet-tmp\", targetFile.getParentFile());\n                    // Storage must actually create the RAF since it knows the length.\n                } else {\n                    callbackCompleteViaTruncation = null;\n                    fileCompleteViaTruncation = null;\n                }\n            } else {\n                callbackCompleteViaTruncation = null;\n                fileCompleteViaTruncation = null;\n            }\n            // Construct the storage.\n            ChecksumChecker checker = new CRCChecksumChecker();\n            storage = new SplitFileFetcherStorage(metadata, this, decompressors, clientMetadata, \n                    topDontCompress, topCompatibilityMode, fetchContext, realTimeFlag, getSalter(),\n                    thisKey, parent.getURI(), isFinalFetch, parent.getClientDetail(checker), \n                    context.random, context.tempBucketFactory, \n                    persistent ? context.persistentRAFFactory : context.tempRAFFactory, \n                    persistent ? context.jobRunner : context.dummyJobRunner, \n                    context.ticker, context.memoryLimitedJobRunner, checker, persistent,\n                    fileCompleteViaTruncation, context.getFileRandomAccessBufferFactory(persistent), \n                    context.getChkFetchScheduler(realTimeFlag).fetchingKeys());\n        } catch (InsufficientDiskSpaceException e) {\n            throw new FetchException(FetchExceptionMode.NOT_ENOUGH_DISK_SPACE);\n        } catch (IOException e) {\n            Logger.error(this, \"Failed to start splitfile fetcher because of disk I/O error?: \"+e, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        }\n        long eventualLength = Math.max(storage.decompressedLength, metadata.uncompressedDataLength());\n        cb.onExpectedSize(eventualLength, context);\n        if(metadata.uncompressedDataLength() > 0)\n            cb.onFinalizedMetadata();\n        if(eventualLength > 0 && fetchContext.maxOutputLength > 0 && eventualLength > fetchContext.maxOutputLength)\n            throw new FetchException(FetchExceptionMode.TOO_BIG, eventualLength, true, clientMetadata.getMIMEType());\n        getter = new SplitFileFetcherGet(this, storage);\n        raf = storage.getRAF();\n        if(logMINOR)\n            Logger.minor(this, \"Created \"+(persistent?\"persistent\" : \"transient\")+\" download for \"+\n                    thisKey+\" on \"+raf+\" for \"+this);\n        lastNotifiedStoreFetch = System.currentTimeMillis();\n    }\n    \n    protected SplitFileFetcher() {\n        // For serialization.\n        parent = null;\n        cb = null;\n        realTimeFlag = false;\n        blockFetchContext = null;\n        token = 0;\n        wantBinaryBlob = false;\n        persistent = true;\n        callbackCompleteViaTruncation = null;\n        fileCompleteViaTruncation = null;\n    }\n\n    @Override\n    public void schedule(ClientContext context) {\n        if(storage.start(false))\n            getter.schedule(context, false);\n    }\n    \n    /** Fail the whole splitfile request when we get an IOException on writing to or reading from \n     * the on-disk storage. Can be called asynchronously by SplitFileFetcher*Storage if an \n     * off-thread job (e.g. FEC decoding) breaks, or may be called when SplitFileFetcher*Storage\n     * throws.\n     * @param e The IOException, generated when accessing the on-disk storage.\n     */\n    @Override\n    public void failOnDiskError(IOException e) {\n        fail(new FetchException(FetchExceptionMode.BUCKET_ERROR));\n    }\n    \n    /** Fail the whole splitfile request when we get unrecoverable data corruption, e.g. can't \n     * read the keys. FIXME ROBUSTNESS in some cases this could actually be recovered by \n     * restarting from the metadata or the original URI. */\n    @Override\n    public void failOnDiskError(ChecksumFailedException e) {\n        fail(new FetchException(FetchExceptionMode.BUCKET_ERROR));\n    }\n    \n    public void fail(FetchException e) {\n        synchronized(this) {\n            if(succeeded || failed) return;\n            failed = true;\n        }\n        if(storage != null)\n            context.getChkFetchScheduler(realTimeFlag).removePendingKeys(storage.keyListener, true);\n        if(getter != null)\n            getter.cancel(context);\n        if(storage != null)\n            storage.cancel();\n        cb.onFailure(e, this, context);\n    }\n\n    @Override\n    public void cancel(ClientContext context) {\n        fail(new FetchException(FetchExceptionMode.CANCELLED));\n    }\n\n    @Override\n    public long getToken() {\n        return token;\n    }\n\n    /** The splitfile download succeeded. Generate a stream and send it to the \n     * GetCompletionCallback. See bug #6063 for a better way that probably is too much complexity\n     * for the benefit. */\n    @Override\n    public void onSuccess() {\n        boolean fail = false;\n        synchronized(this) {\n            if(failed) {\n                fail = true;\n            } else {\n                if(succeeded) {\n                    Logger.error(this, \"Called onSuccess() twice on \"+this, new Exception(\"debug\"));\n                    return;\n                } else {\n                    if(logMINOR) Logger.minor(this, \"onSuccess() on \"+this, new Exception(\"debug\"));\n                }\n                succeeded = true;\n            }\n        }\n        if(fail) {\n            storage.finishedFetcher();\n            return;\n        }\n        context.getChkFetchScheduler(realTimeFlag).removePendingKeys(storage.keyListener, true);\n        getter.cancel(context);\n        if(this.callbackCompleteViaTruncation != null) {\n            long finalLength = storage.finalLength;\n            this.callbackCompleteViaTruncation.onSuccess(fileCompleteViaTruncation, \n                    finalLength, storage.clientMetadata, this, context);\n            // Don't need to call storage.finishedFetcher().\n        } else {\n            cb.onSuccess(storage.streamGenerator(), storage.clientMetadata, storage.decompressors, \n                    this, context);\n            storage.finishedFetcher();\n        }\n    }\n    \n    @Override\n    public void onClosed() {\n        // Don't need to do anything.\n    }\n\n    public short getPriorityClass() {\n        return this.parent.getPriorityClass();\n    }\n\n    @Override\n    public void setSplitfileBlocks(int requiredBlocks, int remainingBlocks) {\n        parent.addMustSucceedBlocks(requiredBlocks);\n        parent.addBlocks(remainingBlocks);\n        parent.notifyClients(context);\n    }\n\n    @Override\n    public void onSplitfileCompatibilityMode(CompatibilityMode min, CompatibilityMode max,\n            byte[] customSplitfileKey, boolean compressed, boolean bottomLayer,\n            boolean definitiveAnyway) {\n        cb.onSplitfileCompatibilityMode(min, max, customSplitfileKey, compressed, bottomLayer, definitiveAnyway, context);\n    }\n\n    @Override\n    public void queueHeal(byte[] data, byte[] cryptoKey, byte cryptoAlgorithm) {\n        try {\n            RandomAccessBucket dataBucket = BucketTools.makeImmutableBucket(\n                context.tempBucketFactory,\n                data);\n            context.healingQueue.queue(dataBucket, cryptoKey, cryptoAlgorithm, context);\n        } catch (IOException e) {\n            // Nothing to be done, but need to log the error.\n            Logger.error(this, \"I/O error, failed to queue healing block: \"+e, e);\n        }\n    }\n\n    public boolean localRequestOnly() {\n        return blockFetchContext.localRequestOnly;\n    }\n\n    public void toNetwork() {\n        parent.toNetwork(context);\n    }\n\n    public boolean hasFinished() {\n        return failed || succeeded;\n    }\n    \n    /** Incremented whenever we fetch a block from the store */\n    private int storeFetchCounter;\n    /** Time when we last passed through a block fetch from the store */\n    private long lastNotifiedStoreFetch;\n    static final int STORE_NOTIFY_BLOCKS = 100;\n    static final long STORE_NOTIFY_INTERVAL = 200;\n\n    @Override\n    public void onFetchedBlock() {\n        boolean dontNotify = true;\n        if(getter.hasQueued()) {\n            dontNotify = false;\n        } else {\n            synchronized(this) {\n                if(storeFetchCounter++ == STORE_NOTIFY_BLOCKS) {\n                    storeFetchCounter = 0;\n                    dontNotify = false;\n                    lastNotifiedStoreFetch = System.currentTimeMillis();\n                } else {\n                    long now = System.currentTimeMillis();\n                    if(now - lastNotifiedStoreFetch >= STORE_NOTIFY_INTERVAL) {\n                        dontNotify = false;\n                        lastNotifiedStoreFetch = now;\n                    }\n                }\n            }\n        }\n        parent.completedBlock(dontNotify, context);\n    }\n\n    @Override\n    public void onFailedBlock() {\n        parent.failedBlock(context);\n    }\n    \n    @Override\n    public void onResume(int succeededBlocks, int failedBlocks, ClientMetadata meta, long finalSize) {\n        for(int i=0;i<succeededBlocks-1;i++)\n            parent.completedBlock(true, context);\n        if(succeededBlocks > 0)\n            parent.completedBlock(false, context);\n        for(int i=0;i<failedBlocks-1;i++)\n            parent.failedBlock(true, context);\n        if(failedBlocks > 0)\n            parent.failedBlock(false, context);\n        parent.blockSetFinalized(context);\n        try {\n            cb.onExpectedMIME(meta, context);\n        } catch (FetchException e) {\n            fail(e);\n            return;\n        }\n        cb.onExpectedSize(finalSize, context);\n    }\n\n    @Override\n    public void maybeAddToBinaryBlob(ClientCHKBlock block) {\n        if(parent instanceof ClientGetter) {\n            ((ClientGetter)parent).addKeyToBinaryBlob(block, context);\n        }\n    }\n\n    @Override\n    public boolean wantBinaryBlob() {\n        return wantBinaryBlob;\n    }\n\n    @Override\n    public BaseSendableGet getSendableGet() {\n        return getter;\n    }\n\n    @Override\n    public void restartedAfterDataCorruption() {\n        if(hasFinished()) return;\n        Logger.error(this, \"Restarting download \"+this+\" after data corruption\");\n        // We need to fetch more blocks. Some of them may even be in the datastore.\n        getter.unregister(context, getPriorityClass());\n        getter.schedule(context, false);\n        context.jobRunner.setCheckpointASAP();\n    }\n\n    @Override\n    public void clearCooldown() {\n        if(hasFinished()) return;\n        getter.clearWakeupTime(context);\n    }\n\n    @Override\n    public void reduceCooldown(long wakeupTime) {\n        getter.reduceWakeupTime(wakeupTime, context);\n    }\n\n    @Override\n    public HasKeyListener getHasKeyListener() {\n        return getter;\n    }\n\n    @Override\n    public void onResume(ClientContext context) throws FetchException {\n        if(logMINOR) Logger.minor(this, \"Restarting SplitFileFetcher from storage...\");\n        boolean resumed = parent instanceof ClientGetter && ((ClientGetter)parent).resumedFetcher();\n        this.context = context;\n        try {\n            KeySalter salter = getSalter();\n            raf.onResume(context);\n            this.storage = new SplitFileFetcherStorage(raf, realTimeFlag, this, blockFetchContext, \n                    context.random, context.jobRunner, \n                    context.getChkFetchScheduler(realTimeFlag).fetchingKeys(), context.ticker, \n                    context.memoryLimitedJobRunner, new CRCChecksumChecker(), \n                    context.jobRunner.newSalt(), salter, resumed, \n                    callbackCompleteViaTruncation != null);\n        } catch (ResumeFailedException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume storage file: \"+e+\" for \"+raf, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        } catch (IOException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume due to I/O error: \"+e+\" raf = \"+raf, e);\n            throw new FetchException(FetchExceptionMode.BUCKET_ERROR, e);\n        } catch (StorageFormatException e) {\n            raf.free();\n            Logger.error(this, \"Failed to resume due to storage error: \"+e+\" raf = \"+raf, e);\n            throw new FetchException(FetchExceptionMode.INTERNAL_ERROR, \"Resume failed: \"+e, e);\n        } catch (FetchException e) {\n            raf.free();\n            throw e;\n        }\n        synchronized(this) {\n            lastNotifiedStoreFetch = System.currentTimeMillis();\n        }\n        getter = new SplitFileFetcherGet(this, storage);\n        if (storage.start(resumed)) {\n            getter.schedule(context, storage.hasCheckedStore());\n        }\n    }\n\n    @Override\n    public KeySalter getSalter() {\n        return context.getChkFetchScheduler(realTimeFlag).getGlobalKeySalter(persistent);\n    }\n\n    public boolean writeTrivialProgress(DataOutputStream dos) throws IOException {\n        boolean done = false;\n        synchronized(this) {\n            done = failed || succeeded;\n        }\n        if(done) {\n            dos.writeBoolean(false);\n            return false;\n        }\n        dos.writeBoolean(true);\n        if(callbackCompleteViaTruncation == null) {\n            dos.writeBoolean(false);\n            raf.storeTo(dos);\n        } else {\n            dos.writeBoolean(true);\n            dos.writeUTF(fileCompleteViaTruncation.toString());\n            dos.writeLong(raf.size());\n        }\n        dos.writeLong(token);\n        return true;\n    }\n    \n    public SplitFileFetcher(ClientGetter getter, DataInputStream dis, ClientContext context) \n    throws StorageFormatException, ResumeFailedException, IOException {\n        Logger.normal(this, \"Resuming splitfile download for \"+this);\n        boolean completeViaTruncation = dis.readBoolean();\n        if(completeViaTruncation) {\n            fileCompleteViaTruncation = new File(dis.readUTF());\n            if(!fileCompleteViaTruncation.exists())\n                throw new ResumeFailedException(\"Storage file does not exist: \"+fileCompleteViaTruncation);\n            callbackCompleteViaTruncation = (FileGetCompletionCallback) getter;\n            long rafSize = dis.readLong();\n            if(fileCompleteViaTruncation.length() != rafSize)\n                throw new ResumeFailedException(\"Storage file is not of the correct length\");\n            // FIXME check against finalLength too, maybe we can finish straight away.\n            this.raf = new PooledFileRandomAccessBuffer(fileCompleteViaTruncation, false, rafSize, null, -1, true);\n        } else {\n            this.raf = BucketTools.restoreRAFFrom(dis, context.persistentFG, context.persistentFileTracker, context.getPersistentMasterSecret());\n            fileCompleteViaTruncation = null;\n            callbackCompleteViaTruncation = null;\n        }\n        this.parent = getter;\n        this.cb = getter;\n        this.persistent = true;\n        this.realTimeFlag = parent.realTimeFlag();\n        token = dis.readLong();\n        this.blockFetchContext = getter.ctx;\n        this.wantBinaryBlob = getter.collectingBinaryBlob();\n        // onResume() will do the rest.\n        Logger.normal(this, \"Resumed splitfile download for \"+this);\n        lastNotifiedStoreFetch = System.currentTimeMillis();\n    }\n\n    @Override\n    public void onShutdown(ClientContext context) {\n        storage.onShutdown(context);\n    }\n\n}\n","lineNo":301}
{"Smelly Sample":"package freenet.support.compress;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.text.MessageFormat;\nimport java.util.zip.GZIPInputStream;\nimport java.util.zip.GZIPOutputStream;\n\nimport freenet.support.Logger;\nimport freenet.support.api.Bucket;\nimport freenet.support.api.BucketFactory;\nimport freenet.support.api.RandomAccessBucket;\nimport freenet.support.api.RandomAccessBuffer;\nimport freenet.support.io.ArrayBucket;\nimport freenet.support.io.Closer;\nimport freenet.support.io.CountedOutputStream;\n\npublic class GzipCompressor extends AbstractCompressor {\n\n\t@Override\n\tpublic Bucket compress(Bucket data, BucketFactory bf, long maxReadLength, long maxWriteLength)\n\t\t\tthrows IOException, CompressionOutputSizeException {\n\t\tRandomAccessBucket output = bf.makeBucket(maxWriteLength);\n\t\tInputStream is = null;\n\t\tOutputStream os = null;\n\t\ttry {\n\t\t\tis = data.getInputStream();\n\t\t\tos = output.getOutputStream();\n\t\t\tcompress(is, os, maxReadLength, maxWriteLength);\n\t\t\t// It is essential that the close()'s throw if there is any problem.\n\t\t\tis.close(); is = null;\n\t\t\tos.close(); os = null;\n\t\t} finally {\n\t\t\tCloser.close(is);\n\t\t\tCloser.close(os);\n\t\t}\n\t\t// force OS byte to 0 regardless of Java version (java 16 changed to setting 255 which would break hashes)\n\t\tif (output instanceof ArrayBucket) {\n\t\t\tbyte[] dataArray = ((ArrayBucket) output).toByteArray();\n\t\t\tdataArray[9] = 0;\n\t\t\treturn new ArrayBucket(dataArray);\n\t\t} else {\n\t\t\t// slower fallback\n\t\t\treturn copyBucketPatchingOSByte(bf, maxWriteLength, output);\n\t\t}\n\t}\n\n\tprivate static RandomAccessBucket copyBucketPatchingOSByte(\n\t\t\tBucketFactory bf,\n\t\t\tlong maxWriteLength,\n\t\t\tRandomAccessBucket output) throws IOException {\n\t\tRandomAccessBucket consistentOutput = bf.makeBucket(maxWriteLength);\n\t\tInputStream inputStream = null;\n\t\tOutputStream consistentOutputStream = null;\n\t\ttry {\n\t\t\tinputStream = output.getInputStream();\n\t\t\tconsistentOutputStream = consistentOutput.getOutputStream();\n\t\t\tbyte[] buf = new byte[8192];\n\t\t\tint previousRead = 0;\n\t\t\tint length = inputStream.read(buf);\n\t\t\tint read = length;\n\t\t\twhile (read < 8 && length != -1) {\n\t\t\t\tpreviousRead = read;\n\t\t\t\tconsistentOutputStream.write(buf, 0, length);\n\t\t\t\tlength = inputStream.read(buf);\n\t\t\t\tread += length;\n\t\t\t}\n\t\t\t// fix OS byte\n\t\t\tbuf[9 - previousRead] = 0;\n\t\t\tconsistentOutputStream.write(buf, 0, length);\n\t\t\twhile ((length = inputStream.read(buf)) != -1) {\n\t\t\t\tconsistentOutputStream.write(buf, 0, length);\n\t\t\t}\n\t\t\tinputStream.close(); inputStream = null;\n\t\t\tconsistentOutputStream.close(); consistentOutputStream = null;\n\t\t} finally {\n\t\t\tCloser.close(inputStream);\n\t\t\tCloser.close(consistentOutputStream);\n\t\t}\n\t\treturn consistentOutput;\n\t}\n\n\t@Override\n\tpublic long compress(InputStream is, OutputStream os, long maxReadLength, long maxWriteLength,\n\t\t\t\t\t\t long amountOfDataToCheckCompressionRatio, int minimumCompressionPercentage)\n\t\t\tthrows IOException, CompressionRatioException {\n\t\tif(maxReadLength < 0)\n\t\t\tthrow new IllegalArgumentException();\n\t\tGZIPOutputStream gos = null;\n\t\tCountedOutputStream cos = new CountedOutputStream(os);\n\t\ttry {\n\t\t\tgos = new GZIPOutputStream(cos);\n\t\t\tlong read = 0;\n\t\t\t// Bigger input buffer, so can compress all at once.\n\t\t\t// Won't hurt on I/O either, although most OSs will only return a page at a time.\n\t\t\tint bufferSize = 32768;\n\t\t\tbyte[] buffer = new byte[bufferSize];\n\t\t\tlong iterationToCheckCompressionRatio = amountOfDataToCheckCompressionRatio / bufferSize;\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tint l = (int) Math.min(buffer.length, maxReadLength - read);\n\t\t\t\tint x = l == 0 ? -1 : is.read(buffer, 0, l);\n\t\t\t\tif(x <= -1) break;\n\t\t\t\tif(x == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\t\tgos.write(buffer, 0, x);\n\t\t\t\tread += x;\n\t\t\t\tif(cos.written() > maxWriteLength)\n\t\t\t\t\tthrow new CompressionOutputSizeException();\n\n\t\t\t\tif (++i == iterationToCheckCompressionRatio && minimumCompressionPercentage != 0) {\n\t\t\t\t\tcheckCompressionEffect(read, cos.written(), minimumCompressionPercentage);\n\t\t\t\t}\n\t\t\t}\n\t\t\tgos.flush();\n\t\t\tgos.finish();\n\t\t\tcos.flush();\n\t\t\tgos = null;\n\t\t\tif(cos.written() > maxWriteLength)\n\t\t\t\tthrow new CompressionOutputSizeException();\n\t\t\treturn cos.written();\n\t\t} finally {\n\t\t\tif(gos != null) {\n\t\t\t\tgos.flush();\n\t\t\t\tgos.finish();\n\t\t\t}\n\t\t}\n\t}\n\n\t@Override\n\tpublic long decompress(InputStream is, OutputStream os, long maxLength, long maxCheckSizeBytes) throws IOException, CompressionOutputSizeException {\n\t\tGZIPInputStream gis = new GZIPInputStream(is);\n\t\tlong written = 0;\n\t\tint bufSize = 32768;\n\t\tif(maxLength > 0 && maxLength < bufSize)\n\t\t\tbufSize = (int)maxLength;\n\t\tbyte[] buffer = new byte[bufSize];\n\t\twhile(true) {\n\t\t\tint expectedBytesRead = (int) Math.min(buffer.length, maxLength - written);\n\t\t\t// We can over-read to determine whether we have over-read.\n\t\t\t// We enforce maximum size this way.\n\t\t\t// FIXME there is probably a better way to do this!\n\t\t\tint bytesRead = gis.read(buffer, 0, buffer.length);\n\t\t\tif(expectedBytesRead < bytesRead) {\n\t\t\t\tLogger.normal(this, \"expectedBytesRead=\"+expectedBytesRead+\", bytesRead=\"+bytesRead+\", written=\"+written+\", maxLength=\"+maxLength+\" throwing a CompressionOutputSizeException\");\n\t\t\t\tif(maxCheckSizeBytes > 0) {\n\t\t\t\t\twritten += bytesRead;\n\t\t\t\t\twhile(true) {\n\t\t\t\t\t\texpectedBytesRead = (int) Math.min(buffer.length, maxLength + maxCheckSizeBytes - written);\n\t\t\t\t\t\tbytesRead = gis.read(buffer, 0, expectedBytesRead);\n\t\t\t\t\t\tif(bytesRead <= -1) throw new CompressionOutputSizeException(written);\n\t\t\t\t\t\tif(bytesRead == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\t\t\t\twritten += bytesRead;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tthrow new CompressionOutputSizeException();\n\t\t\t}\n\t\t\tif(bytesRead <= -1) {\n\t\t\t\tos.flush();\n\t\t\t\treturn written;\n\t\t\t}\n\t\t\tif(bytesRead == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\tos.write(buffer, 0, bytesRead);\n\t\t\twritten += bytesRead;\n\t\t}\n\t}\n\n\t@Override\n\tpublic int decompress(byte[] dbuf, int i, int j, byte[] output) throws CompressionOutputSizeException {\n\t\t// Didn't work with Inflater.\n\t\t// FIXME fix sometimes to use Inflater - format issue?\n\t\tByteArrayInputStream bais = new ByteArrayInputStream(dbuf, i, j);\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream(output.length);\n\t\tint bytes = 0;\n\t\ttry {\n\t\t\tdecompress(bais, baos, output.length, -1);\n\t\t\tbytes = baos.size();\n\t\t} catch (IOException e) {\n\t\t\t// Impossible\n\t\t\tthrow new Error(\"Got IOException: \" + e.getMessage(), e);\n\t\t}\n\t\tbyte[] buf = baos.toByteArray();\n\t\tSystem.arraycopy(buf, 0, output, 0, bytes);\n\t\treturn bytes;\n\t}\n}\n","Method after Refactoring":"package freenet.support.compress;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.text.MessageFormat;\nimport java.util.zip.GZIPInputStream;\nimport java.util.zip.GZIPOutputStream;\n\nimport freenet.support.Logger;\nimport freenet.support.api.Bucket;\nimport freenet.support.api.BucketFactory;\nimport freenet.support.api.RandomAccessBucket;\nimport freenet.support.api.RandomAccessBuffer;\nimport freenet.support.io.ArrayBucket;\nimport freenet.support.io.Closer;\nimport freenet.support.io.CountedOutputStream;\n\npublic class GzipCompressor extends AbstractCompressor {\n\n\t@Override\n\tpublic Bucket compress(Bucket data, BucketFactory bf, long maxReadLength, long maxWriteLength)\n\t\t\tthrows IOException, CompressionOutputSizeException {\n\t\tRandomAccessBucket output = bf.makeBucket(maxWriteLength);\n\t\tInputStream is = null;\n\t\tOutputStream os = null;\n\t\ttry {\n\t\t\tis = data.getInputStream();\n\t\t\tos = output.getOutputStream();\n\t\t\t// force OS byte to 0 regardless of Java version (java 16 changed to setting 255 which would break hashes)\n\t\t\tSingleOffsetReplacingOutputStream osByteFixingOs = new SingleOffsetReplacingOutputStream(os, 9, 0);\n\t\t\tcompress(is, osByteFixingOs, maxReadLength, maxWriteLength);\n\t\t\t// It is essential that the close()'s throw if there is any problem.\n\t\t\tis.close(); is = null;\n\t\t\tos.close(); os = null;\n\t\t} finally {\n\t\t\tCloser.close(is);\n\t\t\tCloser.close(os);\n\t\t}\n\t\treturn output;\n\t}\n\n\t@Override\n\tpublic long compress(InputStream is, OutputStream os, long maxReadLength, long maxWriteLength,\n\t\t\t\t\t\t long amountOfDataToCheckCompressionRatio, int minimumCompressionPercentage)\n\t\t\tthrows IOException, CompressionRatioException {\n\t\tif(maxReadLength < 0)\n\t\t\tthrow new IllegalArgumentException();\n\t\tGZIPOutputStream gos = null;\n\t\tCountedOutputStream cos = new CountedOutputStream(os);\n\t\ttry {\n\t\t\tgos = new GZIPOutputStream(cos);\n\t\t\tlong read = 0;\n\t\t\t// Bigger input buffer, so can compress all at once.\n\t\t\t// Won't hurt on I/O either, although most OSs will only return a page at a time.\n\t\t\tint bufferSize = 32768;\n\t\t\tbyte[] buffer = new byte[bufferSize];\n\t\t\tlong iterationToCheckCompressionRatio = amountOfDataToCheckCompressionRatio / bufferSize;\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tint l = (int) Math.min(buffer.length, maxReadLength - read);\n\t\t\t\tint x = l == 0 ? -1 : is.read(buffer, 0, l);\n\t\t\t\tif(x <= -1) break;\n\t\t\t\tif(x == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\t\tgos.write(buffer, 0, x);\n\t\t\t\tread += x;\n\t\t\t\tif(cos.written() > maxWriteLength)\n\t\t\t\t\tthrow new CompressionOutputSizeException();\n\n\t\t\t\tif (++i == iterationToCheckCompressionRatio && minimumCompressionPercentage != 0) {\n\t\t\t\t\tcheckCompressionEffect(read, cos.written(), minimumCompressionPercentage);\n\t\t\t\t}\n\t\t\t}\n\t\t\tgos.flush();\n\t\t\tgos.finish();\n\t\t\tcos.flush();\n\t\t\tgos = null;\n\t\t\tif(cos.written() > maxWriteLength)\n\t\t\t\tthrow new CompressionOutputSizeException();\n\t\t\treturn cos.written();\n\t\t} finally {\n\t\t\tif(gos != null) {\n\t\t\t\tgos.flush();\n\t\t\t\tgos.finish();\n\t\t\t}\n\t\t}\n\t}\n\n\t@Override\n\tpublic long decompress(InputStream is, OutputStream os, long maxLength, long maxCheckSizeBytes) throws IOException, CompressionOutputSizeException {\n\t\tGZIPInputStream gis = new GZIPInputStream(is);\n\t\tlong written = 0;\n\t\tint bufSize = 32768;\n\t\tif(maxLength > 0 && maxLength < bufSize)\n\t\t\tbufSize = (int)maxLength;\n\t\tbyte[] buffer = new byte[bufSize];\n\t\twhile(true) {\n\t\t\tint expectedBytesRead = (int) Math.min(buffer.length, maxLength - written);\n\t\t\t// We can over-read to determine whether we have over-read.\n\t\t\t// We enforce maximum size this way.\n\t\t\t// FIXME there is probably a better way to do this!\n\t\t\tint bytesRead = gis.read(buffer, 0, buffer.length);\n\t\t\tif(expectedBytesRead < bytesRead) {\n\t\t\t\tLogger.normal(this, \"expectedBytesRead=\"+expectedBytesRead+\", bytesRead=\"+bytesRead+\", written=\"+written+\", maxLength=\"+maxLength+\" throwing a CompressionOutputSizeException\");\n\t\t\t\tif(maxCheckSizeBytes > 0) {\n\t\t\t\t\twritten += bytesRead;\n\t\t\t\t\twhile(true) {\n\t\t\t\t\t\texpectedBytesRead = (int) Math.min(buffer.length, maxLength + maxCheckSizeBytes - written);\n\t\t\t\t\t\tbytesRead = gis.read(buffer, 0, expectedBytesRead);\n\t\t\t\t\t\tif(bytesRead <= -1) throw new CompressionOutputSizeException(written);\n\t\t\t\t\t\tif(bytesRead == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\t\t\t\twritten += bytesRead;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tthrow new CompressionOutputSizeException();\n\t\t\t}\n\t\t\tif(bytesRead <= -1) {\n\t\t\t\tos.flush();\n\t\t\t\treturn written;\n\t\t\t}\n\t\t\tif(bytesRead == 0) throw new IOException(\"Returned zero from read()\");\n\t\t\tos.write(buffer, 0, bytesRead);\n\t\t\twritten += bytesRead;\n\t\t}\n\t}\n\n\t@Override\n\tpublic int decompress(byte[] dbuf, int i, int j, byte[] output) throws CompressionOutputSizeException {\n\t\t// Didn't work with Inflater.\n\t\t// FIXME fix sometimes to use Inflater - format issue?\n\t\tByteArrayInputStream bais = new ByteArrayInputStream(dbuf, i, j);\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream(output.length);\n\t\tint bytes = 0;\n\t\ttry {\n\t\t\tdecompress(bais, baos, output.length, -1);\n\t\t\tbytes = baos.size();\n\t\t} catch (IOException e) {\n\t\t\t// Impossible\n\t\t\tthrow new Error(\"Got IOException: \" + e.getMessage(), e);\n\t\t}\n\t\tbyte[] buf = baos.toByteArray();\n\t\tSystem.arraycopy(buf, 0, output, 0, bytes);\n\t\treturn bytes;\n\t}\n}\n","lineNo":33}
{"Smelly Sample":"package freenet.support;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\nimport java.io.BufferedOutputStream;\nimport java.io.Closeable;\nimport java.io.DataInputStream;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.OutputStreamWriter;\nimport java.io.PrintStream;\nimport java.io.UnsupportedEncodingException;\nimport java.net.InetAddress;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\nimport java.text.DateFormat;\nimport java.text.SimpleDateFormat;\nimport java.util.ArrayList;\nimport java.util.ArrayDeque;\nimport java.util.Calendar;\nimport java.util.Date;\nimport java.util.Deque;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.StringTokenizer;\nimport java.util.TimeZone;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.zip.GZIPOutputStream;\n\nimport freenet.node.SemiOrderedShutdownHook;\nimport freenet.node.Version;\nimport freenet.support.io.FileUtil;\n\n/**\n * Converted the old StandardLogger to Ian's loggerhook interface.\n * \n * @author oskar\n */\npublic class FileLoggerHook extends LoggerHook implements Closeable {\n\n\t/** Verbosity types */\n\tpublic static final int DATE = 1,\n\t\tCLASS = 2,\n\t\tHASHCODE = 3,\n\t\tTHREAD = 4,\n\t\tPRIORITY = 5,\n\t\tMESSAGE = 6,\n\t\tUNAME = 7;\n\n\tprivate volatile boolean closed = false;\n\tprivate boolean closedFinished = false;\n\n\tprotected int INTERVAL = Calendar.MINUTE;\n\tprotected int INTERVAL_MULTIPLIER = 5;\n\t\n\tprivate static final String ENCODING = \"UTF-8\";\n\n        private static volatile boolean logMINOR;\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t/** Name of the local host (called uname in Unix-like operating systems). */\n\tprivate static String uname;\n\tstatic {\n\t\tuname = \"unknown\";\n\t}\n\n\tstatic synchronized void getUName() {\n\t\tif(!uname.equals(\"unknown\")) return;\n\t\tSystem.out.println(\"Getting uname for logging\");\n\t\ttry {\n\t\t\tInetAddress addr = InetAddress.getLocalHost();\n\t\t\tif (addr != null) {\n\t\t\t\tuname =\n\t\t\t\t\tnew StringTokenizer(addr.getHostName(), \".\").nextToken();\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\t// Ignored.\n\t\t}\n\t}\n\t\n\tprivate DateFormat df;\n\tprivate int[] fmt;\n\tprivate String[] str;\n\n\t/** Stream to write data to (compressed if rotate is on) */\n\tprotected OutputStream logStream;\n\t/** Other stream to write data to (may be null) */\n\tprotected OutputStream altLogStream;\n\n\tprotected final boolean logOverwrite;\n\n\t/* Base filename for rotating logs */\n\tprotected String baseFilename = null;\n\t\n\tprotected File latestFile;\n\tprotected File previousFile;\n\n\t/* Whether to redirect stdout */\n\tprotected boolean redirectStdOut = false;\n\t/* Whether to redirect stderr */\n\tprotected boolean redirectStdErr = false;\n\n\tprotected final int MAX_LIST_SIZE;\n\tprotected long MAX_LIST_BYTES = 10 * (1 << 20);\n\tprotected long LIST_WRITE_THRESHOLD;\n\n\t/**\n\t * Something weird happens when the disk gets full, also we don't want to\n\t * block So run the actual write on another thread\n\t * \n\t * Unfortunately, we can't use ConcurrentBlockingQueue because we need to dump stuff when the queue gets\n\t * too big.\n\t * \n\t * FIXME PERFORMANCE: Using an ArrayBlockingQueue avoids some unnecessary memory allocations, but it \n\t * means we have to take two locks. \n\t * Seriously consider reverting 88268b99856919df0d42c2787d9ea3674a9f6f0d..e359b4005ef728a159fdee988c483de8ce8f3f6b\n\t * to go back to one lock and a LinkedList.\n\t */\n\tprotected final ArrayBlockingQueue<byte[]> list;\n\tprotected long listBytes = 0;\n\n\tlong maxOldLogfilesDiskUsage;\n\tprotected final Deque<OldLogFile> logFiles = new ArrayDeque<OldLogFile>();\n\tprivate long oldLogFilesDiskSpaceUsage = 0;\n\n\tprivate static class OldLogFile {\n\t\tpublic OldLogFile(File currentFilename, long startTime, long endTime, long length) {\n\t\t\tthis.filename = currentFilename;\n\t\t\tthis.start = startTime;\n\t\t\tthis.end = endTime;\n\t\t\tthis.size = length;\n\t\t}\n\t\tfinal File filename;\n\t\tfinal long start; // inclusive\n\t\tfinal long end; // exclusive\n\t\tfinal long size;\n\t}\n\t\n\tpublic void setMaxListBytes(long len) {\n\t\tsynchronized(list) {\n\t\t\tMAX_LIST_BYTES = len;\n\t\t\tLIST_WRITE_THRESHOLD = MAX_LIST_BYTES / 4;\n\t\t}\n\t}\n\n\tpublic void setInterval(String intervalName) throws IntervalParseException {\n\t\tStringBuilder sb = new StringBuilder(intervalName.length());\n\t\tfor(int i=0;i<intervalName.length();i++) {\n\t\t\tchar c = intervalName.charAt(i);\n\t\t\tif(!Character.isDigit(c)) break;\n\t\t\tsb.append(c);\n\t\t}\n\t\tif(sb.length() > 0) {\n\t\t\tString prefix = sb.toString();\n\t\t\tintervalName = intervalName.substring(prefix.length());\n\t\t\tINTERVAL_MULTIPLIER = Integer.parseInt(prefix);\n\t\t} else {\n\t\t\tINTERVAL_MULTIPLIER = 1;\n\t\t}\n\t\tif (intervalName.endsWith(\"S\")) {\n\t\t\tintervalName = intervalName.substring(0, intervalName.length()-1);\n\t\t}\n\t\tif (intervalName.equalsIgnoreCase(\"MINUTE\"))\n\t\t\tINTERVAL = Calendar.MINUTE;\n\t\telse if (intervalName.equalsIgnoreCase(\"HOUR\"))\n\t\t\tINTERVAL = Calendar.HOUR;\n\t\telse if (intervalName.equalsIgnoreCase(\"DAY\"))\n\t\t\tINTERVAL = Calendar.DAY_OF_MONTH;\n\t\telse if (intervalName.equalsIgnoreCase(\"WEEK\"))\n\t\t\tINTERVAL = Calendar.WEEK_OF_YEAR;\n\t\telse if (intervalName.equalsIgnoreCase(\"MONTH\"))\n\t\t\tINTERVAL = Calendar.MONTH;\n\t\telse if (intervalName.equalsIgnoreCase(\"YEAR\"))\n\t\t\tINTERVAL = Calendar.YEAR;\n\t\telse\n\t\t\tthrow new IntervalParseException(\"invalid interval \" + intervalName);\n\t\tSystem.out.println(\"Set interval to \"+INTERVAL+\" and multiplier to \"+INTERVAL_MULTIPLIER);\n\t}\n\n\tpublic static class IntervalParseException extends Exception {\n\n\t\tprivate static final long serialVersionUID = 69847854744673572L;\n\n\t\tpublic IntervalParseException(String string) {\n\t\t\tsuper(string);\n\t\t}\n\n\t}\n\t\n\t/**\n\t * The extra parameter int digit is to be used for creating a logfile name\n\t * when a log exists already with the same date.\n\t * @param c\n\t * @param digit\n\t *\t\t\tlog file name suffix. ignored if this is {@code < 0}\n\t * @param compressed\n\t * @return\n\t */\n\tprotected String getHourLogName(Calendar c, int digit, boolean compressed){\n\t\tStringBuilder buf = new StringBuilder(50);\n\t\tbuf.append(baseFilename).append('-');\n\t\tbuf.append(Version.buildNumber());\n\t\tbuf.append('-');\n\t\tbuf.append(c.get(Calendar.YEAR)).append('-');\n\t\tpad2digits(buf, c.get(Calendar.MONTH) + 1);\n\t\tbuf.append('-');\n\t\tpad2digits(buf, c.get(Calendar.DAY_OF_MONTH));\n\t\tbuf.append('-');\n\t\tpad2digits(buf, c.get(Calendar.HOUR_OF_DAY));\n\t\tif (INTERVAL == Calendar.MINUTE) {\n\t\t\tbuf.append('-');\n\t\t\tpad2digits(buf, c.get(Calendar.MINUTE));\n\t\t}\n\t\tif (digit > 0) {\n\t\t\tbuf.append(\"-\");\n\t\t\tbuf.append(digit);\n\t\t}\n\t\tbuf.append(\".log\");\n\t\tif(compressed) buf.append(\".gz\");\n\t\treturn buf.toString();\n\t}\n\n\tprivate StringBuilder pad2digits(StringBuilder buf, int x) {\n\t\tString s = Integer.toString(x);\n\t\tif (s.length() == 1) {\n\t\t\tbuf.append('0');\n\t\t}\n\t\tbuf.append(s);\n\t\treturn buf;\n\t}\n\t\n\t// Unless we are writing flat out, everything will hit disk within this period.\n\tprivate long flushTime = 1000; // Default is 1 second. Will be set by setMaxBacklogNotBusy().\n\n\tclass WriterThread extends Thread {\n\t\tWriterThread() {\n\t\t\tsuper(\"Log File Writer Thread\");\n\t\t}\n\n\t\t@Override\n\t\t@SuppressWarnings(\"fallthrough\")\n\t\tpublic void run() {\n\t\t\tFile currentFilename = null;\n\t\t\tbyte[] o = null;\n\t\t\tlong thisTime;\n\t\t\tlong lastTime = -1;\n\t\t\tlong startTime;\n\t\t\tlong nextHour = -1;\n\t\t\tGregorianCalendar gc = null;\n\t\t\tif (baseFilename != null) {\n\t\t\t\tlatestFile = new File(baseFilename+\"-latest.log\");\n\t\t\t\tpreviousFile = new File(baseFilename+\"-previous.log\");\n\t\t\t\tgc = new GregorianCalendar();\n\t\t\t\tswitch (INTERVAL) {\n\t\t\t\t\tcase Calendar.YEAR :\n\t\t\t\t\t\tgc.set(Calendar.MONTH, 0);\n\t\t\t\t\tcase Calendar.MONTH :\n\t\t\t\t\t\tgc.set(Calendar.DAY_OF_MONTH, 0);\n\t\t\t\t\tcase Calendar.WEEK_OF_YEAR :\n\t\t\t\t\t\tif (INTERVAL == Calendar.WEEK_OF_YEAR)\n\t\t\t\t\t\t\tgc.set(Calendar.DAY_OF_WEEK, 0);\n\t\t\t\t\tcase Calendar.DAY_OF_MONTH :\n\t\t\t\t\t\tgc.set(Calendar.HOUR, 0);\n\t\t\t\t\tcase Calendar.HOUR :\n\t\t\t\t\t\tgc.set(Calendar.MINUTE, 0);\n\t\t\t\t\tcase Calendar.MINUTE :\n\t\t\t\t\t\tgc.set(Calendar.SECOND, 0);\n\t\t\t\t\t\tgc.set(Calendar.MILLISECOND, 0);\n\t\t\t\t}\n\t\t\t\tif(INTERVAL_MULTIPLIER > 1) {\n\t\t\t\t\tint x = gc.get(INTERVAL);\n\t\t\t\t\tgc.set(INTERVAL, (x / INTERVAL_MULTIPLIER) * INTERVAL_MULTIPLIER);\n\t\t\t\t}\n\t\t\t\tfindOldLogFiles((GregorianCalendar)gc.clone());\n\t\t\t\tcurrentFilename = new File(getHourLogName(gc, -1, true));\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif((!logFiles.isEmpty()) && logFiles.getLast().filename.equals(currentFilename)) {\n\t\t\t\t\t\tlogFiles.removeLast();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlogStream = openNewLogFile(currentFilename, true);\n\t\t\t\tif(latestFile != null) {\n\t\t\t\t\taltLogStream = openNewLogFile(latestFile, false);\n\t\t\t\t}\n\t\t\t\tSystem.err.println(\"Created log files\");\n\t\t\t\tstartTime = gc.getTimeInMillis();\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Start time: \"+gc+\" -> \"+startTime);\n\t\t\t\tlastTime = startTime;\n\t\t\t\tgc.add(INTERVAL, INTERVAL_MULTIPLIER);\n\t\t\t\tnextHour = gc.getTimeInMillis();\n\t\t\t}\n\t\t\tlong timeWaitingForSync = -1;\n\t\t\tlong flush;\n\t\t\tsynchronized(this) {\n\t\t\t\tflush = flushTime;\n\t\t\t}\n\t\t\twhile (true) {\n\t\t\t\ttry {\n\t\t\t\t\tthisTime = System.currentTimeMillis();\n\t\t\t\t\tif (baseFilename != null) {\n\t\t\t\t\t\tif ((thisTime > nextHour) || switchedBaseFilename) {\n\t\t\t\t\t\t\tcurrentFilename = rotateLog(currentFilename, lastTime, nextHour, gc);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tgc.add(INTERVAL, INTERVAL_MULTIPLIER);\n\t\t\t\t\t\t\tlastTime = nextHour;\n\t\t\t\t\t\t\tnextHour = gc.getTimeInMillis();\n\n\t\t\t\t\t\t\tif(switchedBaseFilename) {\n\t\t\t\t\t\t\t\tsynchronized(FileLoggerHook.class) {\n\t\t\t\t\t\t\t\t\tswitchedBaseFilename = false;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tboolean died = false;\n\t\t\t\t\tboolean timeoutFlush = false;\n\t\t\t\t\tsynchronized (list) {\n\t\t\t\t\t\tflush = flushTime;\n\t\t\t\t\t\tlong maxWait;\n\t\t\t\t\t\tif(timeWaitingForSync == -1)\n\t\t\t\t\t\t\tmaxWait = Long.MAX_VALUE;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tmaxWait = timeWaitingForSync + flush;\n\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\twhile(o == null) {\n\t\t\t\t\t\t\tif (closed) {\n\t\t\t\t\t\t\t\tdied = true;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif(thisTime < maxWait) {\n\t\t\t\t\t\t\t\t\t// Wait no more than 500ms since the CloserThread might be waiting for closedFinished.\n\t\t\t\t\t\t\t\t\tlist.wait(Math.min(500L, maxWait - thisTime));\n\t\t\t\t\t\t\t\t\tthisTime = System.currentTimeMillis();\n\t\t\t\t\t\t\t\t\tif(listBytes < LIST_WRITE_THRESHOLD) {\n\t\t\t\t\t\t\t\t\t\t// Don't write at all until the lower bytes threshold is exceeded, or the time threshold is.\n\t\t\t\t\t\t\t\t\t\tassert((listBytes == 0) == (list.peek() == null));\n\t\t\t\t\t\t\t\t\t\tif(listBytes != 0 && maxWait == Long.MAX_VALUE)\n\t\t\t\t\t\t\t\t\t\t\tmaxWait = thisTime + flush;\n\t\t\t\t\t\t\t\t\t\tif(closed) // If closing, write stuff ASAP.\n\t\t\t\t\t\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\t\t\t\t\telse if(maxWait != Long.MAX_VALUE) {\n\t\t\t\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t// Do NOT use list.poll(timeout) because it uses a separate lock.\n\t\t\t\t\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t\t\t\t// Ignored.\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(o == null) {\n\t\t\t\t\t\t\t\tif(timeWaitingForSync == -1) {\n\t\t\t\t\t\t\t\t\ttimeWaitingForSync = thisTime;\n\t\t\t\t\t\t\t\t\tmaxWait = thisTime + flush;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif(thisTime >= maxWait) {\n\t\t\t\t\t\t\t\t\ttimeoutFlush = true;\n\t\t\t\t\t\t\t\t\ttimeWaitingForSync = -1; // We have stuff to write, we are no longer waiting.\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} else break;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(o != null) {\n\t\t\t\t\t\t\tlistBytes -= o.length + LINE_OVERHEAD;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif(timeoutFlush || died) {\n\t\t\t\t\t\t// Flush to disk \n\t\t\t\t\t\tmyWrite(logStream, null);\n\t\t\t\t        if(altLogStream != null)\n\t\t\t\t        \tmyWrite(altLogStream, null);\n\t\t\t\t\t}\n\t\t\t\t\tif(died) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tlogStream.close();\n\t\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\t\tSystem.err.println(\"Failed to close log stream: \"+e);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(altLogStream != null) {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\taltLogStream.close();\n\t\t\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\t\t\tSystem.err.println(\"Failed to close compressed log stream: \"+e);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsynchronized(list) {\n\t\t\t\t\t\t\tclosedFinished = true;\n\t\t\t\t\t\t\tlist.notifyAll();\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tif(o == null) continue;\n\t\t\t\t\tmyWrite(logStream,  o);\n\t\t\t        if(altLogStream != null)\n\t\t\t        \tmyWrite(altLogStream, o);\n\t\t\t\t} catch (OutOfMemoryError e) {\n\t\t\t\t\tSystem.err.println(e.getClass());\n\t\t\t\t\tSystem.err.println(e.getMessage());\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t    // FIXME\n\t\t\t\t\t//freenet.node.Main.dumpInterestingObjects();\n\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\tSystem.err.println(\"FileLoggerHook log writer caught \" + t);\n\t\t\t\t\tt.printStackTrace(System.err);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tprivate File rotateLog(File currentFilename, long lastTime, long nextHour, GregorianCalendar gc) {\n\t        // Switch logs\n\t        try {\n\t        \tlogStream.flush();\n\t        \tif(altLogStream != null) altLogStream.flush();\n\t        } catch (IOException e) {\n\t        \tSystem.err.println(\n\t        \t\t\"Flushing on change caught \" + e);\n\t        }\n\t        try {\n\t        \tlogStream.close();\n\t        } catch (IOException e) {\n\t        \tSystem.err.println(\n\t        \t\t\t\"Closing on change caught \" + e);\n\t        }\n\t        long length = currentFilename.length();\n\t        OldLogFile olf = new OldLogFile(currentFilename, lastTime, nextHour, length);\n\t        synchronized(logFiles) {\n\t        \tlogFiles.addLast(olf);\n\t        }\n\t        oldLogFilesDiskSpaceUsage += length;\n\t        trimOldLogFiles();\n\t        // Rotate primary log stream\n\t        currentFilename = new File(getHourLogName(gc, -1, true));\n\t        logStream = openNewLogFile(currentFilename, true);\n\t        if(latestFile != null) {\n\t        \ttry {\n\t        \t\taltLogStream.close();\n\t        \t} catch (IOException e) {\n\t        \t\tSystem.err.println(\n\t        \t\t\t\t\"Closing alt on change caught \" + e);\n\t        \t}\n\t        \tif(previousFile != null && latestFile.exists())\n\t        \t\tFileUtil.renameTo(latestFile, previousFile);\n\t        \tlatestFile.delete();\n\t        \taltLogStream = openNewLogFile(latestFile, false);\n\t        }\n\t        return currentFilename;\n        }\n\n\t\t// Check every minute\n\t\tstatic final int maxSleepTime = 60 * 1000;\n\t\t/**\n\t\t * @param b\n\t\t *            the bytes to write, null to flush\n\t\t */\n\t\tprotected void myWrite(OutputStream os, byte[] b) {\n\t\t\tlong sleepTime = 1000;\n\t\t\twhile (true) {\n\t\t\t\tboolean thrown = false;\n\t\t\t\ttry {\n\t\t\t\t\tif (b != null)\n\t\t\t\t\t\tos.write(b);\n\t\t\t\t\telse\n\t\t\t\t\t\tos.flush();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Exception writing to log: \"\n\t\t\t\t\t\t\t+ e\n\t\t\t\t\t\t\t+ \", sleeping \"\n\t\t\t\t\t\t\t+ sleepTime);\n\t\t\t\t\tthrown = true;\n\t\t\t\t}\n\t\t\t\tif (thrown) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tThread.sleep(sleepTime);\n\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t}\n\t\t\t\t\tsleepTime += sleepTime;\n\t\t\t\t\tif (sleepTime > maxSleepTime)\n\t\t\t\t\t\tsleepTime = maxSleepTime;\n\t\t\t\t} else\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\tprotected OutputStream openNewLogFile(File filename, boolean compress) {\n\t\t\twhile (true) {\n\t\t\t\tlong sleepTime = 1000;\n\t\t\t\ttry {\n\t\t\t\t\tOutputStream o = new FileOutputStream(filename, !logOverwrite);\n\t\t\t\t\tif(compress) {\n\t\t\t\t\t\t// buffer -> gzip -> buffer -> file\n\t\t\t\t\t\to = new BufferedOutputStream(o, 512*1024); // to file\n\t\t\t\t\t\to = new GZIPOutputStream(o);\n\t\t\t\t\t\t// gzip block size is 32kB\n\t\t\t\t\t\to = new BufferedOutputStream(o, 65536); // to gzipper\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// buffer -> file\n\t\t\t\t\t\to = new BufferedOutputStream(o, 512*1024);\n\t\t\t\t\t}\n\t\t\t\t\to.write(BOM);\n\t\t\t\t\treturn o;\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Could not create FOS \" + filename + \": \" + e);\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Sleeping \" + sleepTime / 1000 + \" seconds\");\n\t\t\t\t\ttry {\n\t\t\t\t\t\tThread.sleep(sleepTime);\n\t\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\t}\n\t\t\t\t\tsleepTime += sleepTime;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tprivate static final byte[] BOM;\n\t\n\tstatic {\n\t\ttry {\n\t\t\tBOM = \"\\uFEFF\".getBytes(ENCODING);\n\t\t} catch (UnsupportedEncodingException e) {\n\t\t\tthrow new Error(e);\n\t\t}\n\t}\n\n\tprotected int runningCompressors = 0;\n\tprotected Object runningCompressorsSync = new Object();\n\n\tprivate Date myDate = new Date();\n\n\t/**\n\t * Create a Logger to append to the given file. If the file does not exist\n\t * it will be created.\n\t * \n\t * @param filename\n\t *            the name of the file to log to.\n\t * @param fmt\n\t *            log message format string\n\t * @param dfmt\n\t *            date format string\n\t * @param threshold\n\t *            Lowest logged priority\n\t * @param assumeWorking\n\t *            If false, check whether stderr and stdout are writable and if\n\t *            not, redirect them to the log file\n\t * @exception IOException\n\t *                if the file couldn't be opened for append.\n\t * @throws IntervalParseException \n\t */\n\tpublic FileLoggerHook(\n\t\tString filename,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tString logRotateInterval,\n\t\tLogLevel threshold,\n\t\tboolean assumeWorking,\n\t\tboolean logOverwrite,\n\t\tlong maxOldLogfilesDiskUsage, int maxListSize)\n\t\tthrows IOException, IntervalParseException {\n\t\tthis(\n\t\t\tfalse,\n\t\t\tfilename,\n\t\t\tfmt,\n\t\t\tdfmt,\n\t\t\tlogRotateInterval,\n\t\t\tthreshold,\n\t\t\tassumeWorking,\n\t\t\tlogOverwrite,\n\t\t\tmaxOldLogfilesDiskUsage,\n\t\t\tmaxListSize);\n\t}\n\t\n\tprivate final Object trimOldLogFilesLock = new Object();\n\t\n\tpublic void trimOldLogFiles() {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\twhile(oldLogFilesDiskSpaceUsage > maxOldLogfilesDiskUsage) {\n\t\t\t\tOldLogFile olf;\n\t\t\t\t// TODO: creates a double lock situation, but only here. I think this is okay because the inner lock is only used for trivial things.\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif(logFiles.isEmpty()) {\n\t\t\t\t\t\tSystem.err.println(\"ERROR: INCONSISTENT LOGGER TOTALS: Log file list is empty but still used \"+oldLogFilesDiskSpaceUsage+\" bytes!\");\n\t\t\t\t\t}\n\t\t\t\t\tolf = logFiles.removeFirst();\n\t\t\t\t}\n\t\t\t\tolf.filename.delete();\n\t\t\t\toldLogFilesDiskSpaceUsage -= olf.size;\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Deleting \"+olf.filename+\" - saving \"+olf.size+\n\t\t\t\t\t\t\" bytes, disk usage now: \"+oldLogFilesDiskSpaceUsage+\" of \"+maxOldLogfilesDiskUsage);\n\t\t\t}\n\t\t}\n\t}\n\n\t/** Initialize oldLogFiles */\n\tpublic void findOldLogFiles(GregorianCalendar gc) {\n\t\tgc = (GregorianCalendar) gc.clone();\n\t\tFile currentFilename = new File(getHourLogName(gc, -1, true));\n\t\tSystem.out.println(\"Finding old log files. New log file is \"+currentFilename);\n\t\tFile numericSameDateFilename;\n\t\tint slashIndex = baseFilename.lastIndexOf(File.separatorChar);\n\t\tFile dir;\n\t\tString prefix;\n\t\tif(slashIndex == -1) {\n\t\t\tdir = new File(System.getProperty(\"user.dir\"));\n\t\t\tprefix = baseFilename.toLowerCase();\n\t\t} else {\n\t\t\tdir = new File(baseFilename.substring(0, slashIndex));\n\t\t\tprefix = baseFilename.substring(slashIndex+1).toLowerCase();\n\t\t}\n\t\tFile[] files = dir.listFiles();\n\t\tif(files == null) return;\n\t\tjava.util.Arrays.sort(files);\n\t\tlong lastStartTime = -1;\n\t\tFile oldFile = null;\n        if(latestFile.exists())\n        \tFileUtil.renameTo(latestFile, previousFile);\n\n\t\tfor(File f: files) {\n\t\t\tString name = f.getName();\n\t\t\tif(name.toLowerCase().startsWith(prefix)) {\n\t\t\t\tif(name.equals(previousFile.getName()) || name.equals(latestFile.getName())) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(!name.endsWith(\".log.gz\")) {\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Does not end in .log.gz: \"+name);\n\t\t\t\t\tf.delete();\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\tname = name.substring(0, name.length()-\".log.gz\".length());\n\t\t\t\t}\n\t\t\t\tname = name.substring(prefix.length());\n\t\t\t\tif((name.length() == 0) || (name.charAt(0) != '-')) {\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Deleting unrecognized: \"+name+\" (\"+f.getPath()+ ')');\n\t\t\t\t\tf.delete();\n\t\t\t\t\tcontinue;\n\t\t\t\t} else\n\t\t\t\t\tname = name.substring(1);\n\t\t\t\tString[] tokens = name.split(\"-\");\n\t\t\t\tint[] nums = new int[tokens.length];\n\t\t\t\tfor(int j=0;j<tokens.length;j++) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tnums[j] = Integer.parseInt(tokens[j]);\n\t\t\t\t\t} catch (NumberFormatException e) {\n\t\t\t\t\t\tLogger.normal(this, \"Could not parse: \"+tokens[j]+\" into number from \"+name);\n\t\t\t\t\t\t// Broken\n\t\t\t\t\t\tf.delete();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(nums.length > 1)\n\t\t\t\t\tgc.set(Calendar.YEAR, nums[1]);\n\t\t\t\tif(nums.length > 2)\n\t\t\t\t\tgc.set(Calendar.MONTH, nums[2]-1);\n\t\t\t\tif(nums.length > 3)\n\t\t\t\t\tgc.set(Calendar.DAY_OF_MONTH, nums[3]);\n\t\t\t\tif(nums.length > 4)\n\t\t\t\t\tgc.set(Calendar.HOUR_OF_DAY, nums[4]);\n\t\t\t\tif(nums.length > 5)\n\t\t\t\t\tgc.set(Calendar.MINUTE, nums[5]);\n\t\t\t\tgc.set(Calendar.SECOND, 0);\n\t\t\t\tgc.set(Calendar.MILLISECOND, 0);\n\t\t\t\tlong startTime = gc.getTimeInMillis();\n\t\t\t\tif(oldFile != null) {\n\t\t\t\t\tlong l = oldFile.length();\n\t\t\t\t\tOldLogFile olf = new OldLogFile(oldFile, lastStartTime, startTime, l);\n\t\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\t\tlogFiles.addLast(olf);\n\t\t\t\t\t}\n\t\t\t\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\t\t\t\toldLogFilesDiskSpaceUsage += l;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlastStartTime = startTime;\n\t\t\t\toldFile = f;\n\t\t\t} else {\n\t\t\t\t// Nothing to do with us\n\t\t\t\tLogger.normal(this, \"Unknown file: \"+name+\" in the log directory\");\n\t\t\t}\n\t\t}\n\t\t//If a compressed log file already exists for a given date,\n\t\t//add a number to the end of the file that already exists\n\t\tif(currentFilename != null && currentFilename.exists()) {\n\t\t\tSystem.out.println(\"Old log file exists for this time period: \"+currentFilename);\n\t\t\tfor(int a = 1;; a++){\n\t\t\t\tnumericSameDateFilename = new File(getHourLogName(gc, a, true));\n\t\t\t\tif(numericSameDateFilename == null || !numericSameDateFilename.exists()) {\n\t\t\t\t\tif(numericSameDateFilename != null) {\n\t\t\t\t\t\tSystem.out.println(\"Renaming to: \"+numericSameDateFilename);\n\t\t\t\t\t\tFileUtil.renameTo(currentFilename, numericSameDateFilename);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(oldFile != null) {\n\t\t\tlong l = oldFile.length();\n\t\t\tOldLogFile olf = new OldLogFile(oldFile, lastStartTime, System.currentTimeMillis(), l);\n\t\t\tsynchronized(logFiles) {\n\t\t\t\tlogFiles.addLast(olf);\n\t\t\t}\n\t\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\t\toldLogFilesDiskSpaceUsage += l;\n\t\t\t}\n\t\t}\n\t\ttrimOldLogFiles();\n\t}\n\n\tpublic FileLoggerHook(\n\t\t\tString filename,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold,\n\t\t\tString logRotateInterval,\n\t\t\tboolean assumeWorking,\n\t\t\tboolean logOverwrite,\n\t\t\tlong maxOldLogFilesDiskUsage,\n\t\t\tint maxListSize)\n\t\t\tthrows IOException, InvalidThresholdException, IntervalParseException {\n\t\t\tthis(filename,\n\t\t\t\tfmt,\n\t\t\t\tdfmt,\n\t\t\t\tlogRotateInterval,\n\t\t\t\tLogLevel.valueOf(threshold.toUpperCase()),\n\t\t\t\tassumeWorking,\n\t\t\t\tlogOverwrite,\n\t\t\t\tmaxOldLogFilesDiskUsage,\n\t\t\t\tmaxListSize);\n\t\t}\n\n\tprivate void checkStdStreams() {\n\t\t// Redirect System.err and System.out to the Logger Printstream\n\t\t// if they don't exist (like when running under javaw)\n\t\tSystem.out.print(\" \\b\");\n\t\tif (System.out.checkError()) {\n\t\t\tredirectStdOut = true;\n\t\t}\n\t\tSystem.err.print(\" \\b\");\n\t\tif (System.err.checkError()) {\n\t\t\tredirectStdErr = true;\n\t\t}\n\t}\n\n\tpublic FileLoggerHook(\n\t\tOutputStream os,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tLogLevel threshold) throws IntervalParseException {\n\t\tthis(os, fmt, dfmt, threshold, true);\n\t\tlogStream = os;\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\t\tOutputStream os,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold) throws InvalidThresholdException, IntervalParseException {\n\t\t\tthis(os, fmt, dfmt, LogLevel.valueOf(threshold.toUpperCase()), true);\n\t\t\tlogStream = os;\n\t\t}\n\n\t/**\n\t * Create a Logger to send log output to the given PrintStream.\n\t * \n\t * @param stream\n\t *            the PrintStream to send log output to.\n\t * @param fmt\n\t *            log message format string\n\t * @param dfmt\n\t *            date format string\n\t * @param threshold\n\t *            Lowest logged priority\n\t * @throws IntervalParseException \n\t */\n\tpublic FileLoggerHook(\n\t\tOutputStream stream,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tLogLevel threshold,\n\t\tboolean overwrite) throws IntervalParseException {\n\t\tthis(fmt, dfmt, threshold, \"HOUR\", overwrite, -1, 10000);\n\t\tlogStream = stream;\n\t}\n\n\tpublic void start() {\n\t\tif(redirectStdOut) {\n\t\t\ttry {\n\t\t\t\tSystem.setOut(new PrintStream(new OutputStreamLogger(LogLevel.NORMAL, \"Stdout: \", ENCODING), false, ENCODING));\n\t\t\t\tif(redirectStdErr)\n\t\t\t\t\tSystem.setErr(new PrintStream(new OutputStreamLogger(LogLevel.ERROR, \"Stderr: \", ENCODING), false, ENCODING));\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new Error(e);\n\t\t\t}\n\t\t}\n\t\tWriterThread wt = new WriterThread();\n\t\twt.setDaemon(true);\n\t\tCloserThread ct = new CloserThread();\n\t\tSemiOrderedShutdownHook.get().addLateJob(ct);\n\t\twt.start();\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\tboolean rotate,\n\t\tString baseFilename,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tString logRotateInterval,\n\t\tLogLevel threshold,\n\t\tboolean assumeWorking,\n\t\tboolean logOverwrite,\n\t\tlong maxOldLogfilesDiskUsage, int maxListSize)\n\t\tthrows IOException, IntervalParseException {\n\t\tthis(fmt, dfmt, threshold, logRotateInterval, logOverwrite, maxOldLogfilesDiskUsage, maxListSize);\n\t\t//System.err.println(\"Creating FileLoggerHook with threshold\n\t\t// \"+threshold);\n\t\tif (!assumeWorking)\n\t\t\tcheckStdStreams();\n\t\tif (rotate) {\n\t\t\tthis.baseFilename = baseFilename;\n\t\t} else {\n\t\t\tlogStream = new BufferedOutputStream(new FileOutputStream(baseFilename, !logOverwrite), 65536);\n\t\t}\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\t\tboolean rotate,\n\t\t\tString baseFilename,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold,\n\t\t\tString logRotateInterval,\n\t\t\tboolean assumeWorking,\n\t\t\tboolean logOverwrite,\n\t\t\tlong maxOldLogFilesDiskUsage, int maxListSize) throws IOException, InvalidThresholdException, IntervalParseException{\n\t\tthis(rotate,baseFilename,fmt,dfmt,logRotateInterval,LogLevel.valueOf(threshold.toUpperCase()),assumeWorking,logOverwrite,maxOldLogFilesDiskUsage,maxListSize);\n\t}\n\n\tprivate FileLoggerHook(String fmt, String dfmt, LogLevel threshold, String logRotateInterval, boolean overwrite, long maxOldLogfilesDiskUsage, int maxListSize) throws IntervalParseException {\n\t\tsuper(threshold);\n\t\tthis.maxOldLogfilesDiskUsage = maxOldLogfilesDiskUsage;\n\t\tthis.logOverwrite = overwrite;\n\t\tsetInterval(logRotateInterval);\n\t\t\n\t\tMAX_LIST_SIZE = maxListSize;\n\t\tlist = new ArrayBlockingQueue<byte[]>(MAX_LIST_SIZE);\n\t\t\n\t\tsetDateFormat(dfmt);\n\t\tsetLogFormat(fmt);\n\t}\n\n\tprivate void setLogFormat(String fmt) {\n\t\tif ((fmt == null) || (fmt.length() == 0))\n\t\t\tfmt = \"d:c:h:t:p:m\";\n\t\tchar[] f = fmt.toCharArray();\n\n\t\tArrayList<Integer> fmtVec = new ArrayList<Integer>();\n\t\tArrayList<String> strVec = new ArrayList<String>();\n\n\t\tStringBuilder sb = new StringBuilder();\n\n\t\tboolean comment = false;\n\t\tfor (char fi: f) {\n\t\t\tint type = numberOf(fi);\n\t\t\tif(type == UNAME)\n\t\t\t\tgetUName();\n\t\t\tif (!comment && (type != 0)) {\n\t\t\t\tif (sb.length() > 0) {\n\t\t\t\t\tstrVec.add(sb.toString());\n\t\t\t\t\tfmtVec.add(0);\n\t\t\t\t\tsb = new StringBuilder();\n\t\t\t\t}\n\t\t\t\tfmtVec.add(type);\n\t\t\t} else if (fi == '\\\\') {\n\t\t\t\tcomment = true;\n\t\t\t} else {\n\t\t\t\tcomment = false;\n\t\t\t\tsb.append(fi);\n\t\t\t}\n\t\t}\n\t\tif (sb.length() > 0) {\n\t\t\tstrVec.add(sb.toString());\n\t\t\tfmtVec.add(0);\n\t\t}\n\n\t\tthis.fmt = new int[fmtVec.size()];\n\t\tint size = fmtVec.size();\n\t\tfor (int i = 0; i < size; ++i)\n\t\t\tthis.fmt[i] = fmtVec.get(i);\n\n\t\tthis.str = new String[strVec.size()];\n\t\tstr = strVec.toArray(str);\n\t}\n\n\tprivate void setDateFormat(String dfmt) {\n\t\tif ((dfmt != null) && (dfmt.length() != 0)) {\n\t\t\ttry {\n\t\t\t\tdf = new SimpleDateFormat(dfmt);\n\t\t\t} catch (RuntimeException e) {\n\t\t\t\tdf = DateFormat.getDateTimeInstance();\n\t\t\t}\n\t\t} else\n\t\t\tdf = DateFormat.getDateTimeInstance();\n\n\t\tdf.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n\t}\n\n\t@Override\n\tpublic void log(Object o, Class<?> c, String msg, Throwable e, LogLevel priority) {\n\t\tif (!instanceShouldLog(priority, c))\n\t\t\treturn;\n\n\t\tif (closed)\n\t\t\treturn;\n\t\t\n\t\tStringBuilder sb = new StringBuilder( e == null ? 512 : 1024 );\n\t\tint sctr = 0;\n\n\t\tfor (int f: fmt) {\n\t\t\tswitch (f) {\n\t\t\t\tcase 0 :\n\t\t\t\t\tsb.append(str[sctr++]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase DATE :\n\t\t\t\t\tlong now = System.currentTimeMillis();\n\t\t\t\t\tsynchronized (this) {\n\t\t\t\t\t\tmyDate.setTime(now);\n\t\t\t\t\t\tsb.append(df.format(myDate));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase CLASS :\n\t\t\t\t\tsb.append(c == null ? \"<none>\" : c.getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase HASHCODE :\n\t\t\t\t\tsb.append(\n\t\t\t\t\t\to == null\n\t\t\t\t\t\t\t? \"<none>\"\n\t\t\t\t\t\t\t: Integer.toHexString(o.hashCode()));\n\t\t\t\t\tbreak;\n\t\t\t\tcase THREAD :\n\t\t\t\t\tsb.append(Thread.currentThread().getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase PRIORITY :\n\t\t\t\t\tsb.append(priority.name());\n\t\t\t\t\tbreak;\n\t\t\t\tcase MESSAGE :\n\t\t\t\t\tsb.append(msg);\n\t\t\t\t\tbreak;\n\t\t\t\tcase UNAME :\n\t\t\t\t\tsb.append(uname);\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tsb.append('\\n');\n\n\t\t// Write stacktrace if available\n\t\tfor(int j=0;j<20 && e != null;j++) {\n\t\t\tsb.append(e.toString());\n\t\t\t\n\t\t\tStackTraceElement[] trace = e.getStackTrace();\n\t\t\t\n\t\t\tif(trace == null)\n\t\t\t\tsb.append(\"(null)\\n\");\n\t\t\telse if(trace.length == 0)\n\t\t\t\tsb.append(\"(no stack trace)\\n\");\n\t\t\telse {\n\t\t\t\tsb.append('\\n');\n\t\t\t\tfor(StackTraceElement elt: trace) {\n\t\t\t\t\tsb.append(\"\\tat \");\n\t\t\t\t\tsb.append(elt.toString());\n\t\t\t\t\tsb.append('\\n');\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tThrowable cause = e.getCause();\n\t\t\tif(cause != e) e = cause;\n\t\t\telse break;\n\t\t}\n\n\t\ttry {\n\t\t\tlogString(sb.toString().getBytes(ENCODING));\n\t\t} catch (UnsupportedEncodingException e1) {\n\t\t\tthrow new Error(e1);\n\t\t}\n\t}\n\n\t/** Memory allocation overhead (estimated through experimentation with bsh) */\n\tprivate static final int LINE_OVERHEAD = 60;\n\t\n\tpublic void logString(byte[] b) throws UnsupportedEncodingException {\n\t\tsynchronized (list) {\n\t\t\tint sz = list.size();\n\t\t\tif(!list.offer(b)) {\n\t\t\t\tbyte[] ss = list.poll();\n\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\tss = list.poll();\n\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\tString err =\n\t\t\t\t\t\"GRRR: ERROR: Logging too fast, chopped \"\n\t\t\t\t\t\t+ 2\n\t\t\t\t\t\t+ \" entries, \"\n\t\t\t\t\t\t+ listBytes\n\t\t\t\t\t\t+ \" bytes in memory\\n\";\n\t\t\t\tbyte[] buf = err.getBytes(ENCODING);\n\t\t\t\tif(list.offer(buf))\n\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t\tif(list.offer(b))\n\t\t\t\t\tlistBytes += (b.length + LINE_OVERHEAD);\n\t\t\t} else\n\t\t\t\tlistBytes += (b.length + LINE_OVERHEAD);\n\t\t\tint x = 0;\n\t\t\tif (listBytes > MAX_LIST_BYTES) {\n\t\t\t\twhile ((list.size() > (MAX_LIST_SIZE * 0.9F))\n\t\t\t\t\t|| (listBytes > (MAX_LIST_BYTES * 0.9F))) {\n\t\t\t\t\tbyte[] ss;\n\t\t\t\t\tss = list.poll();\n\t\t\t\t\tlistBytes -= (ss.length + LINE_OVERHEAD);\n\t\t\t\t\tx++;\n\t\t\t\t}\n\t\t\t\tString err =\n\t\t\t\t\t\"GRRR: ERROR: Logging too fast, chopped \"\n\t\t\t\t\t\t+ x\n\t\t\t\t\t\t+ \" entries, \"\n\t\t\t\t\t\t+ listBytes\n\t\t\t\t\t\t+ \" bytes in memory\\n\";\n\t\t\t\tbyte[] buf = err.getBytes(ENCODING);\n\t\t\t\tif(!list.offer(buf)) {\n\t\t\t\t\tbyte[] ss = list.poll();\n\t\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\t\tif(list.offer(buf))\n\t\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t\t} else\n\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t}\n\t\t\tif (sz == 0)\n\t\t\t\tlist.notifyAll();\n\t\t}\n\t}\n\n\tpublic long listBytes() {\n\t\tsynchronized (list) {\n\t\t\treturn listBytes;\n\t\t}\n\t}\n\n\tpublic static int numberOf(char c) {\n\t\tswitch (c) {\n\t\t\tcase 'd' :\n\t\t\t\treturn DATE;\n\t\t\tcase 'c' :\n\t\t\t\treturn CLASS;\n\t\t\tcase 'h' :\n\t\t\t\treturn HASHCODE;\n\t\t\tcase 't' :\n\t\t\t\treturn THREAD;\n\t\t\tcase 'p' :\n\t\t\t\treturn PRIORITY;\n\t\t\tcase 'm' :\n\t\t\t\treturn MESSAGE;\n\t\t\tcase 'u' :\n\t\t\t\treturn UNAME;\n\t\t\tdefault :\n\t\t\t\treturn 0;\n\t\t}\n\t}\n\n\t@Override\n\tpublic void close() {\n\t\tclosed = true;\n\t}\n\n\tclass CloserThread extends Thread {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tsynchronized(list) {\n\t\t\t\tclosed = true;\n\t\t\t\tlong deadline = System.currentTimeMillis() + SECONDS.toMillis(10);\n\t\t\t\twhile(!closedFinished) {\n\t\t\t\t\tint wait = (int) (deadline - System.currentTimeMillis());\n\t\t\t\t\tif(wait <= 0) return;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tlist.wait(wait);\n\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t\t// Ok.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tSystem.out.println(\"Completed writing logs to disk.\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Print a human- and script- readable list of available log files.\n\t * @throws IOException \n\t */\n\tpublic void listAvailableLogs(OutputStreamWriter writer) throws IOException {\n\t\tOldLogFile[] oldLogFiles;\n\t\tsynchronized(logFiles) {\n\t\t\toldLogFiles = logFiles.toArray(new OldLogFile[logFiles.size()]);\n\t\t}\n\t\tDateFormat tempDF = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT, Locale.ENGLISH);\n\t\ttempDF.setTimeZone(TimeZone.getTimeZone(\"GMT\"));\n\t\tfor(OldLogFile olf: oldLogFiles) {\n\t\t\twriter.write(olf.filename.getName()+\" : \"+tempDF.format(new Date(olf.start))+\" to \"+tempDF.format(new Date(olf.end))+ \" - \"+olf.size+\" bytes\\n\");\n\t\t}\n\t}\n\n\tpublic void sendLogByContainedDate(long time, OutputStream os) throws IOException {\n\t\tOldLogFile toReturn = null;\n\t\tsynchronized(logFiles) {\n\t\t\tfor(OldLogFile olf : logFiles) {\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Checking \"+time+\" against \"+olf.filename+\" : start=\"+olf.start+\", end=\"+olf.end);\n\t\t\t\tif((time >= olf.start) && (time < olf.end)) {\n\t\t\t\t\ttoReturn = olf;\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Found \"+olf);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(toReturn == null)\n\t\t\t\treturn; // couldn't find it\n\t\t}\n\t\tFileInputStream fis = new FileInputStream(toReturn.filename);\n\t\tDataInputStream dis = new DataInputStream(fis);\n\t\tlong written = 0;\n\t\tlong size = toReturn.size;\n\t\tbyte[] buf = new byte[4096];\n\t\twhile(written < size) {\n\t\t\tint toRead = (int) Math.min(buf.length, (size - written));\n\t\t\ttry {\n\t\t\t\tdis.readFully(buf, 0, toRead);\n\t\t\t} catch (IOException e) {\n\t\t\t\tLogger.error(this, \"Could not read bytes \"+written+\" to \"+(written + toRead)+\" from file \"+toReturn.filename+\" which is supposed to be \"+size+\" bytes (\"+toReturn.filename.length()+ ')');\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tos.write(buf, 0, toRead);\n\t\t\twritten += toRead;\n\t\t}\n\t\tdis.close();\n\t\tfis.close();\n\t}\n\n\t/** Set the maximum size of old (gzipped) log files to keep.\n\t * Will start to prune old files immediately, but this will likely not be completed\n\t * by the time the function returns as it is run off-thread.\n\t */\n\tpublic void setMaxOldLogsSize(long val) {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\tmaxOldLogfilesDiskUsage = val;\n\t\t}\n\t\tRunnable r = new Runnable() {\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttrimOldLogFiles();\n\t\t\t}\n\t\t};\n\t\tThread t = new Thread(r, \"Shrink logs\");\n\t\tt.setDaemon(true);\n\t\tt.start();\n\t}\n\n\tprivate boolean switchedBaseFilename;\n\t\n\tpublic void switchBaseFilename(String filename) {\n\t\tsynchronized(this) {\n\t\t\tthis.baseFilename = filename;\n\t\t\tswitchedBaseFilename = true;\n\t\t}\n\t}\n\n\tpublic void waitForSwitch() {\n\t\tlong now = System.currentTimeMillis();\n\t\tsynchronized(this) {\n\t\t\tif(!switchedBaseFilename) return;\n\t\t\tlong startTime = now;\n\t\t\tlong endTime = startTime + 10000;\n\t\t\twhile(((now = System.currentTimeMillis()) < endTime) && !switchedBaseFilename) {\n\t\t\t\ttry {\n\t\t\t\t\twait(Math.max(1, endTime-now));\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t// Ignore\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void deleteAllOldLogFiles() {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\twhile(true) {\n\t\t\t\tOldLogFile olf;\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif(logFiles.isEmpty()) return;\n\t\t\t\t\tolf = logFiles.removeFirst();\n\t\t\t\t}\n\t\t\t\tolf.filename.delete();\n\t\t\t\toldLogFilesDiskSpaceUsage -= olf.size;\n\t\t\t\tif(logMINOR)\n\t\t\t\t\tLogger.minor(this, \"Deleting \"+olf.filename+\" - saving \"+olf.size+\n\t\t\t\t\t\t\t\" bytes, disk usage now: \"+oldLogFilesDiskSpaceUsage+\" of \"+maxOldLogfilesDiskUsage);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * This is used by the lost-lock deadlock detector so MUST NOT TAKE A LOCK ever!\n\t */\n\tpublic boolean hasRedirectedStdOutErrNoLock() {\n\t\treturn redirectStdOut || redirectStdErr;\n\t}\n\n\tpublic synchronized void setMaxBacklogNotBusy(long val) {\n\t\tflushTime = val;\n\t}\n}\n","Method after Refactoring":"package freenet.support;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\nimport java.io.BufferedOutputStream;\nimport java.io.Closeable;\nimport java.io.DataInputStream;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.OutputStreamWriter;\nimport java.io.PrintStream;\nimport java.io.UnsupportedEncodingException;\nimport java.net.InetAddress;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\nimport java.text.DateFormat;\nimport java.text.SimpleDateFormat;\nimport java.util.ArrayList;\nimport java.util.ArrayDeque;\nimport java.util.Calendar;\nimport java.util.Date;\nimport java.util.Deque;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.StringTokenizer;\nimport java.util.TimeZone;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.zip.GZIPOutputStream;\n\nimport freenet.node.SemiOrderedShutdownHook;\nimport freenet.node.Version;\nimport freenet.support.io.FileUtil;\n\n/**\n * Converted the old StandardLogger to Ian's loggerhook interface.\n * \n * @author oskar\n */\npublic class FileLoggerHook extends LoggerHook implements Closeable {\n\n\t/** Verbosity types */\n\tpublic static final int DATE = 1,\n\t\tCLASS = 2,\n\t\tHASHCODE = 3,\n\t\tTHREAD = 4,\n\t\tPRIORITY = 5,\n\t\tMESSAGE = 6,\n\t\tUNAME = 7;\n\n\tprivate volatile boolean closed = false;\n\tprivate boolean closedFinished = false;\n\n\tprotected int INTERVAL = Calendar.MINUTE;\n\tprotected int INTERVAL_MULTIPLIER = 5;\n\t\n\tprivate static final Charset ENCODING = StandardCharsets.UTF_8;\n\n        private static volatile boolean logMINOR;\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t/** Name of the local host (called uname in Unix-like operating systems). */\n\tprivate static String uname;\n\tstatic {\n\t\tuname = \"unknown\";\n\t}\n\n\tstatic synchronized void getUName() {\n\t\tif(!uname.equals(\"unknown\")) return;\n\t\tSystem.out.println(\"Getting uname for logging\");\n\t\ttry {\n\t\t\tInetAddress addr = InetAddress.getLocalHost();\n\t\t\tif (addr != null) {\n\t\t\t\tuname =\n\t\t\t\t\tnew StringTokenizer(addr.getHostName(), \".\").nextToken();\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\t// Ignored.\n\t\t}\n\t}\n\t\n\tprivate DateFormat df;\n\tprivate int[] fmt;\n\tprivate String[] str;\n\n\t/** Stream to write data to (compressed if rotate is on) */\n\tprotected OutputStream logStream;\n\t/** Other stream to write data to (may be null) */\n\tprotected OutputStream altLogStream;\n\n\tprotected final boolean logOverwrite;\n\n\t/* Base filename for rotating logs */\n\tprotected String baseFilename = null;\n\t\n\tprotected File latestFile;\n\tprotected File previousFile;\n\n\t/* Whether to redirect stdout */\n\tprotected boolean redirectStdOut = false;\n\t/* Whether to redirect stderr */\n\tprotected boolean redirectStdErr = false;\n\n\tprotected final int MAX_LIST_SIZE;\n\tprotected long MAX_LIST_BYTES = 10 * (1 << 20);\n\tprotected long LIST_WRITE_THRESHOLD;\n\n\t/**\n\t * Something weird happens when the disk gets full, also we don't want to\n\t * block So run the actual write on another thread\n\t * \n\t * Unfortunately, we can't use ConcurrentBlockingQueue because we need to dump stuff when the queue gets\n\t * too big.\n\t * \n\t * FIXME PERFORMANCE: Using an ArrayBlockingQueue avoids some unnecessary memory allocations, but it \n\t * means we have to take two locks. \n\t * Seriously consider reverting 88268b99856919df0d42c2787d9ea3674a9f6f0d..e359b4005ef728a159fdee988c483de8ce8f3f6b\n\t * to go back to one lock and a LinkedList.\n\t */\n\tprotected final ArrayBlockingQueue<byte[]> list;\n\tprotected long listBytes = 0;\n\n\tlong maxOldLogfilesDiskUsage;\n\tprotected final Deque<OldLogFile> logFiles = new ArrayDeque<OldLogFile>();\n\tprivate long oldLogFilesDiskSpaceUsage = 0;\n\n\tprivate static class OldLogFile {\n\t\tpublic OldLogFile(File currentFilename, long startTime, long endTime, long length) {\n\t\t\tthis.filename = currentFilename;\n\t\t\tthis.start = startTime;\n\t\t\tthis.end = endTime;\n\t\t\tthis.size = length;\n\t\t}\n\t\tfinal File filename;\n\t\tfinal long start; // inclusive\n\t\tfinal long end; // exclusive\n\t\tfinal long size;\n\t}\n\t\n\tpublic void setMaxListBytes(long len) {\n\t\tsynchronized(list) {\n\t\t\tMAX_LIST_BYTES = len;\n\t\t\tLIST_WRITE_THRESHOLD = MAX_LIST_BYTES / 4;\n\t\t}\n\t}\n\n\tpublic void setInterval(String intervalName) throws IntervalParseException {\n\t\tStringBuilder sb = new StringBuilder(intervalName.length());\n\t\tfor(int i=0;i<intervalName.length();i++) {\n\t\t\tchar c = intervalName.charAt(i);\n\t\t\tif(!Character.isDigit(c)) break;\n\t\t\tsb.append(c);\n\t\t}\n\t\tif(sb.length() > 0) {\n\t\t\tString prefix = sb.toString();\n\t\t\tintervalName = intervalName.substring(prefix.length());\n\t\t\tINTERVAL_MULTIPLIER = Integer.parseInt(prefix);\n\t\t} else {\n\t\t\tINTERVAL_MULTIPLIER = 1;\n\t\t}\n\t\tif (intervalName.endsWith(\"S\")) {\n\t\t\tintervalName = intervalName.substring(0, intervalName.length()-1);\n\t\t}\n\t\tif (intervalName.equalsIgnoreCase(\"MINUTE\"))\n\t\t\tINTERVAL = Calendar.MINUTE;\n\t\telse if (intervalName.equalsIgnoreCase(\"HOUR\"))\n\t\t\tINTERVAL = Calendar.HOUR;\n\t\telse if (intervalName.equalsIgnoreCase(\"DAY\"))\n\t\t\tINTERVAL = Calendar.DAY_OF_MONTH;\n\t\telse if (intervalName.equalsIgnoreCase(\"WEEK\"))\n\t\t\tINTERVAL = Calendar.WEEK_OF_YEAR;\n\t\telse if (intervalName.equalsIgnoreCase(\"MONTH\"))\n\t\t\tINTERVAL = Calendar.MONTH;\n\t\telse if (intervalName.equalsIgnoreCase(\"YEAR\"))\n\t\t\tINTERVAL = Calendar.YEAR;\n\t\telse\n\t\t\tthrow new IntervalParseException(\"invalid interval \" + intervalName);\n\t\tSystem.out.println(\"Set interval to \"+INTERVAL+\" and multiplier to \"+INTERVAL_MULTIPLIER);\n\t}\n\n\tpublic static class IntervalParseException extends Exception {\n\n\t\tprivate static final long serialVersionUID = 69847854744673572L;\n\n\t\tpublic IntervalParseException(String string) {\n\t\t\tsuper(string);\n\t\t}\n\n\t}\n\t\n\t/**\n\t * The extra parameter int digit is to be used for creating a logfile name\n\t * when a log exists already with the same date.\n\t * @param c\n\t * @param digit\n\t *\t\t\tlog file name suffix. ignored if this is {@code < 0}\n\t * @param compressed\n\t * @return\n\t */\n\tprotected String getHourLogName(Calendar c, int digit, boolean compressed){\n\t\tStringBuilder buf = new StringBuilder(50);\n\t\tbuf.append(baseFilename).append('-');\n\t\tbuf.append(Version.buildNumber());\n\t\tbuf.append('-');\n\t\tbuf.append(c.get(Calendar.YEAR)).append('-');\n\t\tpad2digits(buf, c.get(Calendar.MONTH) + 1);\n\t\tbuf.append('-');\n\t\tpad2digits(buf, c.get(Calendar.DAY_OF_MONTH));\n\t\tbuf.append('-');\n\t\tpad2digits(buf, c.get(Calendar.HOUR_OF_DAY));\n\t\tif (INTERVAL == Calendar.MINUTE) {\n\t\t\tbuf.append('-');\n\t\t\tpad2digits(buf, c.get(Calendar.MINUTE));\n\t\t}\n\t\tif (digit > 0) {\n\t\t\tbuf.append(\"-\");\n\t\t\tbuf.append(digit);\n\t\t}\n\t\tbuf.append(\".log\");\n\t\tif(compressed) buf.append(\".gz\");\n\t\treturn buf.toString();\n\t}\n\n\tprivate StringBuilder pad2digits(StringBuilder buf, int x) {\n\t\tString s = Integer.toString(x);\n\t\tif (s.length() == 1) {\n\t\t\tbuf.append('0');\n\t\t}\n\t\tbuf.append(s);\n\t\treturn buf;\n\t}\n\t\n\t// Unless we are writing flat out, everything will hit disk within this period.\n\tprivate long flushTime = 1000; // Default is 1 second. Will be set by setMaxBacklogNotBusy().\n\n\tclass WriterThread extends Thread {\n\t\tWriterThread() {\n\t\t\tsuper(\"Log File Writer Thread\");\n\t\t}\n\n\t\t@Override\n\t\t@SuppressWarnings(\"fallthrough\")\n\t\tpublic void run() {\n\t\t\tFile currentFilename = null;\n\t\t\tbyte[] o = null;\n\t\t\tlong thisTime;\n\t\t\tlong lastTime = -1;\n\t\t\tlong startTime;\n\t\t\tlong nextHour = -1;\n\t\t\tGregorianCalendar gc = null;\n\t\t\tif (baseFilename != null) {\n\t\t\t\tlatestFile = new File(baseFilename+\"-latest.log\");\n\t\t\t\tpreviousFile = new File(baseFilename+\"-previous.log\");\n\t\t\t\tgc = new GregorianCalendar();\n\t\t\t\tswitch (INTERVAL) {\n\t\t\t\t\tcase Calendar.YEAR :\n\t\t\t\t\t\tgc.set(Calendar.MONTH, 0);\n\t\t\t\t\tcase Calendar.MONTH :\n\t\t\t\t\t\tgc.set(Calendar.DAY_OF_MONTH, 0);\n\t\t\t\t\tcase Calendar.WEEK_OF_YEAR :\n\t\t\t\t\t\tif (INTERVAL == Calendar.WEEK_OF_YEAR)\n\t\t\t\t\t\t\tgc.set(Calendar.DAY_OF_WEEK, 0);\n\t\t\t\t\tcase Calendar.DAY_OF_MONTH :\n\t\t\t\t\t\tgc.set(Calendar.HOUR, 0);\n\t\t\t\t\tcase Calendar.HOUR :\n\t\t\t\t\t\tgc.set(Calendar.MINUTE, 0);\n\t\t\t\t\tcase Calendar.MINUTE :\n\t\t\t\t\t\tgc.set(Calendar.SECOND, 0);\n\t\t\t\t\t\tgc.set(Calendar.MILLISECOND, 0);\n\t\t\t\t}\n\t\t\t\tif(INTERVAL_MULTIPLIER > 1) {\n\t\t\t\t\tint x = gc.get(INTERVAL);\n\t\t\t\t\tgc.set(INTERVAL, (x / INTERVAL_MULTIPLIER) * INTERVAL_MULTIPLIER);\n\t\t\t\t}\n\t\t\t\tfindOldLogFiles((GregorianCalendar)gc.clone());\n\t\t\t\tcurrentFilename = new File(getHourLogName(gc, -1, true));\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif((!logFiles.isEmpty()) && logFiles.getLast().filename.equals(currentFilename)) {\n\t\t\t\t\t\tlogFiles.removeLast();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlogStream = openNewLogFile(currentFilename, true);\n\t\t\t\tif(latestFile != null) {\n\t\t\t\t\taltLogStream = openNewLogFile(latestFile, false);\n\t\t\t\t}\n\t\t\t\tSystem.err.println(\"Created log files\");\n\t\t\t\tstartTime = gc.getTimeInMillis();\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Start time: \"+gc+\" -> \"+startTime);\n\t\t\t\tlastTime = startTime;\n\t\t\t\tgc.add(INTERVAL, INTERVAL_MULTIPLIER);\n\t\t\t\tnextHour = gc.getTimeInMillis();\n\t\t\t}\n\t\t\tlong timeWaitingForSync = -1;\n\t\t\tlong flush;\n\t\t\tsynchronized(this) {\n\t\t\t\tflush = flushTime;\n\t\t\t}\n\t\t\twhile (true) {\n\t\t\t\ttry {\n\t\t\t\t\tthisTime = System.currentTimeMillis();\n\t\t\t\t\tif (baseFilename != null) {\n\t\t\t\t\t\tif ((thisTime > nextHour) || switchedBaseFilename) {\n\t\t\t\t\t\t\tcurrentFilename = rotateLog(currentFilename, lastTime, nextHour, gc);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tgc.add(INTERVAL, INTERVAL_MULTIPLIER);\n\t\t\t\t\t\t\tlastTime = nextHour;\n\t\t\t\t\t\t\tnextHour = gc.getTimeInMillis();\n\n\t\t\t\t\t\t\tif(switchedBaseFilename) {\n\t\t\t\t\t\t\t\tsynchronized(FileLoggerHook.class) {\n\t\t\t\t\t\t\t\t\tswitchedBaseFilename = false;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tboolean died = false;\n\t\t\t\t\tboolean timeoutFlush = false;\n\t\t\t\t\tsynchronized (list) {\n\t\t\t\t\t\tflush = flushTime;\n\t\t\t\t\t\tlong maxWait;\n\t\t\t\t\t\tif(timeWaitingForSync == -1)\n\t\t\t\t\t\t\tmaxWait = Long.MAX_VALUE;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tmaxWait = timeWaitingForSync + flush;\n\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\twhile(o == null) {\n\t\t\t\t\t\t\tif (closed) {\n\t\t\t\t\t\t\t\tdied = true;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif(thisTime < maxWait) {\n\t\t\t\t\t\t\t\t\t// Wait no more than 500ms since the CloserThread might be waiting for closedFinished.\n\t\t\t\t\t\t\t\t\tlist.wait(Math.min(500L, maxWait - thisTime));\n\t\t\t\t\t\t\t\t\tthisTime = System.currentTimeMillis();\n\t\t\t\t\t\t\t\t\tif(listBytes < LIST_WRITE_THRESHOLD) {\n\t\t\t\t\t\t\t\t\t\t// Don't write at all until the lower bytes threshold is exceeded, or the time threshold is.\n\t\t\t\t\t\t\t\t\t\tassert((listBytes == 0) == (list.peek() == null));\n\t\t\t\t\t\t\t\t\t\tif(listBytes != 0 && maxWait == Long.MAX_VALUE)\n\t\t\t\t\t\t\t\t\t\t\tmaxWait = thisTime + flush;\n\t\t\t\t\t\t\t\t\t\tif(closed) // If closing, write stuff ASAP.\n\t\t\t\t\t\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\t\t\t\t\telse if(maxWait != Long.MAX_VALUE) {\n\t\t\t\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t// Do NOT use list.poll(timeout) because it uses a separate lock.\n\t\t\t\t\t\t\t\t\t\to = list.poll();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t\t\t\t// Ignored.\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(o == null) {\n\t\t\t\t\t\t\t\tif(timeWaitingForSync == -1) {\n\t\t\t\t\t\t\t\t\ttimeWaitingForSync = thisTime;\n\t\t\t\t\t\t\t\t\tmaxWait = thisTime + flush;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif(thisTime >= maxWait) {\n\t\t\t\t\t\t\t\t\ttimeoutFlush = true;\n\t\t\t\t\t\t\t\t\ttimeWaitingForSync = -1; // We have stuff to write, we are no longer waiting.\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} else break;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(o != null) {\n\t\t\t\t\t\t\tlistBytes -= o.length + LINE_OVERHEAD;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif(timeoutFlush || died) {\n\t\t\t\t\t\t// Flush to disk \n\t\t\t\t\t\tmyWrite(logStream, null);\n\t\t\t\t        if(altLogStream != null)\n\t\t\t\t        \tmyWrite(altLogStream, null);\n\t\t\t\t\t}\n\t\t\t\t\tif(died) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tlogStream.close();\n\t\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\t\tSystem.err.println(\"Failed to close log stream: \"+e);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(altLogStream != null) {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\taltLogStream.close();\n\t\t\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\t\t\tSystem.err.println(\"Failed to close compressed log stream: \"+e);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsynchronized(list) {\n\t\t\t\t\t\t\tclosedFinished = true;\n\t\t\t\t\t\t\tlist.notifyAll();\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tif(o == null) continue;\n\t\t\t\t\tmyWrite(logStream,  o);\n\t\t\t        if(altLogStream != null)\n\t\t\t        \tmyWrite(altLogStream, o);\n\t\t\t\t} catch (OutOfMemoryError e) {\n\t\t\t\t\tSystem.err.println(e.getClass());\n\t\t\t\t\tSystem.err.println(e.getMessage());\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t    // FIXME\n\t\t\t\t\t//freenet.node.Main.dumpInterestingObjects();\n\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\tSystem.err.println(\"FileLoggerHook log writer caught \" + t);\n\t\t\t\t\tt.printStackTrace(System.err);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tprivate File rotateLog(File currentFilename, long lastTime, long nextHour, GregorianCalendar gc) {\n\t        // Switch logs\n\t        try {\n\t        \tlogStream.flush();\n\t        \tif(altLogStream != null) altLogStream.flush();\n\t        } catch (IOException e) {\n\t        \tSystem.err.println(\n\t        \t\t\"Flushing on change caught \" + e);\n\t        }\n\t        try {\n\t        \tlogStream.close();\n\t        } catch (IOException e) {\n\t        \tSystem.err.println(\n\t        \t\t\t\"Closing on change caught \" + e);\n\t        }\n\t        long length = currentFilename.length();\n\t        OldLogFile olf = new OldLogFile(currentFilename, lastTime, nextHour, length);\n\t        synchronized(logFiles) {\n\t        \tlogFiles.addLast(olf);\n\t        }\n\t        oldLogFilesDiskSpaceUsage += length;\n\t        trimOldLogFiles();\n\t        // Rotate primary log stream\n\t        currentFilename = new File(getHourLogName(gc, -1, true));\n\t        logStream = openNewLogFile(currentFilename, true);\n\t        if(latestFile != null) {\n\t        \ttry {\n\t        \t\taltLogStream.close();\n\t        \t} catch (IOException e) {\n\t        \t\tSystem.err.println(\n\t        \t\t\t\t\"Closing alt on change caught \" + e);\n\t        \t}\n\t        \tif(previousFile != null && latestFile.exists())\n\t        \t\tFileUtil.renameTo(latestFile, previousFile);\n\t        \tlatestFile.delete();\n\t        \taltLogStream = openNewLogFile(latestFile, false);\n\t        }\n\t        return currentFilename;\n        }\n\n\t\t// Check every minute\n\t\tstatic final int maxSleepTime = 60 * 1000;\n\t\t/**\n\t\t * @param b\n\t\t *            the bytes to write, null to flush\n\t\t */\n\t\tprotected void myWrite(OutputStream os, byte[] b) {\n\t\t\tlong sleepTime = 1000;\n\t\t\twhile (true) {\n\t\t\t\tboolean thrown = false;\n\t\t\t\ttry {\n\t\t\t\t\tif (b != null)\n\t\t\t\t\t\tos.write(b);\n\t\t\t\t\telse\n\t\t\t\t\t\tos.flush();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Exception writing to log: \"\n\t\t\t\t\t\t\t+ e\n\t\t\t\t\t\t\t+ \", sleeping \"\n\t\t\t\t\t\t\t+ sleepTime);\n\t\t\t\t\tthrown = true;\n\t\t\t\t}\n\t\t\t\tif (thrown) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tThread.sleep(sleepTime);\n\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t}\n\t\t\t\t\tsleepTime += sleepTime;\n\t\t\t\t\tif (sleepTime > maxSleepTime)\n\t\t\t\t\t\tsleepTime = maxSleepTime;\n\t\t\t\t} else\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\tprotected OutputStream openNewLogFile(File filename, boolean compress) {\n\t\t\twhile (true) {\n\t\t\t\tlong sleepTime = 1000;\n\t\t\t\ttry {\n\t\t\t\t\tOutputStream o = new FileOutputStream(filename, !logOverwrite);\n\t\t\t\t\tif(compress) {\n\t\t\t\t\t\t// buffer -> gzip -> buffer -> file\n\t\t\t\t\t\to = new BufferedOutputStream(o, 512*1024); // to file\n\t\t\t\t\t\to = new GZIPOutputStream(o);\n\t\t\t\t\t\t// gzip block size is 32kB\n\t\t\t\t\t\to = new BufferedOutputStream(o, 65536); // to gzipper\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// buffer -> file\n\t\t\t\t\t\to = new BufferedOutputStream(o, 512*1024);\n\t\t\t\t\t}\n\t\t\t\t\to.write(BOM);\n\t\t\t\t\treturn o;\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Could not create FOS \" + filename + \": \" + e);\n\t\t\t\t\tSystem.err.println(\n\t\t\t\t\t\t\"Sleeping \" + sleepTime / 1000 + \" seconds\");\n\t\t\t\t\ttry {\n\t\t\t\t\t\tThread.sleep(sleepTime);\n\t\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\t}\n\t\t\t\t\tsleepTime += sleepTime;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tprivate static final byte[] BOM = \"\\uFEFF\".getBytes(ENCODING);\n\n\tprotected int runningCompressors = 0;\n\tprotected Object runningCompressorsSync = new Object();\n\n\tprivate Date myDate = new Date();\n\n\t/**\n\t * Create a Logger to append to the given file. If the file does not exist\n\t * it will be created.\n\t * \n\t * @param filename\n\t *            the name of the file to log to.\n\t * @param fmt\n\t *            log message format string\n\t * @param dfmt\n\t *            date format string\n\t * @param threshold\n\t *            Lowest logged priority\n\t * @param assumeWorking\n\t *            If false, check whether stderr and stdout are writable and if\n\t *            not, redirect them to the log file\n\t * @exception IOException\n\t *                if the file couldn't be opened for append.\n\t * @throws IntervalParseException \n\t */\n\tpublic FileLoggerHook(\n\t\tString filename,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tString logRotateInterval,\n\t\tLogLevel threshold,\n\t\tboolean assumeWorking,\n\t\tboolean logOverwrite,\n\t\tlong maxOldLogfilesDiskUsage, int maxListSize)\n\t\tthrows IOException, IntervalParseException {\n\t\tthis(\n\t\t\tfalse,\n\t\t\tfilename,\n\t\t\tfmt,\n\t\t\tdfmt,\n\t\t\tlogRotateInterval,\n\t\t\tthreshold,\n\t\t\tassumeWorking,\n\t\t\tlogOverwrite,\n\t\t\tmaxOldLogfilesDiskUsage,\n\t\t\tmaxListSize);\n\t}\n\t\n\tprivate final Object trimOldLogFilesLock = new Object();\n\t\n\tpublic void trimOldLogFiles() {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\twhile(oldLogFilesDiskSpaceUsage > maxOldLogfilesDiskUsage) {\n\t\t\t\tOldLogFile olf;\n\t\t\t\t// TODO: creates a double lock situation, but only here. I think this is okay because the inner lock is only used for trivial things.\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif(logFiles.isEmpty()) {\n\t\t\t\t\t\tSystem.err.println(\"ERROR: INCONSISTENT LOGGER TOTALS: Log file list is empty but still used \"+oldLogFilesDiskSpaceUsage+\" bytes!\");\n\t\t\t\t\t}\n\t\t\t\t\tolf = logFiles.removeFirst();\n\t\t\t\t}\n\t\t\t\tolf.filename.delete();\n\t\t\t\toldLogFilesDiskSpaceUsage -= olf.size;\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Deleting \"+olf.filename+\" - saving \"+olf.size+\n\t\t\t\t\t\t\" bytes, disk usage now: \"+oldLogFilesDiskSpaceUsage+\" of \"+maxOldLogfilesDiskUsage);\n\t\t\t}\n\t\t}\n\t}\n\n\t/** Initialize oldLogFiles */\n\tpublic void findOldLogFiles(GregorianCalendar gc) {\n\t\tgc = (GregorianCalendar) gc.clone();\n\t\tFile currentFilename = new File(getHourLogName(gc, -1, true));\n\t\tSystem.out.println(\"Finding old log files. New log file is \"+currentFilename);\n\t\tFile numericSameDateFilename;\n\t\tint slashIndex = baseFilename.lastIndexOf(File.separatorChar);\n\t\tFile dir;\n\t\tString prefix;\n\t\tif(slashIndex == -1) {\n\t\t\tdir = new File(System.getProperty(\"user.dir\"));\n\t\t\tprefix = baseFilename.toLowerCase();\n\t\t} else {\n\t\t\tdir = new File(baseFilename.substring(0, slashIndex));\n\t\t\tprefix = baseFilename.substring(slashIndex+1).toLowerCase();\n\t\t}\n\t\tFile[] files = dir.listFiles();\n\t\tif(files == null) return;\n\t\tjava.util.Arrays.sort(files);\n\t\tlong lastStartTime = -1;\n\t\tFile oldFile = null;\n        if(latestFile.exists())\n        \tFileUtil.renameTo(latestFile, previousFile);\n\n\t\tfor(File f: files) {\n\t\t\tString name = f.getName();\n\t\t\tif(name.toLowerCase().startsWith(prefix)) {\n\t\t\t\tif(name.equals(previousFile.getName()) || name.equals(latestFile.getName())) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(!name.endsWith(\".log.gz\")) {\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Does not end in .log.gz: \"+name);\n\t\t\t\t\tf.delete();\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\tname = name.substring(0, name.length()-\".log.gz\".length());\n\t\t\t\t}\n\t\t\t\tname = name.substring(prefix.length());\n\t\t\t\tif((name.length() == 0) || (name.charAt(0) != '-')) {\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Deleting unrecognized: \"+name+\" (\"+f.getPath()+ ')');\n\t\t\t\t\tf.delete();\n\t\t\t\t\tcontinue;\n\t\t\t\t} else\n\t\t\t\t\tname = name.substring(1);\n\t\t\t\tString[] tokens = name.split(\"-\");\n\t\t\t\tint[] nums = new int[tokens.length];\n\t\t\t\tfor(int j=0;j<tokens.length;j++) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tnums[j] = Integer.parseInt(tokens[j]);\n\t\t\t\t\t} catch (NumberFormatException e) {\n\t\t\t\t\t\tLogger.normal(this, \"Could not parse: \"+tokens[j]+\" into number from \"+name);\n\t\t\t\t\t\t// Broken\n\t\t\t\t\t\tf.delete();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(nums.length > 1)\n\t\t\t\t\tgc.set(Calendar.YEAR, nums[1]);\n\t\t\t\tif(nums.length > 2)\n\t\t\t\t\tgc.set(Calendar.MONTH, nums[2]-1);\n\t\t\t\tif(nums.length > 3)\n\t\t\t\t\tgc.set(Calendar.DAY_OF_MONTH, nums[3]);\n\t\t\t\tif(nums.length > 4)\n\t\t\t\t\tgc.set(Calendar.HOUR_OF_DAY, nums[4]);\n\t\t\t\tif(nums.length > 5)\n\t\t\t\t\tgc.set(Calendar.MINUTE, nums[5]);\n\t\t\t\tgc.set(Calendar.SECOND, 0);\n\t\t\t\tgc.set(Calendar.MILLISECOND, 0);\n\t\t\t\tlong startTime = gc.getTimeInMillis();\n\t\t\t\tif(oldFile != null) {\n\t\t\t\t\tlong l = oldFile.length();\n\t\t\t\t\tOldLogFile olf = new OldLogFile(oldFile, lastStartTime, startTime, l);\n\t\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\t\tlogFiles.addLast(olf);\n\t\t\t\t\t}\n\t\t\t\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\t\t\t\toldLogFilesDiskSpaceUsage += l;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlastStartTime = startTime;\n\t\t\t\toldFile = f;\n\t\t\t} else {\n\t\t\t\t// Nothing to do with us\n\t\t\t\tLogger.normal(this, \"Unknown file: \"+name+\" in the log directory\");\n\t\t\t}\n\t\t}\n\t\t//If a compressed log file already exists for a given date,\n\t\t//add a number to the end of the file that already exists\n\t\tif(currentFilename != null && currentFilename.exists()) {\n\t\t\tSystem.out.println(\"Old log file exists for this time period: \"+currentFilename);\n\t\t\tfor(int a = 1;; a++){\n\t\t\t\tnumericSameDateFilename = new File(getHourLogName(gc, a, true));\n\t\t\t\tif(numericSameDateFilename == null || !numericSameDateFilename.exists()) {\n\t\t\t\t\tif(numericSameDateFilename != null) {\n\t\t\t\t\t\tSystem.out.println(\"Renaming to: \"+numericSameDateFilename);\n\t\t\t\t\t\tFileUtil.renameTo(currentFilename, numericSameDateFilename);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(oldFile != null) {\n\t\t\tlong l = oldFile.length();\n\t\t\tOldLogFile olf = new OldLogFile(oldFile, lastStartTime, System.currentTimeMillis(), l);\n\t\t\tsynchronized(logFiles) {\n\t\t\t\tlogFiles.addLast(olf);\n\t\t\t}\n\t\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\t\toldLogFilesDiskSpaceUsage += l;\n\t\t\t}\n\t\t}\n\t\ttrimOldLogFiles();\n\t}\n\n\tpublic FileLoggerHook(\n\t\t\tString filename,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold,\n\t\t\tString logRotateInterval,\n\t\t\tboolean assumeWorking,\n\t\t\tboolean logOverwrite,\n\t\t\tlong maxOldLogFilesDiskUsage,\n\t\t\tint maxListSize)\n\t\t\tthrows IOException, InvalidThresholdException, IntervalParseException {\n\t\t\tthis(filename,\n\t\t\t\tfmt,\n\t\t\t\tdfmt,\n\t\t\t\tlogRotateInterval,\n\t\t\t\tLogLevel.valueOf(threshold.toUpperCase()),\n\t\t\t\tassumeWorking,\n\t\t\t\tlogOverwrite,\n\t\t\t\tmaxOldLogFilesDiskUsage,\n\t\t\t\tmaxListSize);\n\t\t}\n\n\tprivate void checkStdStreams() {\n\t\t// Redirect System.err and System.out to the Logger Printstream\n\t\t// if they don't exist (like when running under javaw)\n\t\tSystem.out.print(\" \\b\");\n\t\tif (System.out.checkError()) {\n\t\t\tredirectStdOut = true;\n\t\t}\n\t\tSystem.err.print(\" \\b\");\n\t\tif (System.err.checkError()) {\n\t\t\tredirectStdErr = true;\n\t\t}\n\t}\n\n\tpublic FileLoggerHook(\n\t\tOutputStream os,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tLogLevel threshold) throws IntervalParseException {\n\t\tthis(os, fmt, dfmt, threshold, true);\n\t\tlogStream = os;\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\t\tOutputStream os,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold) throws InvalidThresholdException, IntervalParseException {\n\t\t\tthis(os, fmt, dfmt, LogLevel.valueOf(threshold.toUpperCase()), true);\n\t\t\tlogStream = os;\n\t\t}\n\n\t/**\n\t * Create a Logger to send log output to the given PrintStream.\n\t * \n\t * @param stream\n\t *            the PrintStream to send log output to.\n\t * @param fmt\n\t *            log message format string\n\t * @param dfmt\n\t *            date format string\n\t * @param threshold\n\t *            Lowest logged priority\n\t * @throws IntervalParseException \n\t */\n\tpublic FileLoggerHook(\n\t\tOutputStream stream,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tLogLevel threshold,\n\t\tboolean overwrite) throws IntervalParseException {\n\t\tthis(fmt, dfmt, threshold, \"HOUR\", overwrite, -1, 10000);\n\t\tlogStream = stream;\n\t}\n\n\tpublic void start() {\n\t\tif(redirectStdOut) {\n\t\t\ttry {\n\t\t\t\tString encName = ENCODING.name();\n\t\t\t\tSystem.setOut(\n\t\t\t\t\tnew PrintStream(\n\t\t\t\t\t\tnew OutputStreamLogger(LogLevel.NORMAL, \"Stdout: \", encName),\n\t\t\t\t\t\tfalse,\n\t\t\t\t\t\tencName\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t\tif(redirectStdErr) {\n\t\t\t\t\tSystem.setErr(\n\t\t\t\t\t\tnew PrintStream(\n\t\t\t\t\t\t\tnew OutputStreamLogger(LogLevel.ERROR, \"Stderr: \", encName),\n\t\t\t\t\t\t\tfalse,\n\t\t\t\t\t\t\tencName\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new Error(e);\n\t\t\t}\n\t\t}\n\t\tWriterThread wt = new WriterThread();\n\t\twt.setDaemon(true);\n\t\tCloserThread ct = new CloserThread();\n\t\tSemiOrderedShutdownHook.get().addLateJob(ct);\n\t\twt.start();\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\tboolean rotate,\n\t\tString baseFilename,\n\t\tString fmt,\n\t\tString dfmt,\n\t\tString logRotateInterval,\n\t\tLogLevel threshold,\n\t\tboolean assumeWorking,\n\t\tboolean logOverwrite,\n\t\tlong maxOldLogfilesDiskUsage, int maxListSize)\n\t\tthrows IOException, IntervalParseException {\n\t\tthis(fmt, dfmt, threshold, logRotateInterval, logOverwrite, maxOldLogfilesDiskUsage, maxListSize);\n\t\t//System.err.println(\"Creating FileLoggerHook with threshold\n\t\t// \"+threshold);\n\t\tif (!assumeWorking)\n\t\t\tcheckStdStreams();\n\t\tif (rotate) {\n\t\t\tthis.baseFilename = baseFilename;\n\t\t} else {\n\t\t\tlogStream = new BufferedOutputStream(new FileOutputStream(baseFilename, !logOverwrite), 65536);\n\t\t}\n\t}\n\t\n\tpublic FileLoggerHook(\n\t\t\tboolean rotate,\n\t\t\tString baseFilename,\n\t\t\tString fmt,\n\t\t\tString dfmt,\n\t\t\tString threshold,\n\t\t\tString logRotateInterval,\n\t\t\tboolean assumeWorking,\n\t\t\tboolean logOverwrite,\n\t\t\tlong maxOldLogFilesDiskUsage, int maxListSize) throws IOException, InvalidThresholdException, IntervalParseException{\n\t\tthis(rotate,baseFilename,fmt,dfmt,logRotateInterval,LogLevel.valueOf(threshold.toUpperCase()),assumeWorking,logOverwrite,maxOldLogFilesDiskUsage,maxListSize);\n\t}\n\n\tprivate FileLoggerHook(String fmt, String dfmt, LogLevel threshold, String logRotateInterval, boolean overwrite, long maxOldLogfilesDiskUsage, int maxListSize) throws IntervalParseException {\n\t\tsuper(threshold);\n\t\tthis.maxOldLogfilesDiskUsage = maxOldLogfilesDiskUsage;\n\t\tthis.logOverwrite = overwrite;\n\t\tsetInterval(logRotateInterval);\n\t\t\n\t\tMAX_LIST_SIZE = maxListSize;\n\t\tlist = new ArrayBlockingQueue<byte[]>(MAX_LIST_SIZE);\n\t\t\n\t\tsetDateFormat(dfmt);\n\t\tsetLogFormat(fmt);\n\t}\n\n\tprivate void setLogFormat(String fmt) {\n\t\tif ((fmt == null) || (fmt.length() == 0))\n\t\t\tfmt = \"d:c:h:t:p:m\";\n\t\tchar[] f = fmt.toCharArray();\n\n\t\tArrayList<Integer> fmtVec = new ArrayList<Integer>();\n\t\tArrayList<String> strVec = new ArrayList<String>();\n\n\t\tStringBuilder sb = new StringBuilder();\n\n\t\tboolean comment = false;\n\t\tfor (char fi: f) {\n\t\t\tint type = numberOf(fi);\n\t\t\tif(type == UNAME)\n\t\t\t\tgetUName();\n\t\t\tif (!comment && (type != 0)) {\n\t\t\t\tif (sb.length() > 0) {\n\t\t\t\t\tstrVec.add(sb.toString());\n\t\t\t\t\tfmtVec.add(0);\n\t\t\t\t\tsb = new StringBuilder();\n\t\t\t\t}\n\t\t\t\tfmtVec.add(type);\n\t\t\t} else if (fi == '\\\\') {\n\t\t\t\tcomment = true;\n\t\t\t} else {\n\t\t\t\tcomment = false;\n\t\t\t\tsb.append(fi);\n\t\t\t}\n\t\t}\n\t\tif (sb.length() > 0) {\n\t\t\tstrVec.add(sb.toString());\n\t\t\tfmtVec.add(0);\n\t\t}\n\n\t\tthis.fmt = new int[fmtVec.size()];\n\t\tint size = fmtVec.size();\n\t\tfor (int i = 0; i < size; ++i)\n\t\t\tthis.fmt[i] = fmtVec.get(i);\n\n\t\tthis.str = new String[strVec.size()];\n\t\tstr = strVec.toArray(str);\n\t}\n\n\tprivate void setDateFormat(String dfmt) {\n\t\tif ((dfmt != null) && (dfmt.length() != 0)) {\n\t\t\ttry {\n\t\t\t\tdf = new SimpleDateFormat(dfmt);\n\t\t\t} catch (RuntimeException e) {\n\t\t\t\tdf = DateFormat.getDateTimeInstance();\n\t\t\t}\n\t\t} else\n\t\t\tdf = DateFormat.getDateTimeInstance();\n\n\t\tdf.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n\t}\n\n\t@Override\n\tpublic void log(Object o, Class<?> c, String msg, Throwable e, LogLevel priority) {\n\t\tif (!instanceShouldLog(priority, c))\n\t\t\treturn;\n\n\t\tif (closed)\n\t\t\treturn;\n\t\t\n\t\tStringBuilder sb = new StringBuilder( e == null ? 512 : 1024 );\n\t\tint sctr = 0;\n\n\t\tfor (int f: fmt) {\n\t\t\tswitch (f) {\n\t\t\t\tcase 0 :\n\t\t\t\t\tsb.append(str[sctr++]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase DATE :\n\t\t\t\t\tlong now = System.currentTimeMillis();\n\t\t\t\t\tsynchronized (this) {\n\t\t\t\t\t\tmyDate.setTime(now);\n\t\t\t\t\t\tsb.append(df.format(myDate));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase CLASS :\n\t\t\t\t\tsb.append(c == null ? \"<none>\" : c.getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase HASHCODE :\n\t\t\t\t\tsb.append(\n\t\t\t\t\t\to == null\n\t\t\t\t\t\t\t? \"<none>\"\n\t\t\t\t\t\t\t: Integer.toHexString(o.hashCode()));\n\t\t\t\t\tbreak;\n\t\t\t\tcase THREAD :\n\t\t\t\t\tsb.append(Thread.currentThread().getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase PRIORITY :\n\t\t\t\t\tsb.append(priority.name());\n\t\t\t\t\tbreak;\n\t\t\t\tcase MESSAGE :\n\t\t\t\t\tsb.append(msg);\n\t\t\t\t\tbreak;\n\t\t\t\tcase UNAME :\n\t\t\t\t\tsb.append(uname);\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tsb.append('\\n');\n\n\t\t// Write stacktrace if available\n\t\tfor(int j=0;j<20 && e != null;j++) {\n\t\t\tsb.append(e.toString());\n\t\t\t\n\t\t\tStackTraceElement[] trace = e.getStackTrace();\n\t\t\t\n\t\t\tif(trace == null)\n\t\t\t\tsb.append(\"(null)\\n\");\n\t\t\telse if(trace.length == 0)\n\t\t\t\tsb.append(\"(no stack trace)\\n\");\n\t\t\telse {\n\t\t\t\tsb.append('\\n');\n\t\t\t\tfor(StackTraceElement elt: trace) {\n\t\t\t\t\tsb.append(\"\\tat \");\n\t\t\t\t\tsb.append(elt.toString());\n\t\t\t\t\tsb.append('\\n');\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tThrowable cause = e.getCause();\n\t\t\tif(cause != e) e = cause;\n\t\t\telse break;\n\t\t}\n\n\t\tlogString(sb.toString().getBytes(ENCODING));\n\t}\n\n\t/** Memory allocation overhead (estimated through experimentation with bsh) */\n\tprivate static final int LINE_OVERHEAD = 60;\n\t\n\tpublic void logString(byte[] b) {\n\t\tsynchronized (list) {\n\t\t\tint sz = list.size();\n\t\t\tif(!list.offer(b)) {\n\t\t\t\tbyte[] ss = list.poll();\n\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\tss = list.poll();\n\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\tString err =\n\t\t\t\t\t\"GRRR: ERROR: Logging too fast, chopped \"\n\t\t\t\t\t\t+ 2\n\t\t\t\t\t\t+ \" entries, \"\n\t\t\t\t\t\t+ listBytes\n\t\t\t\t\t\t+ \" bytes in memory\\n\";\n\t\t\t\tbyte[] buf = err.getBytes(ENCODING);\n\t\t\t\tif(list.offer(buf))\n\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t\tif(list.offer(b))\n\t\t\t\t\tlistBytes += (b.length + LINE_OVERHEAD);\n\t\t\t} else\n\t\t\t\tlistBytes += (b.length + LINE_OVERHEAD);\n\t\t\tint x = 0;\n\t\t\tif (listBytes > MAX_LIST_BYTES) {\n\t\t\t\twhile ((list.size() > (MAX_LIST_SIZE * 0.9F))\n\t\t\t\t\t|| (listBytes > (MAX_LIST_BYTES * 0.9F))) {\n\t\t\t\t\tbyte[] ss;\n\t\t\t\t\tss = list.poll();\n\t\t\t\t\tlistBytes -= (ss.length + LINE_OVERHEAD);\n\t\t\t\t\tx++;\n\t\t\t\t}\n\t\t\t\tString err =\n\t\t\t\t\t\"GRRR: ERROR: Logging too fast, chopped \"\n\t\t\t\t\t\t+ x\n\t\t\t\t\t\t+ \" entries, \"\n\t\t\t\t\t\t+ listBytes\n\t\t\t\t\t\t+ \" bytes in memory\\n\";\n\t\t\t\tbyte[] buf = err.getBytes(ENCODING);\n\t\t\t\tif(!list.offer(buf)) {\n\t\t\t\t\tbyte[] ss = list.poll();\n\t\t\t\t\tif(ss != null) listBytes -= ss.length + LINE_OVERHEAD;\n\t\t\t\t\tif(list.offer(buf))\n\t\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t\t} else\n\t\t\t\t\tlistBytes += (buf.length + LINE_OVERHEAD);\n\t\t\t}\n\t\t\tif (sz == 0)\n\t\t\t\tlist.notifyAll();\n\t\t}\n\t}\n\n\tpublic long listBytes() {\n\t\tsynchronized (list) {\n\t\t\treturn listBytes;\n\t\t}\n\t}\n\n\tpublic static int numberOf(char c) {\n\t\tswitch (c) {\n\t\t\tcase 'd' :\n\t\t\t\treturn DATE;\n\t\t\tcase 'c' :\n\t\t\t\treturn CLASS;\n\t\t\tcase 'h' :\n\t\t\t\treturn HASHCODE;\n\t\t\tcase 't' :\n\t\t\t\treturn THREAD;\n\t\t\tcase 'p' :\n\t\t\t\treturn PRIORITY;\n\t\t\tcase 'm' :\n\t\t\t\treturn MESSAGE;\n\t\t\tcase 'u' :\n\t\t\t\treturn UNAME;\n\t\t\tdefault :\n\t\t\t\treturn 0;\n\t\t}\n\t}\n\n\t@Override\n\tpublic void close() {\n\t\tclosed = true;\n\t}\n\n\tclass CloserThread extends Thread {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tsynchronized(list) {\n\t\t\t\tclosed = true;\n\t\t\t\tlong deadline = System.currentTimeMillis() + SECONDS.toMillis(10);\n\t\t\t\twhile(!closedFinished) {\n\t\t\t\t\tint wait = (int) (deadline - System.currentTimeMillis());\n\t\t\t\t\tif(wait <= 0) return;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tlist.wait(wait);\n\t\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t\t// Ok.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tSystem.out.println(\"Completed writing logs to disk.\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Print a human- and script- readable list of available log files.\n\t * @throws IOException \n\t */\n\tpublic void listAvailableLogs(OutputStreamWriter writer) throws IOException {\n\t\tOldLogFile[] oldLogFiles;\n\t\tsynchronized(logFiles) {\n\t\t\toldLogFiles = logFiles.toArray(new OldLogFile[logFiles.size()]);\n\t\t}\n\t\tDateFormat tempDF = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT, Locale.ENGLISH);\n\t\ttempDF.setTimeZone(TimeZone.getTimeZone(\"GMT\"));\n\t\tfor(OldLogFile olf: oldLogFiles) {\n\t\t\twriter.write(olf.filename.getName()+\" : \"+tempDF.format(new Date(olf.start))+\" to \"+tempDF.format(new Date(olf.end))+ \" - \"+olf.size+\" bytes\\n\");\n\t\t}\n\t}\n\n\tpublic void sendLogByContainedDate(long time, OutputStream os) throws IOException {\n\t\tOldLogFile toReturn = null;\n\t\tsynchronized(logFiles) {\n\t\t\tfor(OldLogFile olf : logFiles) {\n\t\t    \tif(logMINOR)\n\t\t    \t\tLogger.minor(this, \"Checking \"+time+\" against \"+olf.filename+\" : start=\"+olf.start+\", end=\"+olf.end);\n\t\t\t\tif((time >= olf.start) && (time < olf.end)) {\n\t\t\t\t\ttoReturn = olf;\n\t\t\t\t\tif(logMINOR) Logger.minor(this, \"Found \"+olf);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(toReturn == null)\n\t\t\t\treturn; // couldn't find it\n\t\t}\n\t\tFileInputStream fis = new FileInputStream(toReturn.filename);\n\t\tDataInputStream dis = new DataInputStream(fis);\n\t\tlong written = 0;\n\t\tlong size = toReturn.size;\n\t\tbyte[] buf = new byte[4096];\n\t\twhile(written < size) {\n\t\t\tint toRead = (int) Math.min(buf.length, (size - written));\n\t\t\ttry {\n\t\t\t\tdis.readFully(buf, 0, toRead);\n\t\t\t} catch (IOException e) {\n\t\t\t\tLogger.error(this, \"Could not read bytes \"+written+\" to \"+(written + toRead)+\" from file \"+toReturn.filename+\" which is supposed to be \"+size+\" bytes (\"+toReturn.filename.length()+ ')');\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tos.write(buf, 0, toRead);\n\t\t\twritten += toRead;\n\t\t}\n\t\tdis.close();\n\t\tfis.close();\n\t}\n\n\t/** Set the maximum size of old (gzipped) log files to keep.\n\t * Will start to prune old files immediately, but this will likely not be completed\n\t * by the time the function returns as it is run off-thread.\n\t */\n\tpublic void setMaxOldLogsSize(long val) {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\tmaxOldLogfilesDiskUsage = val;\n\t\t}\n\t\tRunnable r = new Runnable() {\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttrimOldLogFiles();\n\t\t\t}\n\t\t};\n\t\tThread t = new Thread(r, \"Shrink logs\");\n\t\tt.setDaemon(true);\n\t\tt.start();\n\t}\n\n\tprivate boolean switchedBaseFilename;\n\t\n\tpublic void switchBaseFilename(String filename) {\n\t\tsynchronized(this) {\n\t\t\tthis.baseFilename = filename;\n\t\t\tswitchedBaseFilename = true;\n\t\t}\n\t}\n\n\tpublic void waitForSwitch() {\n\t\tlong now = System.currentTimeMillis();\n\t\tsynchronized(this) {\n\t\t\tif(!switchedBaseFilename) return;\n\t\t\tlong startTime = now;\n\t\t\tlong endTime = startTime + 10000;\n\t\t\twhile(((now = System.currentTimeMillis()) < endTime) && !switchedBaseFilename) {\n\t\t\t\ttry {\n\t\t\t\t\twait(Math.max(1, endTime-now));\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t// Ignore\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic void deleteAllOldLogFiles() {\n\t\tsynchronized(trimOldLogFilesLock) {\n\t\t\twhile(true) {\n\t\t\t\tOldLogFile olf;\n\t\t\t\tsynchronized(logFiles) {\n\t\t\t\t\tif(logFiles.isEmpty()) return;\n\t\t\t\t\tolf = logFiles.removeFirst();\n\t\t\t\t}\n\t\t\t\tolf.filename.delete();\n\t\t\t\toldLogFilesDiskSpaceUsage -= olf.size;\n\t\t\t\tif(logMINOR)\n\t\t\t\t\tLogger.minor(this, \"Deleting \"+olf.filename+\" - saving \"+olf.size+\n\t\t\t\t\t\t\t\" bytes, disk usage now: \"+oldLogFilesDiskSpaceUsage+\" of \"+maxOldLogfilesDiskUsage);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * This is used by the lost-lock deadlock detector so MUST NOT TAKE A LOCK ever!\n\t */\n\tpublic boolean hasRedirectedStdOutErrNoLock() {\n\t\treturn redirectStdOut || redirectStdErr;\n\t}\n\n\tpublic synchronized void setMaxBacklogNotBusy(long val) {\n\t\tflushTime = val;\n\t}\n}\n","lineNo":794}
{"Smelly Sample":"package freenet.clients.http;\n\nimport java.io.IOException;\nimport java.net.URI;\n\nimport freenet.client.HighLevelSimpleClient;\nimport freenet.client.InsertContext;\nimport freenet.client.InsertContext.CompatibilityMode;\nimport freenet.client.filter.FilterOperation;\nimport freenet.clients.http.ContentFilterToadlet.ResultHandling;\nimport freenet.l10n.NodeL10n;\nimport freenet.node.NodeClientCore;\nimport freenet.node.SecurityLevels.NETWORK_THREAT_LEVEL;\nimport freenet.support.HTMLNode;\nimport freenet.support.api.HTTPRequest;\n\npublic class FileInsertWizardToadlet extends Toadlet implements LinkEnabledCallback {\n\n\tprotected FileInsertWizardToadlet (HighLevelSimpleClient client, NodeClientCore clientCore) {\n\t\tsuper(client);\n\t\tthis.core = clientCore;\n\t}\n\n\tfinal NodeClientCore core;\n\t\n\t// IMHO there isn't much point synchronizing these.\n\tprivate boolean rememberedLastTime;\n\tprivate boolean wasCanonicalLastTime;\n\t\n\tstatic final String PATH = \"/insertfile/\";\n\t\n\t@Override\n\tpublic String path() {\n\t\treturn PATH;\n\t}\n\t\n\tpublic void reportCanonicalInsert() {\n\t\trememberedLastTime = true;\n\t\twasCanonicalLastTime = true;\n\t}\n\t\n\tpublic void reportRandomInsert() {\n\t\trememberedLastTime = true;\n\t\twasCanonicalLastTime = false;\n\t}\n\t\n\tpublic void handleMethodGET (URI uri, final HTTPRequest request, final ToadletContext ctx)\n\t        throws ToadletContextClosedException, IOException, RedirectException {\n\n//\t\t// We ensure that we have a FCP server running\n//\t\tif(!fcp.enabled){\n//\t\t\twriteError(NodeL10n.getBase().getString(\"QueueToadlet.fcpIsMissing\"), NodeL10n.getBase().getString(\"QueueToadlet.pleaseEnableFCP\"), ctx, false);\n//\t\t\treturn;\n//\t\t}\n//\t\tif(!core.hasLoadedQueue()) {\n//\t\t\twriteError(NodeL10n.getBase().getString(\"QueueToadlet.notLoadedYetTitle\"), NodeL10n.getBase().getString(\"QueueToadlet.notLoadedYet\"), ctx, false);\n//\t\t\treturn;\n//\t\t}\n\n\t\tif (container.publicGatewayMode() && !ctx.isAllowedFullAccess()) {\n\t\t    sendUnauthorizedPage(ctx);\n\t\t\treturn;\n\t\t}\n\t\t\n\t\tfinal PageMaker pageMaker = ctx.getPageMaker();\n\n\t\tPageNode page = pageMaker.getPageNode(l10n(\"pageTitle\"), ctx);\n\t\tHTMLNode pageNode = page.outer;\n\t\tHTMLNode contentNode = page.content;\n\n\t\t/* add alert summary box */\n\t\tif (ctx.isAllowedFullAccess()) contentNode.addChild(ctx.getAlertManager().createSummary());\n\n\t\tcontentNode.addChild(createInsertBox(pageMaker, ctx, ctx.isAdvancedModeEnabled()));\n\t\tif(ctx.isAdvancedModeEnabled())\n\t\t\tcontentNode.addChild(createFilterBox(pageMaker, ctx));\n\t\t\n\t\twriteHTMLReply(ctx, 200, \"OK\", null, pageNode.generate());\n\t}\n\t\n\tprivate HTMLNode createInsertBox (PageMaker pageMaker, ToadletContext ctx, boolean isAdvancedModeEnabled) {\n\t\t/* the insert file box */\n\t\tInfoboxNode infobox = pageMaker.getInfobox(\n\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFile\"), \"insert-queue\", true);\n\t\tHTMLNode insertBox = infobox.outer;\n\t\tHTMLNode insertContent = infobox.content;\n\t\tinsertContent.addChild(\"p\", l10n(\"insertIntro\"));\n\t\tNETWORK_THREAT_LEVEL seclevel = core.node.securityLevels.getNetworkThreatLevel();\n\t\tHTMLNode insertForm = ctx.addFormChild(insertContent, QueueToadlet.PATH_UPLOADS, \"queueInsertForm\");\n\t\tHTMLNode input = insertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t        new String[] { \"radio\", \"keytype\", \"CHK\", \"keytypeChk\" });\n\t\tif ((!rememberedLastTime && seclevel == NETWORK_THREAT_LEVEL.LOW) ||\n\t\t        (rememberedLastTime && wasCanonicalLastTime && seclevel != NETWORK_THREAT_LEVEL.MAXIMUM)) {\n\t\t\tinput.addAttribute(\"checked\", \"checked\");\n\t\t}\n\t\tinsertForm.addChild(\"label\",\n\t\t        new String[] { \"for\" },\n\t\t        new String[] { \"keytypeChk\" }\n\t\t        ).addChild(\"b\", l10n(\"insertCanonicalTitle\"));\n\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertCanonical\"));\n\t\tif(isAdvancedModeEnabled)\n\t\t\tinsertForm.addChild(\"#\", \" \"+l10n(\"insertCanonicalAdvanced\"));\n\t\tinsertForm.addChild(\"br\");\n\t\tinput = insertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t        new String[] { \"radio\", \"keytype\", \"SSK\", \"keytypeSsk\" });\n\t\tif (seclevel == NETWORK_THREAT_LEVEL.MAXIMUM || (rememberedLastTime && !wasCanonicalLastTime)) {\n\t\t\tinput.addAttribute(\"checked\", \"checked\");\n\t\t}\n\t\tinsertForm.addChild(\"label\",\n            new String[] { \"for\" },\n            new String[] { \"keytypeSsk\" }\n            ).addChild(\"b\", l10n(\"insertRandomTitle\"));\n\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertRandom\"));\n\t\tif(isAdvancedModeEnabled)\n\t\t\tinsertForm.addChild(\"#\", \" \"+l10n(\"insertRandomAdvanced\"));\n\t\tif (isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t\t        new String[] { \"radio\", \"keytype\", \"specify\", \"keytypeSpecify\" });\n\t\t\tinsertForm.addChild(\"label\",\n              new String[] { \"for\" },\n              new String[] { \"keytypeSpecify\" }\n              ).addChild(\"b\", l10n(\"insertSpecificKeyTitle\"));\n\t\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertSpecificKey\")+\" \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"text\", \"key\", \"KSK@\" });\n\t\t}\n\t\tif (isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"checked\", \"id\" },\n\t\t\t        new String[] { \"checkbox\", \"compress\", \"checked\", \"checkboxCompress\" });\n\t\t\tinsertForm.addChild(\"label\",\n              new String[] { \"for\" },\n              new String[] { \"checkboxCompress\" },\n              ' ' + NodeL10n.getBase().getString(\"QueueToadlet.insertFileCompressLabel\"));\n\t\t} else {\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"hidden\", \"compress\", \"true\" });\n\t\t}\n\t\tif(isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.compatModeLabel\")+\": \");\n\t\t\tHTMLNode select = insertForm.addChild(\"select\", \"name\", \"compatibilityMode\");\n\t\t\tfor(CompatibilityMode mode : InsertContext.CompatibilityMode.values()) {\n\t\t\t\tif(mode == CompatibilityMode.COMPAT_UNKNOWN) continue;\n\t\t\t\t// FIXME l10n???\n\t\t\t\tHTMLNode option = select.addChild(\"option\", \"value\", mode.name(),\n\t\t\t\t        NodeL10n.getBase().getString(\"InsertContext.CompatibilityMode.\"+mode.name()));\n\t\t\t\tif (mode == CompatibilityMode.COMPAT_DEFAULT) option.addAttribute(\"selected\", \"\");\n\t\t\t}\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"#\", l10n(\"splitfileCryptoKeyLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"maxlength\" },\n\t\t\t        new String[] { \"text\", \"overrideSplitfileKey\", \"64\" });\n\t\t}\n\t\tinsertForm.addChild(\"br\");\n\t\tinsertForm.addChild(\"br\");\n\t\t// Local file browser\n\t\tif (ctx.isAllowedFullAccess()) {\n\t\t\tinsertForm.addChild(\"#\",\n\t\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"submit\", \"insert-local\",\n\t\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseButton\") + \"...\" });\n\t\t\tinsertForm.addChild(\"br\");\n\t\t}\n\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.insertFileLabel\") + \": \");\n\t\tinsertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"file\", \"filename\", \"\" });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n\t\tinsertForm.addChild(\"input\", \n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"insert\",\n\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileInsertFileLabel\") });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n\t\t\n\t\treturn insertBox;\n\t}\n\t\n\tprivate HTMLNode createFilterBox (PageMaker pageMaker, ToadletContext ctx) {\n\t\t/* the insert file box */\n\t\tInfoboxNode infobox = pageMaker.getInfobox(\n\t\t        l10n(\"previewFilterFile\"), \"insert-queue\", true);\n\t\tHTMLNode insertBox = infobox.outer;\n\t\tHTMLNode insertContent = infobox.content;\n\t\tHTMLNode insertForm = ctx.addFormChild(insertContent, ContentFilterToadlet.PATH, \"filterPreviewForm\");\n\t    insertForm.addChild(\"#\", l10n(\"filterFileLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"br\");\n        \n        // apply read filter, write filter, or both\n        //TODO: radio buttons to select, once ContentFilter supports write filtering\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"hidden\", \"filter-operation\", FilterOperation.BOTH.toString() });\n\n        // display in browser or save to disk\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\", \"id\" },\n                new String[] { \"radio\", \"result-handling\", ResultHandling.DISPLAY.toString(), \"resHandlingDisplay\" });\n\t    insertForm.addChild(\"label\",\n                new String[] { \"for\" },\n                new String[] { \"resHandlingDisplay\" },\n                ContentFilterToadlet.l10n(\"displayResultLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\", \"id\" },\n                new String[] { \"radio\", \"result-handling\", ResultHandling.SAVE.toString(), \"resHandlingSave\" });\n\t    insertForm.addChild(\"label\",\n                new String[] { \"for\" },\n                new String[] { \"resHandlingSave\" },\n                ContentFilterToadlet.l10n(\"saveResultLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"br\");\n        \n        // mime type\n        insertForm.addChild(\"#\", ContentFilterToadlet.l10n(\"mimeTypeLabel\") + \": \");\n        insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"text\", \"mime-type\", \"\" });\n        insertForm.addChild(\"br\");\n        insertForm.addChild(\"#\", ContentFilterToadlet.l10n(\"mimeTypeText\"));\n        insertForm.addChild(\"br\");\n        insertForm.addChild(\"br\");\n        \n\t\t// Local file browser\n\t\tif (ctx.isAllowedFullAccess()) {\n\t\t\tinsertForm.addChild(\"#\",\n\t\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"submit\", \"filter-local\",\n\t\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseButton\") + \"...\" });\n\t\t\tinsertForm.addChild(\"br\");\n\t\t}\n\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.insertFileLabel\") + \": \");\n\t\tinsertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"file\", \"filename\", \"\" });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n        \n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"submit\", \"filter-upload\",\n                        ContentFilterToadlet.l10n(\"filterFileFilterLabel\") });\n\t    return insertBox;\n\t}\n\t\n\tString l10n (String key) {\n\t\treturn NodeL10n.getBase().getString(\"FileInsertWizardToadlet.\"+key);\n\t}\n\t\n\tString l10n (String key, String pattern, String value) {\n\t\treturn NodeL10n.getBase().getString(\"FileInsertWizardToadlet.\"+key, pattern, value);\n\t}\n\n\t@Override\n\tpublic boolean isEnabled (ToadletContext ctx) {\n\t\treturn (!container.publicGatewayMode()) || ((ctx != null) && ctx.isAllowedFullAccess());\n\t}\n}\n","Method after Refactoring":"package freenet.clients.http;\n\nimport java.io.IOException;\nimport java.net.URI;\n\nimport freenet.client.HighLevelSimpleClient;\nimport freenet.client.InsertContext;\nimport freenet.client.InsertContext.CompatibilityMode;\nimport freenet.client.filter.FilterOperation;\nimport freenet.clients.http.ContentFilterToadlet.ResultHandling;\nimport freenet.l10n.NodeL10n;\nimport freenet.node.NodeClientCore;\nimport freenet.node.SecurityLevels.NETWORK_THREAT_LEVEL;\nimport freenet.support.HTMLNode;\nimport freenet.support.api.HTTPRequest;\n\npublic class FileInsertWizardToadlet extends Toadlet implements LinkEnabledCallback {\n\n\tprotected FileInsertWizardToadlet (HighLevelSimpleClient client, NodeClientCore clientCore) {\n\t\tsuper(client);\n\t\tthis.core = clientCore;\n\t}\n\n\tfinal NodeClientCore core;\n\t\n\t// IMHO there isn't much point synchronizing these.\n\tprivate boolean rememberedLastTime;\n\tprivate boolean wasCanonicalLastTime;\n\t\n\tstatic final String PATH = \"/insertfile/\";\n\t\n\t@Override\n\tpublic String path() {\n\t\treturn PATH;\n\t}\n\t\n\tpublic void reportCanonicalInsert() {\n\t\trememberedLastTime = true;\n\t\twasCanonicalLastTime = true;\n\t}\n\t\n\tpublic void reportRandomInsert() {\n\t\trememberedLastTime = true;\n\t\twasCanonicalLastTime = false;\n\t}\n\t\n\tpublic void handleMethodGET (URI uri, final HTTPRequest request, final ToadletContext ctx)\n\t        throws ToadletContextClosedException, IOException, RedirectException {\n\n//\t\t// We ensure that we have a FCP server running\n//\t\tif(!fcp.enabled){\n//\t\t\twriteError(NodeL10n.getBase().getString(\"QueueToadlet.fcpIsMissing\"), NodeL10n.getBase().getString(\"QueueToadlet.pleaseEnableFCP\"), ctx, false);\n//\t\t\treturn;\n//\t\t}\n//\t\tif(!core.hasLoadedQueue()) {\n//\t\t\twriteError(NodeL10n.getBase().getString(\"QueueToadlet.notLoadedYetTitle\"), NodeL10n.getBase().getString(\"QueueToadlet.notLoadedYet\"), ctx, false);\n//\t\t\treturn;\n//\t\t}\n\n\t\tif (container.publicGatewayMode() && !ctx.isAllowedFullAccess()) {\n\t\t    sendUnauthorizedPage(ctx);\n\t\t\treturn;\n\t\t}\n\t\t\n\t\tfinal PageMaker pageMaker = ctx.getPageMaker();\n\n\t\tPageNode page = pageMaker.getPageNode(l10n(\"pageTitle\"), ctx);\n\t\tHTMLNode pageNode = page.outer;\n\t\tHTMLNode contentNode = page.content;\n\n\t\t/* add alert summary box */\n\t\tif (ctx.isAllowedFullAccess()) contentNode.addChild(ctx.getAlertManager().createSummary());\n\n\t\tcontentNode.addChild(createInsertBox(pageMaker, ctx, ctx.isAdvancedModeEnabled()));\n\t\tif(ctx.isAdvancedModeEnabled())\n\t\t\tcontentNode.addChild(createFilterBox(pageMaker, ctx));\n\t\t\n\t\twriteHTMLReply(ctx, 200, \"OK\", null, pageNode.generate());\n\t}\n\t\n\tprivate HTMLNode createInsertBox (PageMaker pageMaker, ToadletContext ctx, boolean isAdvancedModeEnabled) {\n\t\t/* the insert file box */\n\t\tInfoboxNode infobox = pageMaker.getInfobox(\n\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFile\"), \"insert-queue\", true);\n\t\tHTMLNode insertBox = infobox.outer;\n\t\tHTMLNode insertContent = infobox.content;\n\t\tinsertContent.addChild(\"p\", l10n(\"insertIntro\"));\n\t\tNETWORK_THREAT_LEVEL seclevel = core.node.securityLevels.getNetworkThreatLevel();\n\t\tHTMLNode insertForm = ctx.addFormChild(insertContent, QueueToadlet.PATH_UPLOADS, \"queueInsertForm\");\n\t\tboolean preselectSsk = (!rememberedLastTime && seclevel != NETWORK_THREAT_LEVEL.LOW)\n\t\t\t\t|| (rememberedLastTime && !wasCanonicalLastTime)\n\t\t\t\t|| seclevel == NETWORK_THREAT_LEVEL.MAXIMUM;\n\t\tHTMLNode input = insertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t        new String[] { \"radio\", \"keytype\", \"CHK\", \"keytypeChk\" });\n\t\tif (!preselectSsk) {\n\t\t\tinput.addAttribute(\"checked\", \"checked\");\n\t\t}\n\t\tinsertForm.addChild(\"label\",\n\t\t        new String[] { \"for\" },\n\t\t        new String[] { \"keytypeChk\" }\n\t\t        ).addChild(\"b\", l10n(\"insertCanonicalTitle\"));\n\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertCanonical\"));\n\t\tif(isAdvancedModeEnabled)\n\t\t\tinsertForm.addChild(\"#\", \" \"+l10n(\"insertCanonicalAdvanced\"));\n\t\tinsertForm.addChild(\"br\");\n\t\tinput = insertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t        new String[] { \"radio\", \"keytype\", \"SSK\", \"keytypeSsk\" });\n\t\tif (preselectSsk) {\n\t\t\tinput.addAttribute(\"checked\", \"checked\");\n\t\t}\n\t\tinsertForm.addChild(\"label\",\n            new String[] { \"for\" },\n            new String[] { \"keytypeSsk\" }\n            ).addChild(\"b\", l10n(\"insertRandomTitle\"));\n\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertRandom\"));\n\t\tif(isAdvancedModeEnabled)\n\t\t\tinsertForm.addChild(\"#\", \" \"+l10n(\"insertRandomAdvanced\"));\n\t\tif (isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\", \"id\" },\n\t\t\t        new String[] { \"radio\", \"keytype\", \"specify\", \"keytypeSpecify\" });\n\t\t\tinsertForm.addChild(\"label\",\n              new String[] { \"for\" },\n              new String[] { \"keytypeSpecify\" }\n              ).addChild(\"b\", l10n(\"insertSpecificKeyTitle\"));\n\t\t\tinsertForm.addChild(\"#\", \": \"+l10n(\"insertSpecificKey\")+\" \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"text\", \"key\", \"KSK@\" });\n\t\t}\n\t\tif (isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"checked\", \"id\" },\n\t\t\t        new String[] { \"checkbox\", \"compress\", \"checked\", \"checkboxCompress\" });\n\t\t\tinsertForm.addChild(\"label\",\n              new String[] { \"for\" },\n              new String[] { \"checkboxCompress\" },\n              ' ' + NodeL10n.getBase().getString(\"QueueToadlet.insertFileCompressLabel\"));\n\t\t} else {\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"hidden\", \"compress\", \"true\" });\n\t\t}\n\t\tif(isAdvancedModeEnabled) {\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.compatModeLabel\")+\": \");\n\t\t\tHTMLNode select = insertForm.addChild(\"select\", \"name\", \"compatibilityMode\");\n\t\t\tfor(CompatibilityMode mode : InsertContext.CompatibilityMode.values()) {\n\t\t\t\tif(mode == CompatibilityMode.COMPAT_UNKNOWN) continue;\n\t\t\t\t// FIXME l10n???\n\t\t\t\tHTMLNode option = select.addChild(\"option\", \"value\", mode.name(),\n\t\t\t\t        NodeL10n.getBase().getString(\"InsertContext.CompatibilityMode.\"+mode.name()));\n\t\t\t\tif (mode == CompatibilityMode.COMPAT_DEFAULT) option.addAttribute(\"selected\", \"\");\n\t\t\t}\n\t\t\tinsertForm.addChild(\"br\");\n\t\t\tinsertForm.addChild(\"#\", l10n(\"splitfileCryptoKeyLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"maxlength\" },\n\t\t\t        new String[] { \"text\", \"overrideSplitfileKey\", \"64\" });\n\t\t}\n\t\tinsertForm.addChild(\"br\");\n\t\tinsertForm.addChild(\"br\");\n\t\t// Local file browser\n\t\tif (ctx.isAllowedFullAccess()) {\n\t\t\tinsertForm.addChild(\"#\",\n\t\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"submit\", \"insert-local\",\n\t\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseButton\") + \"...\" });\n\t\t\tinsertForm.addChild(\"br\");\n\t\t}\n\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.insertFileLabel\") + \": \");\n\t\tinsertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"file\", \"filename\", \"\" });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n\t\tinsertForm.addChild(\"input\", \n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"insert\",\n\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileInsertFileLabel\") });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n\t\t\n\t\treturn insertBox;\n\t}\n\t\n\tprivate HTMLNode createFilterBox (PageMaker pageMaker, ToadletContext ctx) {\n\t\t/* the insert file box */\n\t\tInfoboxNode infobox = pageMaker.getInfobox(\n\t\t        l10n(\"previewFilterFile\"), \"insert-queue\", true);\n\t\tHTMLNode insertBox = infobox.outer;\n\t\tHTMLNode insertContent = infobox.content;\n\t\tHTMLNode insertForm = ctx.addFormChild(insertContent, ContentFilterToadlet.PATH, \"filterPreviewForm\");\n\t    insertForm.addChild(\"#\", l10n(\"filterFileLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"br\");\n        \n        // apply read filter, write filter, or both\n        //TODO: radio buttons to select, once ContentFilter supports write filtering\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"hidden\", \"filter-operation\", FilterOperation.BOTH.toString() });\n\n        // display in browser or save to disk\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\", \"id\" },\n                new String[] { \"radio\", \"result-handling\", ResultHandling.DISPLAY.toString(), \"resHandlingDisplay\" });\n\t    insertForm.addChild(\"label\",\n                new String[] { \"for\" },\n                new String[] { \"resHandlingDisplay\" },\n                ContentFilterToadlet.l10n(\"displayResultLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\", \"id\" },\n                new String[] { \"radio\", \"result-handling\", ResultHandling.SAVE.toString(), \"resHandlingSave\" });\n\t    insertForm.addChild(\"label\",\n                new String[] { \"for\" },\n                new String[] { \"resHandlingSave\" },\n                ContentFilterToadlet.l10n(\"saveResultLabel\"));\n\t    insertForm.addChild(\"br\");\n\t    insertForm.addChild(\"br\");\n        \n        // mime type\n        insertForm.addChild(\"#\", ContentFilterToadlet.l10n(\"mimeTypeLabel\") + \": \");\n        insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"text\", \"mime-type\", \"\" });\n        insertForm.addChild(\"br\");\n        insertForm.addChild(\"#\", ContentFilterToadlet.l10n(\"mimeTypeText\"));\n        insertForm.addChild(\"br\");\n        insertForm.addChild(\"br\");\n        \n\t\t// Local file browser\n\t\tif (ctx.isAllowedFullAccess()) {\n\t\t\tinsertForm.addChild(\"#\",\n\t\t\t        NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseLabel\")+\": \");\n\t\t\tinsertForm.addChild(\"input\",\n\t\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t\t        new String[] { \"submit\", \"filter-local\",\n\t\t\t                NodeL10n.getBase().getString(\"QueueToadlet.insertFileBrowseButton\") + \"...\" });\n\t\t\tinsertForm.addChild(\"br\");\n\t\t}\n\t\tinsertForm.addChild(\"#\", NodeL10n.getBase().getString(\"QueueToadlet.insertFileLabel\") + \": \");\n\t\tinsertForm.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"file\", \"filename\", \"\" });\n\t\tinsertForm.addChild(\"#\", \" \\u00a0 \");\n        \n\t    insertForm.addChild(\"input\",\n                new String[] { \"type\", \"name\", \"value\" },\n                new String[] { \"submit\", \"filter-upload\",\n                        ContentFilterToadlet.l10n(\"filterFileFilterLabel\") });\n\t    return insertBox;\n\t}\n\t\n\tString l10n (String key) {\n\t\treturn NodeL10n.getBase().getString(\"FileInsertWizardToadlet.\"+key);\n\t}\n\t\n\tString l10n (String key, String pattern, String value) {\n\t\treturn NodeL10n.getBase().getString(\"FileInsertWizardToadlet.\"+key, pattern, value);\n\t}\n\n\t@Override\n\tpublic boolean isEnabled (ToadletContext ctx) {\n\t\treturn (!container.publicGatewayMode()) || ((ctx != null) && ctx.isAllowedFullAccess());\n\t}\n}\n","lineNo":90}
{"Smelly Sample":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.io.comm;\n\nimport java.io.DataInput;\nimport java.io.DataOutputStream;\nimport java.io.IOException;\nimport java.net.Inet6Address;\nimport java.net.InetAddress;\nimport java.net.UnknownHostException;\nimport java.util.Arrays;\n\nimport freenet.io.AddressIdentifier;\nimport freenet.support.LogThresholdCallback;\nimport freenet.support.Logger;\nimport freenet.support.Logger.LogLevel;\nimport freenet.support.io.InetAddressIpv6FirstComparator;\nimport freenet.support.transport.ip.HostnameSyntaxException;\nimport freenet.support.transport.ip.HostnameUtil;\nimport freenet.support.transport.ip.IPUtil;\n\n/**\n * Long-term InetAddress. If created with an IP address, then the IP address is primary.\n * If created with a name, then the name is primary, and the IP address can change.\n * Most code ripped from Peer.\n * \n * Propagates the IP address on equals() but not the hostname. This does not change \n * hashCode() because it only happens if hostname is set, and in that case, hashCode()\n * is based on the hostname and not on the IP address. So it is safe to put \n * FreenetInetAddress's into hashtables: neither equals() nor getAddress() will change\n * its hashCode.\n * \n * BUT a FreenetInetAddress with IP 1.2.3.4 and no hostname is *NOT* equal to one with\n * the IP address and no name. So if you want to match on only the IP address, you need\n * to either call dropHostname() first (after which neither propagation nor getAddress()\n * will change the hashcode), or just use InetAddress's.\n * \n * FIXME reconsider whether we need this. The lazy lookup is useful but not THAT useful,\n * and we have a regular lookup task now anyway. Over-complex, could lead to odd bugs, \n * although not if used correctly as explained above.\n * @author amphibian\n */\npublic class FreenetInetAddress {\n\n\tprivate static volatile boolean logMINOR;\n\tprivate static volatile boolean logDEBUG;\n\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t\tlogDEBUG = Logger.shouldLog(LogLevel.DEBUG, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t// hostname - only set if we were created with a hostname\n\t// and not an address\n\tprivate final String hostname;\n\tprivate InetAddress _address;\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis) throws IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\tthrow new IOException(\"Unknown type byte (old form? corrupt stream? too short/long prev field?): \"+firstByte);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n\t}\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException,\n\t        IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\t// Old format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tba[0] = (byte)firstByte;\n\t\t\tdis.readFully(ba, 1, 3);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n        if(checkHostnameOrIPSyntax && null != hostname) {\n        \tif(!HostnameUtil.isValidHostname(hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n\t}\n\n\t/**\n\t * Create from an InetAddress. The IP address is primary i.e. fixed.\n\t * The hostname either doesn't exist, or is looked up.\n\t */\n\tpublic FreenetInetAddress(InetAddress address) {\n\t\t_address = address;\n\t\thostname = null;\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown) throws UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n        \t// Is an IP address\n            addr = InetAddress.getByName(host);\n            // Don't catch UnknownHostException here, if it happens there's a bug in AddressIdentifier.\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+addr.getHostAddress()+ '\\'');\n            if(addr != null) {\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException, UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n            try {\n                addr = InetAddress.getByName(host);\n            } catch (UnknownHostException e) {\n            \tif(!allowUnknown) throw e;\n                addr = null;\n            }\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+(addr != null ? addr.getHostAddress()+ '\\'' : \"\"));\n            if(addr != null && addr.getHostAddress().equals(host)) {\n            \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' looks like an IP address\");\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        if(checkHostnameOrIPSyntax && null != this.hostname) {\n        \tif(!HostnameUtil.isValidHostname(this.hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\t\n\tpublic boolean laxEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null) {\n\t\t\t\tif(_address == null) return false; // No basis for comparison.\n\t\t\t\tif(addr._address != null) {\n\t\t\t\t\treturn _address.equals(addr._address);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\t\taddr._address = _address;\n\t\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t\t_address = addr._address;\n\t\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\t\treturn false;\n\t\t\t\t// Equal.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t// His hostname might not be null. Not a problem.\n\t\treturn _address.equals(addr._address);\n\t}\n\t\n\t@Override\n\tpublic boolean equals(Object o) {\n\t\tif(!(o instanceof FreenetInetAddress)) {\n\t\t\treturn false;\n\t\t}\n\t\tFreenetInetAddress addr = (FreenetInetAddress)o;\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t}\n\t\tif(addr.hostname != null)\n\t\t\treturn false;\n\n\t\t// No hostname, go by address.\n\t\tif(!_address.equals(addr._address)) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\tpublic boolean strictEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t} else if(addr.hostname != null /* && hostname == null */) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// No hostname, go by address.\n\t\tif(!getHostName(_address).equalsIgnoreCase(getHostName(addr._address))) {\n\t\t\t//Logger.minor(this, \"Addresses do not match: mine=\"+getHostName(_address)+\" his=\"+getHostName(addr._address));\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\t/**\n\t * Get the IP address. Look it up if necessary, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress() {\n\t  return getAddress(true);\n\t}\n\n\t/**\n\t * Get the IP address. Look it up only if allowed to, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress(boolean doDNSRequest) {\n\t\tif (_address != null) {\n\t\t\treturn _address;\n\t\t} else {\n\t\t        if(!doDNSRequest) return null;\n\t\t        InetAddress addr = getHandshakeAddress();\n\t\t        if( addr != null ) {\n\t\t                this._address = addr;\n\t\t        }\n\t\t        return addr;\n\t\t}\n\t}\n\n\t/**\n\t * Get the IP address, looking up the hostname if the hostname is primary, even if\n\t * it has been looked up before. Typically called on a reconnect attempt, when the\n\t * dyndns address may have changed.\n\t */\n\tpublic InetAddress getHandshakeAddress() {\n\t    // Since we're handshaking, hostname-to-IP may have changed\n\t    if ((_address != null) && (hostname == null)) {\n\t    \tif(logMINOR) Logger.minor(this, \"hostname is null, returning \"+_address);\n\t        return _address;\n\t    } else {\n\t    \tif(logMINOR) Logger.minor(this, \"Looking up '\"+hostname+\"' in DNS\", new Exception(\"debug\"));\n\t        /* \n\t         * Peers are constructed from an address once a\n\t         * handshake has been completed, so this lookup\n\t         * will only be performed during a handshake\n\t         * (this method should normally only be called\n\t         * from PeerNode.getHandshakeIPs() and once\n\t         * each connection from this.getAddress()\n\t         * otherwise) - it doesn't mean we perform a\n\t         * DNS lookup with every packet we send.\n\t         */\n\t        try {\n\t        \tInetAddress[] addresses = InetAddress.getAllByName(hostname);\n\t        \tif(logMINOR) Logger.minor(this, \"Look up got '\"+addresses+ '\\'');\n\t        \tif( addresses.length != 0 ) {\n\t        \t\t/* sort by IPv6 first */\n                    Arrays.sort(addresses, InetAddressIpv6FirstComparator.COMPARATOR);\n                    /*\n\t        \t\t * cache the answer since getHandshakeAddress()\n\t        \t\t * doesn't use the cached value, thus\n\t        \t\t * getHandshakeIPs() should always get the\n\t        \t\t * latest value from DNS (minus Java's caching)\n\t        \t\t */\n\t        \t\tthis._address = InetAddress.getByAddress(addresses[0].getAddress());\n\t        \t\tif(logMINOR) Logger.minor(this, \"Setting address to \"+_address);\n\t        \t}\n\t        \treturn addresses[0];\n\t        } catch (UnknownHostException e) {\n\t        \tif(logMINOR) Logger.minor(this, \"DNS said hostname '\"+hostname+\"' is an unknown host, returning null\");\n\t            return null;\n\t        }\n\t    }\n\t}\n\n\t@Override\n\tpublic int hashCode() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname.hashCode(); // Was set at creation, so it can safely be used here.\n\t\t} else {\n\t\t\treturn _address.hashCode(); // Can be null, but if so, hostname will be non-null.\n\t\t}\n\t}\n\t\n\t@Override\n\tpublic String toString() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname;\n\t\t} else {\n\t\t\treturn _address.getHostAddress();\n\t\t}\n\t}\n\t\n\tpublic String toStringPrefNumeric() {\n\t\tif(_address != null)\n\t\t\treturn _address.getHostAddress();\n\t\telse\n\t\t\treturn hostname;\n\t}\n\n\tpublic void writeToDataOutputStream(DataOutputStream dos) throws IOException {\n\t\tInetAddress addr = this.getAddress();\n\t\tif (addr == null) throw new UnknownHostException();\n\t\tbyte[] data = addr.getAddress();\n\t\tif(data.length == 4)\n\t\t\tdos.write(0);\n\t\telse\n\t\t\tdos.write(255);\n\t\tdos.write(data);\n\t\tif(hostname != null)\n\t\t\tdos.writeUTF(hostname);\n\t\telse\n\t\t\tdos.writeUTF(\"\");\n\t}\n\n\t/**\n\t * Return the hostname or the IP address of the given InetAddress.\n\t * Does not attempt to do a reverse lookup; if the hostname is\n\t * known, return it, otherwise return the textual IP address.\n\t */\n\tpublic static String getHostName(InetAddress primaryIPAddress) {\n\t\tif(primaryIPAddress == null) return null;\n\t\tString s = primaryIPAddress.toString();\n\t\tString addr = s.substring(0, s.indexOf('/')).trim();\n\t\tif(addr.length() == 0)\n\t\t\treturn primaryIPAddress.getHostAddress();\n\t\telse\n\t\t\treturn addr;\n\t}\n\n\tpublic boolean isRealInternetAddress(boolean lookup, boolean defaultVal, boolean allowLocalAddresses) {\n\t\tif(_address != null) {\n\t\t\treturn IPUtil.isValidAddress(_address, allowLocalAddresses);\n\t\t} else {\n\t\t\tif(lookup) {\n\t\t\t\tInetAddress a = getAddress();\n\t\t\t\tif(a != null)\n\t\t\t\t\treturn IPUtil.isValidAddress(a, allowLocalAddresses);\n\t\t\t}\n\t\t\treturn defaultVal;\t\n\t\t}\n\t}\n\n\t/**\n\t * Get a new <code>FreenetInetAddress<\/code> with host name removed.\n\t * \n\t * @return a new <code>FreenetInetAddress<\/code> with host name removed; or {@code null} if no\n\t *         known ip address is associated with this object. You may want to do a\n\t *         <code>getAddress(true)<\/code> before calling this.\n\t */\n\tpublic FreenetInetAddress dropHostname() {\n\t\tif(_address == null) {\n\t\t\tLogger.error(this, \"Can't dropHostname() if no address!\");\n\t\t\treturn null;\n\t\t}\n\t\tif(hostname != null) {\n\t\t\treturn new FreenetInetAddress(_address);\n\t\t} else return this;\n\t}\n\n\tpublic boolean hasHostname() {\n\t\treturn hostname != null && hostname.length() > 0;\n\t}\n\n\tpublic boolean hasHostnameNoIP() {\n\t\treturn hasHostname() && _address == null;\n\t}\n\n\tpublic boolean isIPv6(boolean defaultValue) {\n\t\tif(_address == null)\n\t\t\treturn defaultValue;\n\t\telse\n\t\t\treturn (_address instanceof Inet6Address);\n\t}\n}\n","Method after Refactoring":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.io.comm;\n\nimport java.io.DataInput;\nimport java.io.DataOutputStream;\nimport java.io.IOException;\nimport java.net.Inet6Address;\nimport java.net.InetAddress;\nimport java.net.UnknownHostException;\nimport java.util.Arrays;\n\nimport freenet.io.AddressIdentifier;\nimport freenet.support.LogThresholdCallback;\nimport freenet.support.Logger;\nimport freenet.support.Logger.LogLevel;\nimport freenet.support.io.InetAddressIpv6FirstComparator;\nimport freenet.support.transport.ip.HostnameSyntaxException;\nimport freenet.support.transport.ip.HostnameUtil;\nimport freenet.support.transport.ip.IPUtil;\n\n/**\n * Long-term InetAddress. If created with an IP address, then the IP address is primary.\n * If created with a name, then the name is primary, and the IP address can change.\n * Most code ripped from Peer.\n * \n * Propagates the IP address on equals() but not the hostname. This does not change \n * hashCode() because it only happens if hostname is set, and in that case, hashCode()\n * is based on the hostname and not on the IP address. So it is safe to put \n * FreenetInetAddress's into hashtables: neither equals() nor getAddress() will change\n * its hashCode.\n * \n * BUT a FreenetInetAddress with IP 1.2.3.4 and no hostname is *NOT* equal to one with\n * the IP address and no name. So if you want to match on only the IP address, you need\n * to either call dropHostname() first (after which neither propagation nor getAddress()\n * will change the hashcode), or just use InetAddress's.\n * \n * FIXME reconsider whether we need this. The lazy lookup is useful but not THAT useful,\n * and we have a regular lookup task now anyway. Over-complex, could lead to odd bugs, \n * although not if used correctly as explained above.\n * @author amphibian\n */\npublic class FreenetInetAddress {\n\n\tprivate static volatile boolean logMINOR;\n\tprivate static volatile boolean logDEBUG;\n\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t\tlogDEBUG = Logger.shouldLog(LogLevel.DEBUG, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t// hostname - only set if we were created with a hostname\n\t// and not an address\n\tprivate final String hostname;\n\tprivate InetAddress _address;\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis) throws IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\tthrow new IOException(\"Unknown type byte (old form? corrupt stream? too short/long prev field?): \"+firstByte);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n\t}\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException,\n\t        IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\t// Old format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tba[0] = (byte)firstByte;\n\t\t\tdis.readFully(ba, 1, 3);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n        if(checkHostnameOrIPSyntax && null != hostname) {\n        \tif(!HostnameUtil.isValidHostname(hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n\t}\n\n\t/**\n\t * Create from an InetAddress. The IP address is primary i.e. fixed.\n\t * The hostname either doesn't exist, or is looked up.\n\t */\n\tpublic FreenetInetAddress(InetAddress address) {\n\t\t_address = address;\n\t\thostname = null;\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown) throws UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n        \t// Is an IP address\n            addr = InetAddress.getByName(host);\n            // Don't catch UnknownHostException here, if it happens there's a bug in AddressIdentifier.\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+addr.getHostAddress()+ '\\'');\n            if(addr != null) {\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException, UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n            try {\n                addr = InetAddress.getByName(host);\n            } catch (UnknownHostException e) {\n            \tif(!allowUnknown) throw e;\n                addr = null;\n            }\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+(addr != null ? addr.getHostAddress()+ '\\'' : \"\"));\n            if(addr != null && addr.getHostAddress().equals(host)) {\n            \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' looks like an IP address\");\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        if(checkHostnameOrIPSyntax && null != this.hostname) {\n        \tif(!HostnameUtil.isValidHostname(this.hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\t\n\tpublic boolean laxEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null) {\n\t\t\t\tif(_address == null) return false; // No basis for comparison.\n\t\t\t\tif(addr._address != null) {\n\t\t\t\t\treturn _address.equals(addr._address);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\t\taddr._address = _address;\n\t\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t\t_address = addr._address;\n\t\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\t\treturn false;\n\t\t\t\t// Equal.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t// His hostname might not be null. Not a problem.\n\t\treturn _address.equals(addr._address);\n\t}\n\t\n\t@Override\n\tpublic boolean equals(Object o) {\n\t\tif(!(o instanceof FreenetInetAddress)) {\n\t\t\treturn false;\n\t\t}\n\t\tFreenetInetAddress addr = (FreenetInetAddress)o;\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t}\n\t\tif(addr.hostname != null)\n\t\t\treturn false;\n\n\t\t// No hostname, go by address.\n\t\tif(!_address.equals(addr._address)) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\tpublic boolean strictEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t} else if(addr.hostname != null /* && hostname == null */) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// No hostname, go by address.\n\t\tString reverseHostNameISee = getHostName(_address);\n\t\tString reverseHostNameTheySee = getHostName(addr._address);\n\t\tif(reverseHostNameISee == null\n\t\t\t\t|| !reverseHostNameISee.equalsIgnoreCase(reverseHostNameTheySee)) {\n\t\t\t//Logger.minor(this, \"Addresses do not match: mine=\"+getHostName(_address)+\" his=\"+getHostName(addr._address));\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\t/**\n\t * Get the IP address. Look it up if necessary, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress() {\n\t  return getAddress(true);\n\t}\n\n\t/**\n\t * Get the IP address. Look it up only if allowed to, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress(boolean doDNSRequest) {\n\t\tif (_address != null) {\n\t\t\treturn _address;\n\t\t} else {\n\t\t        if(!doDNSRequest) return null;\n\t\t        InetAddress addr = getHandshakeAddress();\n\t\t        if( addr != null ) {\n\t\t                this._address = addr;\n\t\t        }\n\t\t        return addr;\n\t\t}\n\t}\n\n\t/**\n\t * Get the IP address, looking up the hostname if the hostname is primary, even if\n\t * it has been looked up before. Typically called on a reconnect attempt, when the\n\t * dyndns address may have changed.\n\t */\n\tpublic InetAddress getHandshakeAddress() {\n\t    // Since we're handshaking, hostname-to-IP may have changed\n\t    if ((_address != null) && (hostname == null)) {\n\t    \tif(logMINOR) Logger.minor(this, \"hostname is null, returning \"+_address);\n\t        return _address;\n\t    } else {\n\t    \tif(logMINOR) Logger.minor(this, \"Looking up '\"+hostname+\"' in DNS\", new Exception(\"debug\"));\n\t        /* \n\t         * Peers are constructed from an address once a\n\t         * handshake has been completed, so this lookup\n\t         * will only be performed during a handshake\n\t         * (this method should normally only be called\n\t         * from PeerNode.getHandshakeIPs() and once\n\t         * each connection from this.getAddress()\n\t         * otherwise) - it doesn't mean we perform a\n\t         * DNS lookup with every packet we send.\n\t         */\n\t        try {\n\t        \tInetAddress[] addresses = InetAddress.getAllByName(hostname);\n\t        \tif(logMINOR) Logger.minor(this, \"Look up got '\"+addresses+ '\\'');\n\t        \tif( addresses.length != 0 ) {\n\t        \t\t/* sort by IPv6 first */\n                    Arrays.sort(addresses, InetAddressIpv6FirstComparator.COMPARATOR);\n                    /*\n\t        \t\t * cache the answer since getHandshakeAddress()\n\t        \t\t * doesn't use the cached value, thus\n\t        \t\t * getHandshakeIPs() should always get the\n\t        \t\t * latest value from DNS (minus Java's caching)\n\t        \t\t */\n\t        \t\tthis._address = InetAddress.getByAddress(addresses[0].getAddress());\n\t        \t\tif(logMINOR) Logger.minor(this, \"Setting address to \"+_address);\n\t        \t}\n\t        \treturn addresses[0];\n\t        } catch (UnknownHostException e) {\n\t        \tif(logMINOR) Logger.minor(this, \"DNS said hostname '\"+hostname+\"' is an unknown host, returning null\");\n\t            return null;\n\t        }\n\t    }\n\t}\n\n\t@Override\n\tpublic int hashCode() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname.hashCode(); // Was set at creation, so it can safely be used here.\n\t\t} else {\n\t\t\treturn _address.hashCode(); // Can be null, but if so, hostname will be non-null.\n\t\t}\n\t}\n\t\n\t@Override\n\tpublic String toString() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname;\n\t\t} else {\n\t\t\treturn _address.getHostAddress();\n\t\t}\n\t}\n\t\n\tpublic String toStringPrefNumeric() {\n\t\tif(_address != null)\n\t\t\treturn _address.getHostAddress();\n\t\telse\n\t\t\treturn hostname;\n\t}\n\n\tpublic void writeToDataOutputStream(DataOutputStream dos) throws IOException {\n\t\tInetAddress addr = this.getAddress();\n\t\tif (addr == null) throw new UnknownHostException();\n\t\tbyte[] data = addr.getAddress();\n\t\tif(data.length == 4)\n\t\t\tdos.write(0);\n\t\telse\n\t\t\tdos.write(255);\n\t\tdos.write(data);\n\t\tif(hostname != null)\n\t\t\tdos.writeUTF(hostname);\n\t\telse\n\t\t\tdos.writeUTF(\"\");\n\t}\n\n\t/**\n\t * Return the hostname or the IP address of the given InetAddress.\n\t * Does not attempt to do a reverse lookup; if the hostname is\n\t * known, return it, otherwise return the textual IP address.\n\t */\n\tpublic static String getHostName(InetAddress primaryIPAddress) {\n\t\tif(primaryIPAddress == null) return null;\n\t\tString s = primaryIPAddress.toString();\n\t\tString addr = s.substring(0, s.indexOf('/')).trim();\n\t\tif(addr.length() == 0)\n\t\t\treturn primaryIPAddress.getHostAddress();\n\t\telse\n\t\t\treturn addr;\n\t}\n\n\tpublic boolean isRealInternetAddress(boolean lookup, boolean defaultVal, boolean allowLocalAddresses) {\n\t\tif(_address != null) {\n\t\t\treturn IPUtil.isValidAddress(_address, allowLocalAddresses);\n\t\t} else {\n\t\t\tif(lookup) {\n\t\t\t\tInetAddress a = getAddress();\n\t\t\t\tif(a != null)\n\t\t\t\t\treturn IPUtil.isValidAddress(a, allowLocalAddresses);\n\t\t\t}\n\t\t\treturn defaultVal;\t\n\t\t}\n\t}\n\n\t/**\n\t * Get a new <code>FreenetInetAddress<\/code> with host name removed.\n\t * \n\t * @return a new <code>FreenetInetAddress<\/code> with host name removed; or {@code null} if no\n\t *         known ip address is associated with this object. You may want to do a\n\t *         <code>getAddress(true)<\/code> before calling this.\n\t */\n\tpublic FreenetInetAddress dropHostname() {\n\t\tif(_address == null) {\n\t\t\tLogger.error(this, \"Can't dropHostname() if no address!\");\n\t\t\treturn null;\n\t\t}\n\t\tif(hostname != null) {\n\t\t\treturn new FreenetInetAddress(_address);\n\t\t} else return this;\n\t}\n\n\tpublic boolean hasHostname() {\n\t\treturn hostname != null && hostname.length() > 0;\n\t}\n\n\tpublic boolean hasHostnameNoIP() {\n\t\treturn hasHostname() && _address == null;\n\t}\n\n\tpublic boolean isIPv6(boolean defaultValue) {\n\t\tif(_address == null)\n\t\t\treturn defaultValue;\n\t\telse\n\t\t\treturn (_address instanceof Inet6Address);\n\t}\n}\n","lineNo":284}
{"Smelly Sample":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.io.comm;\n\nimport java.io.DataInput;\nimport java.io.DataOutputStream;\nimport java.io.IOException;\nimport java.net.Inet6Address;\nimport java.net.InetAddress;\nimport java.net.UnknownHostException;\nimport java.util.Arrays;\n\nimport freenet.io.AddressIdentifier;\nimport freenet.support.LogThresholdCallback;\nimport freenet.support.Logger;\nimport freenet.support.Logger.LogLevel;\nimport freenet.support.io.InetAddressIpv6FirstComparator;\nimport freenet.support.transport.ip.HostnameSyntaxException;\nimport freenet.support.transport.ip.HostnameUtil;\nimport freenet.support.transport.ip.IPUtil;\n\n/**\n * Long-term InetAddress. If created with an IP address, then the IP address is primary.\n * If created with a name, then the name is primary, and the IP address can change.\n * Most code ripped from Peer.\n * \n * Propagates the IP address on equals() but not the hostname. This does not change \n * hashCode() because it only happens if hostname is set, and in that case, hashCode()\n * is based on the hostname and not on the IP address. So it is safe to put \n * FreenetInetAddress's into hashtables: neither equals() nor getAddress() will change\n * its hashCode.\n * \n * BUT a FreenetInetAddress with IP 1.2.3.4 and no hostname is *NOT* equal to one with\n * the IP address and no name. So if you want to match on only the IP address, you need\n * to either call dropHostname() first (after which neither propagation nor getAddress()\n * will change the hashcode), or just use InetAddress's.\n * \n * FIXME reconsider whether we need this. The lazy lookup is useful but not THAT useful,\n * and we have a regular lookup task now anyway. Over-complex, could lead to odd bugs, \n * although not if used correctly as explained above.\n * @author amphibian\n */\npublic class FreenetInetAddress {\n\n\tprivate static volatile boolean logMINOR;\n\tprivate static volatile boolean logDEBUG;\n\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t\tlogDEBUG = Logger.shouldLog(LogLevel.DEBUG, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t// hostname - only set if we were created with a hostname\n\t// and not an address\n\tprivate final String hostname;\n\tprivate InetAddress _address;\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis) throws IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\tthrow new IOException(\"Unknown type byte (old form? corrupt stream? too short/long prev field?): \"+firstByte);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n\t}\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException,\n\t        IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\t// Old format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tba[0] = (byte)firstByte;\n\t\t\tdis.readFully(ba, 1, 3);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n        if(checkHostnameOrIPSyntax && null != hostname) {\n        \tif(!HostnameUtil.isValidHostname(hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n\t}\n\n\t/**\n\t * Create from an InetAddress. The IP address is primary i.e. fixed.\n\t * The hostname either doesn't exist, or is looked up.\n\t */\n\tpublic FreenetInetAddress(InetAddress address) {\n\t\t_address = address;\n\t\thostname = null;\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown) throws UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n        \t// Is an IP address\n            addr = InetAddress.getByName(host);\n            // Don't catch UnknownHostException here, if it happens there's a bug in AddressIdentifier.\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+addr.getHostAddress()+ '\\'');\n            if(addr != null) {\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException, UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n            try {\n                addr = InetAddress.getByName(host);\n            } catch (UnknownHostException e) {\n            \tif(!allowUnknown) throw e;\n                addr = null;\n            }\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+(addr != null ? addr.getHostAddress()+ '\\'' : \"\"));\n            if(addr != null && addr.getHostAddress().equals(host)) {\n            \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' looks like an IP address\");\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        if(checkHostnameOrIPSyntax && null != this.hostname) {\n        \tif(!HostnameUtil.isValidHostname(this.hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\t\n\tpublic boolean laxEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null) {\n\t\t\t\tif(_address == null) return false; // No basis for comparison.\n\t\t\t\tif(addr._address != null) {\n\t\t\t\t\treturn _address.equals(addr._address);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\t\taddr._address = _address;\n\t\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t\t_address = addr._address;\n\t\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\t\treturn false;\n\t\t\t\t// Equal.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t// His hostname might not be null. Not a problem.\n\t\treturn _address.equals(addr._address);\n\t}\n\t\n\t@Override\n\tpublic boolean equals(Object o) {\n\t\tif(!(o instanceof FreenetInetAddress)) {\n\t\t\treturn false;\n\t\t}\n\t\tFreenetInetAddress addr = (FreenetInetAddress)o;\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t}\n\t\tif(addr.hostname != null)\n\t\t\treturn false;\n\n\t\t// No hostname, go by address.\n\t\tif(!_address.equals(addr._address)) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\tpublic boolean strictEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t} else if(addr.hostname != null /* && hostname == null */) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// No hostname, go by address.\n\t\tif(!getHostName(_address).equalsIgnoreCase(getHostName(addr._address))) {\n\t\t\t//Logger.minor(this, \"Addresses do not match: mine=\"+getHostName(_address)+\" his=\"+getHostName(addr._address));\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\t/**\n\t * Get the IP address. Look it up if necessary, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress() {\n\t  return getAddress(true);\n\t}\n\n\t/**\n\t * Get the IP address. Look it up only if allowed to, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress(boolean doDNSRequest) {\n\t\tif (_address != null) {\n\t\t\treturn _address;\n\t\t} else {\n\t\t        if(!doDNSRequest) return null;\n\t\t        InetAddress addr = getHandshakeAddress();\n\t\t        if( addr != null ) {\n\t\t                this._address = addr;\n\t\t        }\n\t\t        return addr;\n\t\t}\n\t}\n\n\t/**\n\t * Get the IP address, looking up the hostname if the hostname is primary, even if\n\t * it has been looked up before. Typically called on a reconnect attempt, when the\n\t * dyndns address may have changed.\n\t */\n\tpublic InetAddress getHandshakeAddress() {\n\t    // Since we're handshaking, hostname-to-IP may have changed\n\t    if ((_address != null) && (hostname == null)) {\n\t    \tif(logMINOR) Logger.minor(this, \"hostname is null, returning \"+_address);\n\t        return _address;\n\t    } else {\n\t    \tif(logMINOR) Logger.minor(this, \"Looking up '\"+hostname+\"' in DNS\", new Exception(\"debug\"));\n\t        /* \n\t         * Peers are constructed from an address once a\n\t         * handshake has been completed, so this lookup\n\t         * will only be performed during a handshake\n\t         * (this method should normally only be called\n\t         * from PeerNode.getHandshakeIPs() and once\n\t         * each connection from this.getAddress()\n\t         * otherwise) - it doesn't mean we perform a\n\t         * DNS lookup with every packet we send.\n\t         */\n\t        try {\n\t        \tInetAddress[] addresses = InetAddress.getAllByName(hostname);\n\t        \tif(logMINOR) Logger.minor(this, \"Look up got '\"+addresses+ '\\'');\n\t        \tif( addresses.length != 0 ) {\n\t        \t\t/* sort by IPv6 first */\n                    Arrays.sort(addresses, InetAddressIpv6FirstComparator.COMPARATOR);\n                    /*\n\t        \t\t * cache the answer since getHandshakeAddress()\n\t        \t\t * doesn't use the cached value, thus\n\t        \t\t * getHandshakeIPs() should always get the\n\t        \t\t * latest value from DNS (minus Java's caching)\n\t        \t\t */\n\t        \t\tthis._address = InetAddress.getByAddress(addresses[0].getAddress());\n\t        \t\tif(logMINOR) Logger.minor(this, \"Setting address to \"+_address);\n\t        \t}\n\t        \treturn addresses[0];\n\t        } catch (UnknownHostException e) {\n\t        \tif(logMINOR) Logger.minor(this, \"DNS said hostname '\"+hostname+\"' is an unknown host, returning null\");\n\t            return null;\n\t        }\n\t    }\n\t}\n\n\t@Override\n\tpublic int hashCode() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname.hashCode(); // Was set at creation, so it can safely be used here.\n\t\t} else {\n\t\t\treturn _address.hashCode(); // Can be null, but if so, hostname will be non-null.\n\t\t}\n\t}\n\t\n\t@Override\n\tpublic String toString() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname;\n\t\t} else {\n\t\t\treturn _address.getHostAddress();\n\t\t}\n\t}\n\t\n\tpublic String toStringPrefNumeric() {\n\t\tif(_address != null)\n\t\t\treturn _address.getHostAddress();\n\t\telse\n\t\t\treturn hostname;\n\t}\n\n\tpublic void writeToDataOutputStream(DataOutputStream dos) throws IOException {\n\t\tInetAddress addr = this.getAddress();\n\t\tif (addr == null) throw new UnknownHostException();\n\t\tbyte[] data = addr.getAddress();\n\t\tif(data.length == 4)\n\t\t\tdos.write(0);\n\t\telse\n\t\t\tdos.write(255);\n\t\tdos.write(data);\n\t\tif(hostname != null)\n\t\t\tdos.writeUTF(hostname);\n\t\telse\n\t\t\tdos.writeUTF(\"\");\n\t}\n\n\t/**\n\t * Return the hostname or the IP address of the given InetAddress.\n\t * Does not attempt to do a reverse lookup; if the hostname is\n\t * known, return it, otherwise return the textual IP address.\n\t */\n\tpublic static String getHostName(InetAddress primaryIPAddress) {\n\t\tif(primaryIPAddress == null) return null;\n\t\tString s = primaryIPAddress.toString();\n\t\tString addr = s.substring(0, s.indexOf('/')).trim();\n\t\tif(addr.length() == 0)\n\t\t\treturn primaryIPAddress.getHostAddress();\n\t\telse\n\t\t\treturn addr;\n\t}\n\n\tpublic boolean isRealInternetAddress(boolean lookup, boolean defaultVal, boolean allowLocalAddresses) {\n\t\tif(_address != null) {\n\t\t\treturn IPUtil.isValidAddress(_address, allowLocalAddresses);\n\t\t} else {\n\t\t\tif(lookup) {\n\t\t\t\tInetAddress a = getAddress();\n\t\t\t\tif(a != null)\n\t\t\t\t\treturn IPUtil.isValidAddress(a, allowLocalAddresses);\n\t\t\t}\n\t\t\treturn defaultVal;\t\n\t\t}\n\t}\n\n\t/**\n\t * Get a new <code>FreenetInetAddress<\/code> with host name removed.\n\t * \n\t * @return a new <code>FreenetInetAddress<\/code> with host name removed; or {@code null} if no\n\t *         known ip address is associated with this object. You may want to do a\n\t *         <code>getAddress(true)<\/code> before calling this.\n\t */\n\tpublic FreenetInetAddress dropHostname() {\n\t\tif(_address == null) {\n\t\t\tLogger.error(this, \"Can't dropHostname() if no address!\");\n\t\t\treturn null;\n\t\t}\n\t\tif(hostname != null) {\n\t\t\treturn new FreenetInetAddress(_address);\n\t\t} else return this;\n\t}\n\n\tpublic boolean hasHostname() {\n\t\treturn hostname != null && hostname.length() > 0;\n\t}\n\n\tpublic boolean hasHostnameNoIP() {\n\t\treturn hasHostname() && _address == null;\n\t}\n\n\tpublic boolean isIPv6(boolean defaultValue) {\n\t\tif(_address == null)\n\t\t\treturn defaultValue;\n\t\telse\n\t\t\treturn (_address instanceof Inet6Address);\n\t}\n}\n","Method after Refactoring":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.io.comm;\n\nimport java.io.DataInput;\nimport java.io.DataOutputStream;\nimport java.io.IOException;\nimport java.net.Inet6Address;\nimport java.net.InetAddress;\nimport java.net.UnknownHostException;\nimport java.util.Arrays;\n\nimport freenet.io.AddressIdentifier;\nimport freenet.support.LogThresholdCallback;\nimport freenet.support.Logger;\nimport freenet.support.Logger.LogLevel;\nimport freenet.support.io.InetAddressIpv6FirstComparator;\nimport freenet.support.transport.ip.HostnameSyntaxException;\nimport freenet.support.transport.ip.HostnameUtil;\nimport freenet.support.transport.ip.IPUtil;\n\n/**\n * Long-term InetAddress. If created with an IP address, then the IP address is primary.\n * If created with a name, then the name is primary, and the IP address can change.\n * Most code ripped from Peer.\n * \n * Propagates the IP address on equals() but not the hostname. This does not change \n * hashCode() because it only happens if hostname is set, and in that case, hashCode()\n * is based on the hostname and not on the IP address. So it is safe to put \n * FreenetInetAddress's into hashtables: neither equals() nor getAddress() will change\n * its hashCode.\n * \n * BUT a FreenetInetAddress with IP 1.2.3.4 and no hostname is *NOT* equal to one with\n * the IP address and no name. So if you want to match on only the IP address, you need\n * to either call dropHostname() first (after which neither propagation nor getAddress()\n * will change the hashcode), or just use InetAddress's.\n * \n * FIXME reconsider whether we need this. The lazy lookup is useful but not THAT useful,\n * and we have a regular lookup task now anyway. Over-complex, could lead to odd bugs, \n * although not if used correctly as explained above.\n * @author amphibian\n */\npublic class FreenetInetAddress {\n\n\tprivate static volatile boolean logMINOR;\n\tprivate static volatile boolean logDEBUG;\n\n\tstatic {\n\t\tLogger.registerLogThresholdCallback(new LogThresholdCallback(){\n\t\t\t@Override\n\t\t\tpublic void shouldUpdate(){\n\t\t\t\tlogMINOR = Logger.shouldLog(LogLevel.MINOR, this);\n\t\t\t\tlogDEBUG = Logger.shouldLog(LogLevel.DEBUG, this);\n\t\t\t}\n\t\t});\n\t}\n\n\t// hostname - only set if we were created with a hostname\n\t// and not an address\n\tprivate final String hostname;\n\tprivate InetAddress _address;\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis) throws IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\tthrow new IOException(\"Unknown type byte (old form? corrupt stream? too short/long prev field?): \"+firstByte);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n\t}\n\n\t/**\n\t * Create from serialized form on a DataInputStream.\n\t */\n\tpublic FreenetInetAddress(DataInput dis, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException,\n\t        IOException {\n\t\tint firstByte = dis.readUnsignedByte();\n\t\tbyte[] ba;\n\t\tif(firstByte == 255) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv6 address\");\n\t\t\t// New format IPv6 address\n\t\t\tba = new byte[16];\n\t\t\tdis.readFully(ba);\n\t\t} else if(firstByte == 0) {\n\t\t\tif(logMINOR) Logger.minor(this, \"New format IPv4 address\");\n\t\t\t// New format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tdis.readFully(ba);\n\t\t} else {\n\t\t\t// Old format IPv4 address\n\t\t\tba = new byte[4];\n\t\t\tba[0] = (byte)firstByte;\n\t\t\tdis.readFully(ba, 1, 3);\n\t\t}\n\t\t_address = InetAddress.getByAddress(ba);\n\t\tString name = null;\n\t\tString s = dis.readUTF();\n\t\tif(s.length() > 0)\n\t\t\tname = s;\n\t\thostname = name;\n        if(checkHostnameOrIPSyntax && null != hostname) {\n        \tif(!HostnameUtil.isValidHostname(hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n\t}\n\n\t/**\n\t * Create from an InetAddress. The IP address is primary i.e. fixed.\n\t * The hostname either doesn't exist, or is looked up.\n\t */\n\tpublic FreenetInetAddress(InetAddress address) {\n\t\t_address = address;\n\t\thostname = null;\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown) throws UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n        \t// Is an IP address\n            addr = InetAddress.getByName(host);\n            // Don't catch UnknownHostException here, if it happens there's a bug in AddressIdentifier.\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+addr.getHostAddress()+ '\\'');\n            if(addr != null) {\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\n\tpublic FreenetInetAddress(String host, boolean allowUnknown, boolean checkHostnameOrIPSyntax) throws HostnameSyntaxException, UnknownHostException {\n        InetAddress addr = null;\n        if(host != null){\n        \tif(host.startsWith(\"/\")) host = host.substring(1);\n        \thost = host.trim();\n        }\n        // if we were created with an explicit IP address, use it as such\n        // debugging log messages because AddressIdentifier doesn't appear to handle all IPv6 literals correctly, such as \"fe80::204:1234:dead:beef\"\n        AddressIdentifier.AddressType addressType = AddressIdentifier.getAddressType(host);\n        if(logDEBUG) Logger.debug(this, \"Address type of '\"+host+\"' appears to be '\"+addressType+ '\\'');\n        if(addressType != AddressIdentifier.AddressType.OTHER) {\n            try {\n                addr = InetAddress.getByName(host);\n            } catch (UnknownHostException e) {\n            \tif(!allowUnknown) throw e;\n                addr = null;\n            }\n            if(logDEBUG) Logger.debug(this, \"host is '\"+host+\"' and addr.getHostAddress() is '\"+(addr != null ? addr.getHostAddress()+ '\\'' : \"\"));\n            if(addr != null && addr.getHostAddress().equals(host)) {\n            \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' looks like an IP address\");\n                host = null;\n            } else {\n                addr = null;\n            }\n        }\n        if( addr == null ) {\n        \tif(logDEBUG) Logger.debug(this, '\\'' +host+\"' does not look like an IP address\");\n        }\n        this._address = addr;\n        this.hostname = host;\n        if(checkHostnameOrIPSyntax && null != this.hostname) {\n        \tif(!HostnameUtil.isValidHostname(this.hostname, true)) throw new HostnameSyntaxException();\n\t\t}\n        // we're created with a hostname so delay the lookup of the address\n        // until it's needed to work better with dynamic DNS hostnames\n\t}\n\t\n\tpublic boolean laxEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null) {\n\t\t\t\tif(_address == null) return false; // No basis for comparison.\n\t\t\t\tif(addr._address != null) {\n\t\t\t\t\treturn _address.equals(addr._address);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\t\taddr._address = _address;\n\t\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t\t_address = addr._address;\n\t\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\t\treturn false;\n\t\t\t\t// Equal.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t// His hostname might not be null. Not a problem.\n\t\treturn _address.equals(addr._address);\n\t}\n\t\n\t@Override\n\tpublic boolean equals(Object o) {\n\t\tif(!(o instanceof FreenetInetAddress)) {\n\t\t\treturn false;\n\t\t}\n\t\tFreenetInetAddress addr = (FreenetInetAddress)o;\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t}\n\t\tif(addr.hostname != null)\n\t\t\treturn false;\n\n\t\t// No hostname, go by address.\n\t\tif(!_address.equals(addr._address)) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\tpublic boolean strictEquals(FreenetInetAddress addr) {\n\t\tif(hostname != null) {\n\t\t\tif(addr.hostname == null)\n\t\t\t\treturn false;\n\t\t\tif (!hostname.equalsIgnoreCase(addr.hostname)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t// Now that we know we have the same hostname, we can propagate the IP.\n\t\t\tif((_address != null) && (addr._address == null))\n\t\t\t\taddr._address = _address;\n\t\t\tif((addr._address != null) && (_address == null))\n\t\t\t\t_address = addr._address;\n\t\t\t// Except if we actually do have two different looked-up IPs!\n\t\t\tif((addr._address != null) && (_address != null) && !addr._address.equals(_address))\n\t\t\t\treturn false;\n\t\t\t// Equal.\n\t\t\treturn true;\n\t\t} else if(addr.hostname != null /* && hostname == null */) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// No hostname, go by address.\n\t\tString reverseHostNameISee = getHostName(_address);\n\t\tString reverseHostNameTheySee = getHostName(addr._address);\n\t\tif(reverseHostNameISee == null\n\t\t\t\t|| !reverseHostNameISee.equalsIgnoreCase(reverseHostNameTheySee)) {\n\t\t\t//Logger.minor(this, \"Addresses do not match: mine=\"+getHostName(_address)+\" his=\"+getHostName(addr._address));\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn true;\n\t}\n\n\t/**\n\t * Get the IP address. Look it up if necessary, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress() {\n\t  return getAddress(true);\n\t}\n\n\t/**\n\t * Get the IP address. Look it up only if allowed to, but return the last value if it\n\t * has ever been looked up before; will not trigger a new lookup if it has been\n\t * looked up before.\n\t */\n\tpublic InetAddress getAddress(boolean doDNSRequest) {\n\t\tif (_address != null) {\n\t\t\treturn _address;\n\t\t} else {\n\t\t        if(!doDNSRequest) return null;\n\t\t        InetAddress addr = getHandshakeAddress();\n\t\t        if( addr != null ) {\n\t\t                this._address = addr;\n\t\t        }\n\t\t        return addr;\n\t\t}\n\t}\n\n\t/**\n\t * Get the IP address, looking up the hostname if the hostname is primary, even if\n\t * it has been looked up before. Typically called on a reconnect attempt, when the\n\t * dyndns address may have changed.\n\t */\n\tpublic InetAddress getHandshakeAddress() {\n\t    // Since we're handshaking, hostname-to-IP may have changed\n\t    if ((_address != null) && (hostname == null)) {\n\t    \tif(logMINOR) Logger.minor(this, \"hostname is null, returning \"+_address);\n\t        return _address;\n\t    } else {\n\t    \tif(logMINOR) Logger.minor(this, \"Looking up '\"+hostname+\"' in DNS\", new Exception(\"debug\"));\n\t        /* \n\t         * Peers are constructed from an address once a\n\t         * handshake has been completed, so this lookup\n\t         * will only be performed during a handshake\n\t         * (this method should normally only be called\n\t         * from PeerNode.getHandshakeIPs() and once\n\t         * each connection from this.getAddress()\n\t         * otherwise) - it doesn't mean we perform a\n\t         * DNS lookup with every packet we send.\n\t         */\n\t        try {\n\t        \tInetAddress[] addresses = InetAddress.getAllByName(hostname);\n\t        \tif(logMINOR) Logger.minor(this, \"Look up got '\"+addresses+ '\\'');\n\t        \tif( addresses.length != 0 ) {\n\t        \t\t/* sort by IPv6 first */\n                    Arrays.sort(addresses, InetAddressIpv6FirstComparator.COMPARATOR);\n                    /*\n\t        \t\t * cache the answer since getHandshakeAddress()\n\t        \t\t * doesn't use the cached value, thus\n\t        \t\t * getHandshakeIPs() should always get the\n\t        \t\t * latest value from DNS (minus Java's caching)\n\t        \t\t */\n\t        \t\tthis._address = InetAddress.getByAddress(addresses[0].getAddress());\n\t        \t\tif(logMINOR) Logger.minor(this, \"Setting address to \"+_address);\n\t        \t}\n\t        \treturn addresses[0];\n\t        } catch (UnknownHostException e) {\n\t        \tif(logMINOR) Logger.minor(this, \"DNS said hostname '\"+hostname+\"' is an unknown host, returning null\");\n\t            return null;\n\t        }\n\t    }\n\t}\n\n\t@Override\n\tpublic int hashCode() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname.hashCode(); // Was set at creation, so it can safely be used here.\n\t\t} else {\n\t\t\treturn _address.hashCode(); // Can be null, but if so, hostname will be non-null.\n\t\t}\n\t}\n\t\n\t@Override\n\tpublic String toString() {\n\t\tif(hostname != null) {\n\t\t\treturn hostname;\n\t\t} else {\n\t\t\treturn _address.getHostAddress();\n\t\t}\n\t}\n\t\n\tpublic String toStringPrefNumeric() {\n\t\tif(_address != null)\n\t\t\treturn _address.getHostAddress();\n\t\telse\n\t\t\treturn hostname;\n\t}\n\n\tpublic void writeToDataOutputStream(DataOutputStream dos) throws IOException {\n\t\tInetAddress addr = this.getAddress();\n\t\tif (addr == null) throw new UnknownHostException();\n\t\tbyte[] data = addr.getAddress();\n\t\tif(data.length == 4)\n\t\t\tdos.write(0);\n\t\telse\n\t\t\tdos.write(255);\n\t\tdos.write(data);\n\t\tif(hostname != null)\n\t\t\tdos.writeUTF(hostname);\n\t\telse\n\t\t\tdos.writeUTF(\"\");\n\t}\n\n\t/**\n\t * Return the hostname or the IP address of the given InetAddress.\n\t * Does not attempt to do a reverse lookup; if the hostname is\n\t * known, return it, otherwise return the textual IP address.\n\t */\n\tpublic static String getHostName(InetAddress primaryIPAddress) {\n\t\tif(primaryIPAddress == null) return null;\n\t\tString s = primaryIPAddress.toString();\n\t\tString addr = s.substring(0, s.indexOf('/')).trim();\n\t\tif(addr.length() == 0)\n\t\t\treturn primaryIPAddress.getHostAddress();\n\t\telse\n\t\t\treturn addr;\n\t}\n\n\tpublic boolean isRealInternetAddress(boolean lookup, boolean defaultVal, boolean allowLocalAddresses) {\n\t\tif(_address != null) {\n\t\t\treturn IPUtil.isValidAddress(_address, allowLocalAddresses);\n\t\t} else {\n\t\t\tif(lookup) {\n\t\t\t\tInetAddress a = getAddress();\n\t\t\t\tif(a != null)\n\t\t\t\t\treturn IPUtil.isValidAddress(a, allowLocalAddresses);\n\t\t\t}\n\t\t\treturn defaultVal;\t\n\t\t}\n\t}\n\n\t/**\n\t * Get a new <code>FreenetInetAddress<\/code> with host name removed.\n\t * \n\t * @return a new <code>FreenetInetAddress<\/code> with host name removed; or {@code null} if no\n\t *         known ip address is associated with this object. You may want to do a\n\t *         <code>getAddress(true)<\/code> before calling this.\n\t */\n\tpublic FreenetInetAddress dropHostname() {\n\t\tif(_address == null) {\n\t\t\tLogger.error(this, \"Can't dropHostname() if no address!\");\n\t\t\treturn null;\n\t\t}\n\t\tif(hostname != null) {\n\t\t\treturn new FreenetInetAddress(_address);\n\t\t} else return this;\n\t}\n\n\tpublic boolean hasHostname() {\n\t\treturn hostname != null && hostname.length() > 0;\n\t}\n\n\tpublic boolean hasHostnameNoIP() {\n\t\treturn hasHostname() && _address == null;\n\t}\n\n\tpublic boolean isIPv6(boolean defaultValue) {\n\t\tif(_address == null)\n\t\t\treturn defaultValue;\n\t\telse\n\t\t\treturn (_address instanceof Inet6Address);\n\t}\n}\n","lineNo":285}
{"Smelly Sample":"package freenet.clients.http.wizardsteps;\n\nimport freenet.clients.http.FirstTimeWizardToadlet;\nimport freenet.config.Config;\nimport freenet.config.ConfigException;\nimport freenet.config.Option;\nimport freenet.l10n.NodeL10n;\nimport freenet.node.Node;\nimport freenet.node.NodeClientCore;\nimport freenet.node.NodeStarter;\nimport freenet.support.Fields;\nimport freenet.support.HTMLNode;\nimport freenet.support.Logger;\nimport freenet.support.SizeUtil;\nimport freenet.support.api.HTTPRequest;\n\n/**\n * Allows the user to select datastore size, considering available storage space when offering options.\n */\npublic class DATASTORE_SIZE implements Step {\n\n\tprivate final NodeClientCore core;\n\tprivate final Config config;\n\n\tpublic DATASTORE_SIZE(NodeClientCore core, Config config) {\n\t\tthis.config = config;\n\t\tthis.core = core;\n\t}\n\n\t@Override\n\tpublic void getStep(HTTPRequest request, PageHelper helper) {\n\t\tHTMLNode contentNode = helper.getPageContent(WizardL10n.l10n(\"step4Title\"));\n\t\tHTMLNode bandwidthInfoboxContent = helper.getInfobox(\"infobox-header\", WizardL10n.l10n(\"datastoreSize\"),\n\t\t        contentNode, null, false);\n\n\t\tbandwidthInfoboxContent.addChild(\"#\", WizardL10n.l10n(\"datastoreSizeLong\"));\n\t\tHTMLNode bandwidthForm = helper.addFormChild(bandwidthInfoboxContent, \".\", \"dsForm\");\n\t\tHTMLNode result = bandwidthForm.addChild(\"select\", \"name\", \"ds\");\n\n\t\tlong maxSize = maxDatastoreSize();\n\n\t\tlong autodetectedSize = canAutoconfigureDatastoreSize();\n\t\tif(maxSize < autodetectedSize) autodetectedSize = maxSize;\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tOption<Long> sizeOption = (Option<Long>) config.get(\"node\").getOption(\"storeSize\");\n\t\tif(!sizeOption.isDefault()) {\n\t\t\tlong current = sizeOption.getValue();\n\t\t\tresult.addChild(\"option\",\n\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t        new String[] { SizeUtil.formatSize(current), \"on\" }, WizardL10n.l10n(\"currentPrefix\")+\" \"+SizeUtil.formatSize(current));\n\t\t} else if(autodetectedSize != -1) {\n\t\t\tresult.addChild(\"option\",\n\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t        new String[] { SizeUtil.formatSize(autodetectedSize), \"on\" }, SizeUtil.formatSize(autodetectedSize));\n\t\t}\n\t\tif(autodetectedSize != 512*1024*1024) {\n\t\t\tresult.addChild(\"option\", \"value\", \"512M\", \"512 MiB\");\n\t\t}\n\t\t// We always allow at least 1GB\n\t\tresult.addChild(\"option\", \"value\", \"1G\", \"1 GiB\");\n\t\tif(maxSize >= 2l*1024*1024*1024) {\n\t\t\tif(autodetectedSize != -1 || !sizeOption.isDefault()) {\n\t\t\t\tresult.addChild(\"option\", \"value\", \"2G\", \"2 GiB\");\n\t\t\t} else {\n\t\t\t\tresult.addChild(\"option\",\n\t\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t\t        new String[] { \"2G\", \"on\" }, \"2GiB\");\n\t\t\t}\n\t\t}\n\t\tif(maxSize >= 3l*1024*1024*1024) result.addChild(\"option\", \"value\", \"3G\", \"3 GiB\");\n\t\tif(maxSize >= 5l*1024*1024*1024) result.addChild(\"option\", \"value\", \"5G\", \"5 GiB\");\n\t\tif(maxSize >= 10l*1024*1024*1024) result.addChild(\"option\", \"value\", \"10G\", \"10 GiB\");\n\t\tif(maxSize >= 20l*1024*1024*1024) result.addChild(\"option\", \"value\", \"20G\", \"20 GiB\");\n\t\tif(maxSize >= 50l*1024*1024*1024) result.addChild(\"option\", \"value\", \"50G\", \"50 GiB\");\n\t\tif(maxSize >= 200l*1024*1024*1024) result.addChild(\"option\", \"value\", \"200G\", \"200GiB\");\n\t\tif(maxSize >= 500l*1024*1024*1024) result.addChild(\"option\", \"value\", \"500G\", \"500GiB\");\n\n\t\t//Put buttons below dropdown.\n\t\tHTMLNode below = bandwidthForm.addChild(\"div\");\n\t\tbelow.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"back\", NodeL10n.getBase().getString(\"Toadlet.back\")});\n\t\tbelow.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"next\", NodeL10n.getBase().getString(\"Toadlet.next\")});\n\t}\n\n\t@Override\n\tpublic String postStep(HTTPRequest request) {\n\t\t// drop down options may be 6 chars or less, but formatted ones e.g. old value if re-running can be more\n\t\t_setDatastoreSize(request.getPartAsStringFailsafe(\"ds\", 20));\n\t\treturn FirstTimeWizardToadlet.WIZARD_STEP.BANDWIDTH.name();\n\t}\n\n\tprivate void _setDatastoreSize(String selectedStoreSize) {\n\t\ttry {\n\t\t\tlong size = Fields.parseLong(selectedStoreSize);\n\t\t\t// client cache: 10% up to 200MB\n\t\t\tlong clientCacheSize = Math.min(size / 10, 200*1024*1024);\n\t\t\t// recent requests cache / slashdot cache / ULPR cache\n\t\t\tint upstreamLimit = config.get(\"node\").getInt(\"outputBandwidthLimit\");\n\t\t\tint downstreamLimit = config.get(\"node\").getInt(\"inputBandwidthLimit\");\n\t\t\t// is used for remote stuff, so go by the minimum of the two\n\t\t\tint limit;\n\t\t\tif(downstreamLimit <= 0) limit = upstreamLimit;\n\t\t\telse limit = Math.min(downstreamLimit, upstreamLimit);\n\t\t\t// 35KB/sec limit has been seen to have 0.5 store writes per second.\n\t\t\t// So saying we want to have space to cache everything is only doubling that ...\n\t\t\t// OTOH most stuff is at low enough HTL to go to the datastore and thus not to\n\t\t\t// the slashdot cache, so we could probably cut this significantly...\n\t\t\tlong lifetime = config.get(\"node\").getLong(\"slashdotCacheLifetime\");\n\t\t\tlong maxSlashdotCacheSize = (lifetime / 1000) * limit;\n\t\t\tlong slashdotCacheSize = Math.min(size / 10, maxSlashdotCacheSize);\n\n\t\t\tlong storeSize = size - (clientCacheSize + slashdotCacheSize);\n\n\t\t\tSystem.out.println(\"Setting datastore size to \"+Fields.longToString(storeSize, true));\n\t\t\tconfig.get(\"node\").set(\"storeSize\", Fields.longToString(storeSize, true));\n\t\t\tif(config.get(\"node\").getString(\"storeType\").equals(\"ram\"))\n\t\t\t\tconfig.get(\"node\").set(\"storeType\", \"salt-hash\");\n\t\t\tSystem.out.println(\"Setting client cache size to \"+Fields.longToString(clientCacheSize, true));\n\t\t\tconfig.get(\"node\").set(\"clientCacheSize\", Fields.longToString(clientCacheSize, true));\n\t\t\tif(config.get(\"node\").getString(\"clientCacheType\").equals(\"ram\"))\n\t\t\t\tconfig.get(\"node\").set(\"clientCacheType\", \"salt-hash\");\n\t\t\tSystem.out.println(\"Setting slashdot/ULPR/recent requests cache size to \"+Fields.longToString(slashdotCacheSize, true));\n\t\t\tconfig.get(\"node\").set(\"slashdotCacheSize\", Fields.longToString(slashdotCacheSize, true));\n\n\n\t\t\tLogger.normal(this, \"The storeSize has been set to \" + selectedStoreSize);\n\t\t} catch(ConfigException e) {\n\t\t\tLogger.error(this, \"Should not happen, please report!\" + e, e);\n\t\t}\n\t}\n\n\tprivate long maxDatastoreSize() {\n\t\tlong maxMemory = NodeStarter.getMemoryLimitBytes();\n\t\tif(maxMemory == Long.MAX_VALUE) return 1024*1024*1024; // Treat as don't know.\n\t\tif(maxMemory < 128*1024*1024) return 1024*1024*1024; // 1GB default if don't know or very small memory.\n\t\t// Don't use the first 100MB for slot filters.\n\t\tlong available = maxMemory - 100*1024*1024;\n\t\t// Don't use more than 50% of available memory for slot filters.\n\t\tavailable = available / 2;\n\t\t// Slot filters are 4 bytes per slot.\n\t\tlong slots = available / 4;\n\t\t// There are 3 types of keys. We want the number of { SSK, CHK, pubkey } i.e. the number of slots in each store.\n\t\tslots /= 3;\n\t\t// We return the total size, so we don't need to worry about cache vs store or even client cache.\n\t\t// One key of all 3 types combined uses Node.sizePerKey bytes on disk. So we get a size.\n\t\treturn slots * Node.sizePerKey;\n\t}\n\n    private long canAutoconfigureDatastoreSize() {\n        if (!config.get(\"node\").getOption(\"storeSize\").isDefault())\n            return -1;\n\n        long freeSpace = core.node.getStoreDir().getUsableSpace();\n\n        if (freeSpace <= 0) {\n            return -1;\n        } else {\n            long shortSize;\n            long oneGiB = 1024 * 1024 * 1024L;\n            // Maximum for Freenet: 256GB. That's a 128MiB bloom filter.\n            long bloomFilter128MiBMax = 256 * oneGiB;\n            // Maximum to suggest to keep Disk I/O managable. This\n            // value might need revisiting when hardware or\n            // filesystems change.\n            long diskIoMax = 20 * oneGiB;\n\n            // Choose a suggested store size based on available free space.\n            if (freeSpace > 50 * oneGiB) {\n                // > 50 GiB: Use 10% free space; minimum 10 GiB. Limited by\n                // bloom filters and disk I/O.\n                shortSize = Math.max(10 * oneGiB,\n                                     Math.min(freeSpace / 10,\n                                              Math.min(diskIoMax,\n                                                       bloomFilter128MiBMax)));\n            } else if (freeSpace > 5 * oneGiB) {\n                // > 5 GiB: Use 20% free space, minimum 2 GiB.\n                shortSize = Math.max(freeSpace / 5, 2 * oneGiB);\n            } else if (freeSpace > 2 * oneGiB) {\n                // > 2 GiB: 512 MiB.\n                shortSize = 512 * (1024 * 1024);\n            } else {\n                // <= 2 GiB: 256 MiB.\n                shortSize = 256 * (1024 * 1024);\n            }\n\n            return shortSize;\n        }\n    }\n}\n","Method after Refactoring":"package freenet.clients.http.wizardsteps;\n\nimport freenet.clients.http.FirstTimeWizardToadlet;\nimport freenet.config.Config;\nimport freenet.config.ConfigException;\nimport freenet.config.Option;\nimport freenet.l10n.NodeL10n;\nimport freenet.node.Node;\nimport freenet.node.NodeClientCore;\nimport freenet.node.NodeStarter;\nimport freenet.support.Fields;\nimport freenet.support.HTMLNode;\nimport freenet.support.Logger;\nimport freenet.support.SizeUtil;\nimport freenet.support.api.HTTPRequest;\n\n/**\n * Allows the user to select datastore size, considering available storage space when offering options.\n */\npublic class DATASTORE_SIZE implements Step {\n\n\tprivate final NodeClientCore core;\n\tprivate final Config config;\n\n\tpublic DATASTORE_SIZE(NodeClientCore core, Config config) {\n\t\tthis.config = config;\n\t\tthis.core = core;\n\t}\n\n\t@Override\n\tpublic void getStep(HTTPRequest request, PageHelper helper) {\n\t\tHTMLNode contentNode = helper.getPageContent(WizardL10n.l10n(\"step4Title\"));\n\t\tHTMLNode bandwidthInfoboxContent = helper.getInfobox(\"infobox-header\", WizardL10n.l10n(\"datastoreSize\"),\n\t\t        contentNode, null, false);\n\n\t\tbandwidthInfoboxContent.addChild(\"#\", WizardL10n.l10n(\"datastoreSizeLong\"));\n\t\tHTMLNode bandwidthForm = helper.addFormChild(bandwidthInfoboxContent, \".\", \"dsForm\");\n\t\tHTMLNode result = bandwidthForm.addChild(\"select\", \"name\", \"ds\");\n\n\t\tlong maxSize = maxDatastoreSize();\n\n\t\tlong autodetectedSize = canAutoconfigureDatastoreSize();\n\t\tif(maxSize < autodetectedSize) autodetectedSize = maxSize;\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tOption<Long> sizeOption = (Option<Long>) config.get(\"node\").getOption(\"storeSize\");\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tOption<Long> clientCacheSizeOption = (Option<Long>) config.get(\"node\").getOption(\"clientCacheSize\");\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tOption<Long> slashdotCacheSizeOption = (Option<Long>) config.get(\"node\").getOption(\"slashdotCacheSize\");\n\t\tif(!sizeOption.isDefault()) {\n\t\t\tlong current = sizeOption.getValue();\n\t\t\tlong currentTotal = current;\n\t\t\tif (!clientCacheSizeOption.isDefault() && !slashdotCacheSizeOption.isDefault()) {\n\t\t\t\tcurrentTotal += clientCacheSizeOption.getValue() + slashdotCacheSizeOption.getValue();\n\t\t\t}\n\t\t\tresult.addChild(\"option\",\n\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t        new String[] { SizeUtil.formatSize(currentTotal), \"on\" }, WizardL10n.l10n(\"currentPrefix\")+\" \"+SizeUtil.formatSize(currentTotal));\n\t\t} else if(autodetectedSize != -1) {\n\t\t\tresult.addChild(\"option\",\n\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t        new String[] { SizeUtil.formatSize(autodetectedSize), \"on\" }, SizeUtil.formatSize(autodetectedSize));\n\t\t}\n\t\tif(autodetectedSize != 512*1024*1024) {\n\t\t\tresult.addChild(\"option\", \"value\", \"512M\", \"512 MiB\");\n\t\t}\n\t\t// We always allow at least 1GB\n\t\tresult.addChild(\"option\", \"value\", \"1G\", \"1 GiB\");\n\t\tif(maxSize >= 2l*1024*1024*1024) {\n\t\t\tif(autodetectedSize != -1 || !sizeOption.isDefault()) {\n\t\t\t\tresult.addChild(\"option\", \"value\", \"2G\", \"2 GiB\");\n\t\t\t} else {\n\t\t\t\tresult.addChild(\"option\",\n\t\t\t\t        new String[] { \"value\", \"selected\" },\n\t\t\t\t        new String[] { \"2G\", \"on\" }, \"2GiB\");\n\t\t\t}\n\t\t}\n\t\tif(maxSize >= 3l*1024*1024*1024) result.addChild(\"option\", \"value\", \"3G\", \"3 GiB\");\n\t\tif(maxSize >= 5l*1024*1024*1024) result.addChild(\"option\", \"value\", \"5G\", \"5 GiB\");\n\t\tif(maxSize >= 10l*1024*1024*1024) result.addChild(\"option\", \"value\", \"10G\", \"10 GiB\");\n\t\tif(maxSize >= 20l*1024*1024*1024) result.addChild(\"option\", \"value\", \"20G\", \"20 GiB\");\n\t\tif(maxSize >= 50l*1024*1024*1024) result.addChild(\"option\", \"value\", \"50G\", \"50 GiB\");\n\t\tif(maxSize >= 200l*1024*1024*1024) result.addChild(\"option\", \"value\", \"200G\", \"200GiB\");\n\t\tif(maxSize >= 500l*1024*1024*1024) result.addChild(\"option\", \"value\", \"500G\", \"500GiB\");\n\n\t\t//Put buttons below dropdown.\n\t\tHTMLNode below = bandwidthForm.addChild(\"div\");\n\t\tbelow.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"back\", NodeL10n.getBase().getString(\"Toadlet.back\")});\n\t\tbelow.addChild(\"input\",\n\t\t        new String[] { \"type\", \"name\", \"value\" },\n\t\t        new String[] { \"submit\", \"next\", NodeL10n.getBase().getString(\"Toadlet.next\")});\n\t}\n\n\t@Override\n\tpublic String postStep(HTTPRequest request) {\n\t\t// drop down options may be 6 chars or less, but formatted ones e.g. old value if re-running can be more\n\t\t_setDatastoreSize(request.getPartAsStringFailsafe(\"ds\", 20));\n\t\treturn FirstTimeWizardToadlet.WIZARD_STEP.BANDWIDTH.name();\n\t}\n\n\tprivate void _setDatastoreSize(String selectedStoreSize) {\n\t\ttry {\n\t\t\tlong size = Fields.parseLong(selectedStoreSize);\n\t\t\t// client cache: 10% up to 200MB\n\t\t\tlong clientCacheSize = Math.min(size / 10, 200*1024*1024);\n\t\t\t// recent requests cache / slashdot cache / ULPR cache\n\t\t\tint upstreamLimit = config.get(\"node\").getInt(\"outputBandwidthLimit\");\n\t\t\tint downstreamLimit = config.get(\"node\").getInt(\"inputBandwidthLimit\");\n\t\t\t// is used for remote stuff, so go by the minimum of the two\n\t\t\tint limit;\n\t\t\tif(downstreamLimit <= 0) limit = upstreamLimit;\n\t\t\telse limit = Math.min(downstreamLimit, upstreamLimit);\n\t\t\t// 35KB/sec limit has been seen to have 0.5 store writes per second.\n\t\t\t// So saying we want to have space to cache everything is only doubling that ...\n\t\t\t// OTOH most stuff is at low enough HTL to go to the datastore and thus not to\n\t\t\t// the slashdot cache, so we could probably cut this significantly...\n\t\t\tlong lifetime = config.get(\"node\").getLong(\"slashdotCacheLifetime\");\n\t\t\tlong maxSlashdotCacheSize = (lifetime / 1000) * limit;\n\t\t\tlong slashdotCacheSize = Math.min(size / 10, maxSlashdotCacheSize);\n\n\t\t\tlong storeSize = size - (clientCacheSize + slashdotCacheSize);\n\n\t\t\tSystem.out.println(\"Setting datastore size to \"+Fields.longToString(storeSize, true));\n\t\t\tconfig.get(\"node\").set(\"storeSize\", Fields.longToString(storeSize, true));\n\t\t\tif(config.get(\"node\").getString(\"storeType\").equals(\"ram\"))\n\t\t\t\tconfig.get(\"node\").set(\"storeType\", \"salt-hash\");\n\t\t\tSystem.out.println(\"Setting client cache size to \"+Fields.longToString(clientCacheSize, true));\n\t\t\tconfig.get(\"node\").set(\"clientCacheSize\", Fields.longToString(clientCacheSize, true));\n\t\t\tif(config.get(\"node\").getString(\"clientCacheType\").equals(\"ram\"))\n\t\t\t\tconfig.get(\"node\").set(\"clientCacheType\", \"salt-hash\");\n\t\t\tSystem.out.println(\"Setting slashdot/ULPR/recent requests cache size to \"+Fields.longToString(slashdotCacheSize, true));\n\t\t\tconfig.get(\"node\").set(\"slashdotCacheSize\", Fields.longToString(slashdotCacheSize, true));\n\n\n\t\t\tLogger.normal(this, \"The storeSize has been set to \" + selectedStoreSize);\n\t\t} catch(ConfigException e) {\n\t\t\tLogger.error(this, \"Should not happen, please report!\" + e, e);\n\t\t}\n\t}\n\n\tprivate long maxDatastoreSize() {\n\t\tlong maxMemory = NodeStarter.getMemoryLimitBytes();\n\t\tif(maxMemory == Long.MAX_VALUE) return 1024*1024*1024; // Treat as don't know.\n\t\tif(maxMemory < 128*1024*1024) return 1024*1024*1024; // 1GB default if don't know or very small memory.\n\t\t// Don't use the first 100MB for slot filters.\n\t\tlong available = maxMemory - 100*1024*1024;\n\t\t// Don't use more than 50% of available memory for slot filters.\n\t\tavailable = available / 2;\n\t\t// Slot filters are 4 bytes per slot.\n\t\tlong slots = available / 4;\n\t\t// There are 3 types of keys. We want the number of { SSK, CHK, pubkey } i.e. the number of slots in each store.\n\t\tslots /= 3;\n\t\t// We return the total size, so we don't need to worry about cache vs store or even client cache.\n\t\t// One key of all 3 types combined uses Node.sizePerKey bytes on disk. So we get a size.\n\t\treturn slots * Node.sizePerKey;\n\t}\n\n    private long canAutoconfigureDatastoreSize() {\n        if (!config.get(\"node\").getOption(\"storeSize\").isDefault())\n            return -1;\n\n        long freeSpace = core.node.getStoreDir().getUsableSpace();\n\n        if (freeSpace <= 0) {\n            return -1;\n        } else {\n            long shortSize;\n            long oneGiB = 1024 * 1024 * 1024L;\n            // Maximum for Freenet: 256GB. That's a 128MiB bloom filter.\n            long bloomFilter128MiBMax = 256 * oneGiB;\n            // Maximum to suggest to keep Disk I/O managable. This\n            // value might need revisiting when hardware or\n            // filesystems change.\n            long diskIoMax = 20 * oneGiB;\n\n            // Choose a suggested store size based on available free space.\n            if (freeSpace > 50 * oneGiB) {\n                // > 50 GiB: Use 10% free space; minimum 10 GiB. Limited by\n                // bloom filters and disk I/O.\n                shortSize = Math.max(10 * oneGiB,\n                                     Math.min(freeSpace / 10,\n                                              Math.min(diskIoMax,\n                                                       bloomFilter128MiBMax)));\n            } else if (freeSpace > 5 * oneGiB) {\n                // > 5 GiB: Use 20% free space, minimum 2 GiB.\n                shortSize = Math.max(freeSpace / 5, 2 * oneGiB);\n            } else if (freeSpace > 2 * oneGiB) {\n                // > 2 GiB: 512 MiB.\n                shortSize = 512 * (1024 * 1024);\n            } else {\n                // <= 2 GiB: 256 MiB.\n                shortSize = 256 * (1024 * 1024);\n            }\n\n            return shortSize;\n        }\n    }\n}\n","lineNo":53}
{"Smelly Sample":"package freenet.clients.http;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.lang.management.*;\nimport java.net.URI;\nimport java.text.DecimalFormat;\nimport java.text.NumberFormat;\nimport java.util.*;\nimport java.util.stream.*;\n\nimport freenet.client.HighLevelSimpleClient;\nimport freenet.client.async.PersistenceDisabledException;\nimport freenet.clients.fcp.DownloadRequestStatus;\nimport freenet.clients.fcp.FCPServer;\nimport freenet.clients.fcp.RequestStatus;\nimport freenet.clients.fcp.UploadDirRequestStatus;\nimport freenet.clients.fcp.UploadFileRequestStatus;\nimport freenet.config.SubConfig;\nimport freenet.io.xfer.BlockReceiver;\nimport freenet.io.xfer.BlockTransmitter;\nimport freenet.l10n.BaseL10n;\nimport freenet.node.Node;\nimport freenet.node.NodeClientCore;\nimport freenet.node.NodeStarter;\nimport freenet.node.NodeStats;\nimport freenet.node.OpennetManager;\nimport freenet.node.PeerManager;\nimport freenet.node.PeerNodeStatus;\nimport freenet.node.RequestTracker;\nimport freenet.node.Version;\nimport freenet.node.diagnostics.*;\nimport freenet.node.diagnostics.threads.*;\nimport freenet.node.stats.DataStoreInstanceType;\nimport freenet.node.stats.DataStoreStats;\nimport freenet.node.stats.StatsNotAvailableException;\nimport freenet.node.stats.StoreAccessStats;\nimport freenet.pluginmanager.PluginInfoWrapper;\nimport freenet.pluginmanager.PluginManager;\nimport freenet.support.BandwidthStatsContainer;\nimport freenet.support.SizeUtil;\nimport freenet.support.api.HTTPRequest;\n\npublic class DiagnosticToadlet extends Toadlet {\n\n\tprivate final Node node;\n\tprivate final NodeClientCore core;\n\tprivate final NodeStats stats;\n\tprivate final PeerManager peers;\n\tprivate final NumberFormat thousandPoint = NumberFormat.getInstance();\n\tprivate final FCPServer fcp;\n\t//private final DecimalFormat fix1p1 = new DecimalFormat(\"0.0\");\n\t//private final DecimalFormat fix1p2 = new DecimalFormat(\"0.00\");\n\tprivate final DecimalFormat fix1p4 = new DecimalFormat(\"0.0000\");\n\t//private final DecimalFormat fix1p6sci = new DecimalFormat(\"0.######E0\");\n\tprivate final DecimalFormat fix3p1pct = new DecimalFormat(\"##0.0%\");\n\t//private final DecimalFormat fix3p1US = new DecimalFormat(\"##0.0\", new DecimalFormatSymbols(Locale.US));\n\t//private final DecimalFormat fix3pctUS = new DecimalFormat(\"##0%\", new DecimalFormatSymbols(Locale.US));\n\t//private final DecimalFormat fix6p6 = new DecimalFormat(\"#####0.0#####\");\n\tpublic static final String TOADLET_URL = \"/diagnostic/\";\n\tprivate final BaseL10n baseL10n;\n\n\tprotected DiagnosticToadlet(Node n, NodeClientCore core, FCPServer fcp, HighLevelSimpleClient client) {\n\t\tsuper(client);\n\t\tthis.node = n;\n\t\tthis.core = core;\n\t\tthis.fcp = fcp;\n\t\tstats = node.nodeStats;\n\t\tpeers = node.peers;\n\t\t/* copied from NodeL10n constructor. */\n\t\tbaseL10n = new BaseL10n(\"freenet/l10n/\", \"freenet.l10n.${lang}.properties\", new File(\".\").getPath()+File.separator+\"freenet.l10n.${lang}.override.properties\", BaseL10n.LANGUAGE.ENGLISH);\n\t}\n\n\tpublic void handleMethodGET(URI uri, HTTPRequest request, ToadletContext ctx) throws ToadletContextClosedException, IOException, RedirectException {\n        if(!ctx.checkFullAccess(this))\n            return;\n\n\t\tnode.clientCore.bandwidthStatsPutter.updateData(node);\n\n\t\tfinal SubConfig nodeConfig = node.config.get(\"node\");\n\n\t\tStringBuilder textBuilder = new StringBuilder();\n\n\t\t// Synchronize to avoid problems with DecimalFormat.\n\t\tsynchronized(this) {\n\t\t// drawNodeVersionBox\n\t\ttextBuilder.append(\"Freenet Version:\\n\");\n\t\ttextBuilder.append(baseL10n.getString(\"WelcomeToadlet.version\", new String[] { \"fullVersion\", \"build\", \"rev\" },\n\t\t\t\tnew String[] { Version.publicVersion(), Integer.toString(Version.buildNumber()), Version.cvsRevision() })).append(\"\\n\");\n\t\ttextBuilder.append(baseL10n.getString(\"WelcomeToadlet.extVersion\", new String[] { \"build\", \"rev\" },\n\t\t\t\tnew String[] { Integer.toString(NodeStarter.extBuildNumber), NodeStarter.extRevisionNumber }));\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawNodeVersionBox\n\t\ttextBuilder.append(\"System Information:\\n\");\n\t\tRuntime rt = Runtime.getRuntime();\n\t\tlong freeMemory = rt.freeMemory();\n\t\tlong totalMemory = rt.totalMemory();\n\t\tlong maxMemory = rt.maxMemory();\n\t\tlong usedJavaMem = totalMemory - freeMemory;\n\t\tlong allocatedJavaMem = totalMemory;\n\t\tlong maxJavaMem = maxMemory;\n\t\tint availableCpus = rt.availableProcessors();\n\t\tint threadCount = stats.getActiveThreadCount();\n\t\t\ttextBuilder.append(l10n(\"usedMemory\", \"memory\", SizeUtil.formatSize(usedJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"allocMemory\", \"memory\", SizeUtil.formatSize(allocatedJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"maxMemory\", \"memory\", SizeUtil.formatSize(maxJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"threads\", new String[] { \"running\", \"max\" },\n\t\t\t\tnew String[] { thousandPoint.format(threadCount), Integer.toString(stats.getThreadLimit()) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"cpus\", \"count\", Integer.toString(availableCpus))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"javaVersion\", \"version\", System.getProperty(\"java.version\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmVendor\", \"vendor\", System.getProperty(\"java.vendor\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmName\", \"name\", System.getProperty(\"java.vm.name\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmVersion\", \"version\", System.getProperty(\"java.vm.version\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osName\", \"name\", System.getProperty(\"os.name\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osVersion\", \"version\", System.getProperty(\"os.version\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osArch\", \"arch\", System.getProperty(\"os.arch\"))).append(\"\\n\");\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawStoreSizeBox\n\t\ttextBuilder.append(\"Store Size:\\n\");\n\t\tMap<DataStoreInstanceType, DataStoreStats> storeStats = node.getDataStoreStats();\n\t\tfor (Map.Entry<DataStoreInstanceType, DataStoreStats> entry : storeStats.entrySet()) {\n\t\t\tDataStoreInstanceType instance = entry.getKey();\n\t\t\tDataStoreStats stats = entry.getValue();\n\t\t\tStoreAccessStats sessionAccess = stats.getSessionAccessStats();\n\t\t\tStoreAccessStats totalAccess;\n\t\t\ttry {\n\t\t\t\ttotalAccess = stats.getTotalAccessStats();\n\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t\ttotalAccess = null;\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(instance.store.name())).append(\": (\").append(l10n(instance.key.name())).append(\")\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"keys\")).append(\": \").append(thousandPoint.format(stats.keys())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"capacity\")).append(\": \").append(thousandPoint.format(stats.capacity())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"datasize\")).append(\": \").append(SizeUtil.formatSize(stats.dataSize())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"utilization\")).append(\": \").append(fix3p1pct.format(stats.utilization())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"readRequests\")).append(\": \").append(thousandPoint.format(sessionAccess.readRequests()) +\n\t\t\t\t\t(totalAccess == null ? \"\" : (\" (\"+thousandPoint.format(totalAccess.readRequests())+\")\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"successfulReads\")).append(\": \").append(thousandPoint.format(sessionAccess.successfulReads()) +\n\t\t\t\t\t(totalAccess == null ? \"\" : (\" (\"+thousandPoint.format(totalAccess.successfulReads())+\")\"))).append(\"\\n\");\n\t\t\ttry {\n\t\t\t\ttextBuilder.append(fix1p4.format(sessionAccess.successRate())).append(\"%\");\n\t\t\t\tif(totalAccess != null) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\ttextBuilder.append(\" (\").append(fix1p4.format(totalAccess.successRate())).append(\"%)\");\n\t\t\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t\t\t\t// Ignore\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(\"\\n\");\n\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t}\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawActivity\n\t\ttextBuilder.append(\"Activity:\\n\");\n\t\tRequestTracker tracker = node.tracker;\n\t\tint numLocalCHKInserts = tracker.getNumLocalCHKInserts();\n\t\tint numRemoteCHKInserts = tracker.getNumRemoteCHKInserts();\n\t\tint numLocalSSKInserts = tracker.getNumLocalSSKInserts();\n\t\tint numRemoteSSKInserts = tracker.getNumRemoteSSKInserts();\n\t\tint numLocalCHKRequests = tracker.getNumLocalCHKRequests();\n\t\tint numRemoteCHKRequests = tracker.getNumRemoteCHKRequests();\n\t\tint numLocalSSKRequests = tracker.getNumLocalSSKRequests();\n\t\tint numRemoteSSKRequests = tracker.getNumRemoteSSKRequests();\n\t\tint numTransferringRequests = tracker.getNumTransferringRequestSenders();\n\t\tint numTransferringRequestHandlers = tracker.getNumTransferringRequestHandlers();\n\t\tint numCHKOfferReplys = tracker.getNumCHKOfferReplies();\n\t\tint numSSKOfferReplys = tracker.getNumSSKOfferReplies();\n\t\tint numCHKRequests = numLocalCHKRequests + numRemoteCHKRequests;\n\t\tint numSSKRequests = numLocalSSKRequests + numRemoteSSKRequests;\n\t\tint numCHKInserts = numLocalCHKInserts + numRemoteCHKInserts;\n\t\tint numSSKInserts = numLocalSSKInserts + numRemoteSSKInserts;\n\t\tif ((numTransferringRequests == 0) &&\n\t\t\t\t(numCHKRequests == 0) && (numSSKRequests == 0) &&\n\t\t\t\t(numCHKInserts == 0) && (numSSKInserts == 0) &&\n\t\t\t\t(numTransferringRequestHandlers == 0) && \n\t\t\t\t(numCHKOfferReplys == 0) && (numSSKOfferReplys == 0)) {\n\t\t\ttextBuilder.append(l10n(\"noRequests\")).append(\"\\n\");\n\t\t} else {\n\t\t\tif (numCHKInserts > 0 || numSSKInserts > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"activityInserts\",\n\t\t\t\t\t\tnew String[] { \"CHKhandlers\", \"SSKhandlers\", \"local\" } ,\n\t\t\t\t\t\tnew String[] { Integer.toString(numCHKInserts), Integer.toString(numSSKInserts), Integer.toString(numLocalCHKInserts)+\"/\" + Integer.toString(numLocalSSKInserts)})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numCHKRequests > 0 || numSSKRequests > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"activityRequests\",\n\t\t\t\t\t\tnew String[] { \"CHKhandlers\", \"SSKhandlers\", \"local\" } ,\n\t\t\t\t\t\tnew String[] { Integer.toString(numCHKRequests), Integer.toString(numSSKRequests), Integer.toString(numLocalCHKRequests)+\"/\" + Integer.toString(numLocalSSKRequests)})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numTransferringRequests > 0 || numTransferringRequestHandlers > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"transferringRequests\",\n\t\t\t\t\t\tnew String[] { \"senders\", \"receivers\", \"turtles\" }, new String[] { Integer.toString(numTransferringRequests), Integer.toString(numTransferringRequestHandlers), \"0\"})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numCHKOfferReplys > 0 || numSSKOfferReplys > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"offerReplys\",\n\t\t\t\t\t\tnew String[] { \"chk\", \"ssk\" }, new String[] { Integer.toString(numCHKOfferReplys), Integer.toString(numSSKOfferReplys) })\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(\"runningBlockTransfers\",\n\t\t\t\t\tnew String[] { \"sends\", \"receives\" }, new String[] { Integer.toString(BlockTransmitter.getRunningSends()), Integer.toString(BlockReceiver.getRunningReceives()) })\n\t\t\t\t\t+ \"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawPeerStatsBox\n\t\ttextBuilder.append(\"Peer Statistics:\\n\");\n\t\tPeerNodeStatus[] peerNodeStatuses = peers.getPeerNodeStatuses(true);\n\t\tArrays.sort(peerNodeStatuses, new Comparator<PeerNodeStatus>() {\n\t\t\t@Override\n\t\t\tpublic int compare(PeerNodeStatus firstNode, PeerNodeStatus secondNode) {\n\t\t\t\tint statusDifference = firstNode.getStatusValue() - secondNode.getStatusValue();\n\t\t\t\tif (statusDifference != 0) {\n\t\t\t\t\treturn statusDifference;\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t});\n\t\tint numberOfConnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CONNECTED);\n\t\tint numberOfRoutingBackedOff = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_ROUTING_BACKED_OFF);\n\t\tint numberOfTooNew = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_TOO_NEW);\n\t\tint numberOfTooOld = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_TOO_OLD);\n\t\tint numberOfDisconnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISCONNECTED);\n\t\tint numberOfNeverConnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_NEVER_CONNECTED);\n\t\tint numberOfDisabled = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISABLED);\n\t\tint numberOfBursting = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_BURSTING);\n\t\tint numberOfListening = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_LISTENING);\n\t\tint numberOfListenOnly = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_LISTEN_ONLY);\n\t\tint numberOfSeedServers = getCountSeedServers(peerNodeStatuses);\n\t\tint numberOfSeedClients = getCountSeedClients(peerNodeStatuses);\n\t\tint numberOfRoutingDisabled = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_ROUTING_DISABLED);\n\t\tint numberOfClockProblem = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CLOCK_PROBLEM);\n\t\tint numberOfConnError = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CONN_ERROR);\n\t\tint numberOfDisconnecting = PeerNodeStatus.getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISCONNECTING);\n\t\tint numberOfNoLoadStats = PeerNodeStatus.getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_NO_LOAD_STATS);\n\t\tif (numberOfConnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"connectedShort\")).append(\": \").append(numberOfConnected).append(\"\\n\");\n\t\tif (numberOfRoutingBackedOff > 0)\n\t\t\ttextBuilder.append(l10nDark(\"backedOffShort\")).append(\": \").append(numberOfRoutingBackedOff).append(\"\\n\");\n\t\tif (numberOfTooNew > 0)\n\t\t\ttextBuilder.append(l10nDark(\"tooNewShort\")).append(\": \").append(numberOfTooNew).append(\"\\n\");\n\t\tif (numberOfTooOld > 0)\n\t\t\ttextBuilder.append(l10nDark(\"tooOldShort\")).append(\": \").append(numberOfTooOld).append(\"\\n\");\n\t\tif (numberOfDisconnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"notConnectedShort\")).append(\": \").append(numberOfDisconnected).append(\"\\n\");\n\t\tif (numberOfNeverConnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"neverConnectedShort\")).append(\": \").append(numberOfNeverConnected).append(\"\\n\");\n\t\tif (numberOfDisabled > 0)\n\t\t\ttextBuilder.append(l10nDark(\"disabledShort\")).append(\": \").append(numberOfDisabled).append(\"\\n\");\n\t\tif (numberOfBursting > 0)\n\t\t\ttextBuilder.append(l10nDark(\"burstingShort\")).append(\": \").append(numberOfBursting).append(\"\\n\");\n\t\tif (numberOfListening > 0)\n\t\t\ttextBuilder.append(l10nDark(\"listeningShort\")).append(\": \").append(numberOfListening).append(\"\\n\");\n\t\tif (numberOfListenOnly > 0)\n\t\t\ttextBuilder.append(l10nDark(\"listenOnlyShort\")).append(\": \").append(numberOfListenOnly).append(\"\\n\");\n\t\tif (numberOfClockProblem > 0)\n\t\t\ttextBuilder.append(l10nDark(\"clockProblemShort\")).append(\": \").append(numberOfClockProblem).append(\"\\n\");\n\t\tif (numberOfConnError > 0)\n\t\t\ttextBuilder.append(l10nDark(\"connErrorShort\")).append(\": \").append(numberOfConnError).append(\"\\n\");\n\t\tif (numberOfDisconnecting > 0)\n\t\t\ttextBuilder.append(l10nDark(\"disconnectingShort\")).append(\": \").append(numberOfDisconnecting).append(\"\\n\");\n\t\tif (numberOfSeedServers > 0)\n\t\t\ttextBuilder.append(l10nDark(\"seedServersShort\")).append(\": \").append(numberOfSeedServers).append(\"\\n\");\n\t\tif (numberOfSeedClients > 0)\n\t\t\ttextBuilder.append(l10nDark(\"seedClientsShort\")).append(\": \").append(numberOfSeedClients).append(\"\\n\");\n\t\tif (numberOfRoutingDisabled > 0)\n\t\t\ttextBuilder.append(l10nDark(\"routingDisabledShort\")).append(\": \").append(numberOfRoutingDisabled).append(\"\\n\");\n\t\tif (numberOfNoLoadStats > 0)\n\t\t\ttextBuilder.append(l10nDark(\"noLoadStatsShort\")).append(\": \").append(numberOfNoLoadStats).append(\"\\n\");\n\t\tOpennetManager om = node.getOpennet();\n\t\tif(om != null) {\n\t\t\ttextBuilder.append(l10n(\"maxTotalPeers\")+\": \"+om.getNumberOfConnectedPeersToAimIncludingDarknet()).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"maxOpennetPeers\")+\": \"+om.getNumberOfConnectedPeersToAim()).append(\"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawBandwidth\n\t\ttextBuilder.append(\"Bandwidth:\\n\");\n\t\tlong[] total = node.collector.getTotalIO();\n\t\tif(total[0] == 0 || total[1] == 0)\n\t\t\ttextBuilder.append(\"bandwidth error\\n\");\n\t\telse  {\n\t\t\tfinal long now = System.currentTimeMillis();\n\t\t\tfinal long nodeUptimeSeconds = (now - node.startupTime) / 1000;\n\t\t\tlong total_output_rate = (total[0]) / nodeUptimeSeconds;\n\t\t\tlong total_input_rate = (total[1]) / nodeUptimeSeconds;\n\t\t\tlong totalPayload = node.getTotalPayloadSent();\n\t\t\tlong total_payload_rate = totalPayload / nodeUptimeSeconds;\n\t\t\tif(node.clientCore == null) throw new NullPointerException();\n\t\t\tBandwidthStatsContainer stats = node.clientCore.bandwidthStatsPutter.getLatestBWData();\n\t\t\tif(stats == null) throw new NullPointerException();\n\t\t\tlong overall_total_out = stats.totalBytesOut;\n\t\t\tlong overall_total_in = stats.totalBytesIn;\n\t\t\tint percent = (int) (100 * totalPayload / total[0]);\n\t\t\tlong[] rate = node.nodeStats.getNodeIOStats();\n\t\t\tlong delta = (rate[5] - rate[2]) / 1000;\n\t\t\tif(delta > 0) {\n\t\t\t\tlong output_rate = (rate[3] - rate[0]) / delta;\n\t\t\t\tlong input_rate = (rate[4] - rate[1]) / delta;\n\t\t\t\tint outputBandwidthLimit = nodeConfig.getInt(\"outputBandwidthLimit\");\n\t\t\t\tint inputBandwidthLimit = nodeConfig.getInt(\"inputBandwidthLimit\");\n\t\t\t\tif(inputBandwidthLimit == -1) {\n\t\t\t\t\tinputBandwidthLimit = outputBandwidthLimit * 4;\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(l10n(\"inputRate\", new String[] { \"rate\", \"max\" }, new String[] { SizeUtil.formatSize(input_rate, true), SizeUtil.formatSize(inputBandwidthLimit, true) })).append(\"\\n\");\n\t\t\t\ttextBuilder.append(l10n(\"outputRate\", new String[] { \"rate\", \"max\" }, new String[] { SizeUtil.formatSize(output_rate, true), SizeUtil.formatSize(outputBandwidthLimit, true) })).append(\"\\n\");\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(\"totalInputSession\", new String[] { \"total\", \"rate\" }, new String[] { SizeUtil.formatSize(total[1], true), SizeUtil.formatSize(total_input_rate, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalOutputSession\", new String[] { \"total\", \"rate\" }, new String[] { SizeUtil.formatSize(total[0], true), SizeUtil.formatSize(total_output_rate, true) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"payloadOutput\", new String[] { \"total\", \"rate\", \"percent\" }, new String[] { SizeUtil.formatSize(totalPayload, true), SizeUtil.formatSize(total_payload_rate, true), Integer.toString(percent) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalInput\", new String[] { \"total\" }, new String[] { SizeUtil.formatSize(overall_total_in, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalOutput\", new String[] { \"total\" }, new String[] { SizeUtil.formatSize(overall_total_out, true) } )).append(\"\\n\");\n\t\t\tlong totalBytesSentCHKRequests = node.nodeStats.getCHKRequestTotalBytesSent();\n\t\t\tlong totalBytesSentSSKRequests = node.nodeStats.getSSKRequestTotalBytesSent();\n\t\t\tlong totalBytesSentCHKInserts = node.nodeStats.getCHKInsertTotalBytesSent();\n\t\t\tlong totalBytesSentSSKInserts = node.nodeStats.getSSKInsertTotalBytesSent();\n\t\t\tlong totalBytesSentOfferedKeys = node.nodeStats.getOfferedKeysTotalBytesSent();\n\t\t\tlong totalBytesSendOffers = node.nodeStats.getOffersSentBytesSent();\n\t\t\tlong totalBytesSentSwapOutput = node.nodeStats.getSwappingTotalBytesSent();\n\t\t\tlong totalBytesSentAuth = node.nodeStats.getTotalAuthBytesSent();\n\t\t\tlong totalBytesSentAckOnly = node.nodeStats.getNotificationOnlyPacketsSentBytes();\n\t\t\tlong totalBytesSentResends = node.nodeStats.getResendBytesSent();\n\t\t\tlong totalBytesSentUOM = node.nodeStats.getUOMBytesSent();\n\t\t\tlong totalBytesSentAnnounce = node.nodeStats.getAnnounceBytesSent();\n\t\t\tlong totalBytesSentAnnouncePayload = node.nodeStats.getAnnounceBytesPayloadSent();\n\t\t\tlong totalBytesSentRoutingStatus = node.nodeStats.getRoutingStatusBytes();\n\t\t\tlong totalBytesSentNetworkColoring = node.nodeStats.getNetworkColoringSentBytes();\n\t\t\tlong totalBytesSentPing = node.nodeStats.getPingSentBytes();\n\t\t\tlong totalBytesSentProbeRequest = node.nodeStats.getProbeRequestSentBytes();\n\t\t\tlong totalBytesSentRouted = node.nodeStats.getRoutedMessageSentBytes();\n\t\t\tlong totalBytesSentDisconn = node.nodeStats.getDisconnBytesSent();\n\t\t\tlong totalBytesSentInitial = node.nodeStats.getInitialMessagesBytesSent();\n\t\t\tlong totalBytesSentChangedIP = node.nodeStats.getChangedIPBytesSent();\n\t\t\tlong totalBytesSentNodeToNode = node.nodeStats.getNodeToNodeBytesSent();\n\t\t\tlong totalBytesSentAllocationNotices = node.nodeStats.getAllocationNoticesBytesSent();\n\t\t\tlong totalBytesSentFOAF = node.nodeStats.getFOAFBytesSent();\n\t\t\tlong totalBytesSentRemaining = total[0] - \n\t\t\t\t(totalPayload + totalBytesSentCHKRequests + totalBytesSentSSKRequests +\n\t\t\t\ttotalBytesSentCHKInserts + totalBytesSentSSKInserts +\n\t\t\t\ttotalBytesSentOfferedKeys + totalBytesSendOffers + totalBytesSentSwapOutput + \n\t\t\t\ttotalBytesSentAuth + totalBytesSentAckOnly + totalBytesSentResends +\n\t\t\t\ttotalBytesSentUOM + totalBytesSentAnnounce + \n\t\t\t\ttotalBytesSentRoutingStatus + totalBytesSentNetworkColoring + totalBytesSentPing +\n\t\t\t\ttotalBytesSentProbeRequest + totalBytesSentRouted + totalBytesSentDisconn + \n\t\t\t\ttotalBytesSentInitial + totalBytesSentChangedIP + totalBytesSentNodeToNode + totalBytesSentAllocationNotices + totalBytesSentFOAF);\n\t\t\ttextBuilder.append(l10n(\"requestOutput\", new String[] { \"chk\", \"ssk\" }, new String[] { SizeUtil.formatSize(totalBytesSentCHKRequests, true), SizeUtil.formatSize(totalBytesSentSSKRequests, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"insertOutput\", new String[] { \"chk\", \"ssk\" }, new String[] { SizeUtil.formatSize(totalBytesSentCHKInserts, true), SizeUtil.formatSize(totalBytesSentSSKInserts, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"offeredKeyOutput\", new String[] { \"total\", \"offered\" }, new String[] { SizeUtil.formatSize(totalBytesSentOfferedKeys, true), SizeUtil.formatSize(totalBytesSendOffers, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"swapOutput\", \"total\", SizeUtil.formatSize(totalBytesSentSwapOutput, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"authBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAuth, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"ackOnlyBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAckOnly, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"resendBytes\", new String[] { \"total\", \"percent\" }, new String[] { SizeUtil.formatSize(totalBytesSentResends, true), Long.toString((100 * totalBytesSentResends) / Math.max(1, total[0])) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"uomBytes\", \"total\",  SizeUtil.formatSize(totalBytesSentUOM, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"announceBytes\", new String[] { \"total\", \"payload\" }, new String[] { SizeUtil.formatSize(totalBytesSentAnnounce, true), SizeUtil.formatSize(totalBytesSentAnnouncePayload, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"adminBytes\", new String[] { \"routingStatus\", \"disconn\", \"initial\", \"changedIP\" }, new String[] { SizeUtil.formatSize(totalBytesSentRoutingStatus, true), SizeUtil.formatSize(totalBytesSentDisconn, true), SizeUtil.formatSize(totalBytesSentInitial, true), SizeUtil.formatSize(totalBytesSentChangedIP, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"debuggingBytes\", new String[] { \"netColoring\", \"ping\", \"probe\", \"routed\" }, new String[] { SizeUtil.formatSize(totalBytesSentNetworkColoring, true), SizeUtil.formatSize(totalBytesSentPing, true), SizeUtil.formatSize(totalBytesSentProbeRequest, true), SizeUtil.formatSize(totalBytesSentRouted, true) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"nodeToNodeBytes\", \"total\", SizeUtil.formatSize(totalBytesSentNodeToNode, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"loadAllocationNoticesBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAllocationNotices, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"foafBytes\", \"total\", SizeUtil.formatSize(totalBytesSentFOAF, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"unaccountedBytes\", new String[] { \"total\", \"percent\" },\n\t\t\t\t\tnew String[] { SizeUtil.formatSize(totalBytesSentRemaining, true), Integer.toString((int)(totalBytesSentRemaining*100 / total[0])) })).append(\"\\n\");\n\t\t\tdouble sentOverheadPerSecond = node.nodeStats.getSentOverheadPerSecond();\n\t\t\ttextBuilder.append(l10n(\"totalOverhead\", new String[] { \"rate\", \"percent\" },\n\t\t\t\t\tnew String[] { SizeUtil.formatSize((long)sentOverheadPerSecond), Integer.toString((int)((100 * sentOverheadPerSecond) / total_output_rate)) })).append(\"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// showStartingPlugins\n\t\ttextBuilder.append(\"Plugins:\\n\");\n\t\tPluginManager pm = node.pluginManager;\n\t\tif (!pm.getPlugins().isEmpty()) {\n\t\t\ttextBuilder.append(baseL10n.getString(\"PluginToadlet.pluginListTitle\")).append(\"\\n\");\n\t\t\tfor(PluginInfoWrapper pi: pm.getPlugins()) {\n\t\t\t\tlong ver = pi.getPluginLongVersion();\n\t\t\t\tif (ver != -1)\n\t\t\t\t\ttextBuilder.append(pi.getFilename()).append(\" (\").append(pi.getPluginClassName()).append(\") - \" ).append(pi.getPluginVersion()+ \" (\"+ver+\")\").append(\" \").append(pi.getThreadName()).append(\"\\n\");\n\t\t\t\telse\n\t\t\t\t\ttextBuilder.append(pi.getFilename()).append(\" (\").append(pi.getPluginClassName()).append(\") - \").append(pi.getPluginVersion()).append(\" \").append(pi.getThreadName()).append(\"\\n\");\n\t\t\t}\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// handleGetInner\n\t\ttextBuilder.append(\"Queue:\\n\");\n\t\ttry {\n\t\t\tRequestStatus[] reqs = fcp.getGlobalRequests();\n\t\t\tif(reqs.length < 1)\n\t\t\t\ttextBuilder.append(baseL10n.getString(\"QueueToadlet.globalQueueIsEmpty\")).append(\"\\n\");\n\t\t\telse {\n\t\t\t\tlong totalQueuedDownload = 0;\n\t\t\t\tlong totalQueuedUpload = 0;\n\t\t\t\tfor(RequestStatus req: reqs) {\n\t\t\t\t\tif(req instanceof DownloadRequestStatus) {\n\t\t\t\t\t\ttotalQueuedDownload++;\n\t\t\t\t\t} else if(req instanceof UploadFileRequestStatus) {\n\t\t\t\t\t\ttotalQueuedUpload++;\n\t\t\t\t\t} else if(req instanceof UploadDirRequestStatus) {\n\t\t\t\t\t\ttotalQueuedUpload++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(\"Downloads Queued: \").append(totalQueuedDownload).append(\" (\").append(totalQueuedDownload).append(\")\\n\");\n\t\t\t\ttextBuilder.append(\"Uploads Queued: \").append(totalQueuedUpload).append(\" (\").append(totalQueuedUpload).append(\")\\n\");\n\t\t\t}\n\t\t} catch (PersistenceDisabledException e) {\n\t\t\ttextBuilder.append(\"DatabaseDisabledException\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawThreadPriorityStatsBox\n\t\ttextBuilder.append(threadsStats());\n\n\t\ttextBuilder.append(\"\\n\");\n\t\t}\n\n\t\tthis.writeTextReply(ctx, 200, \"OK\", textBuilder.toString());\n\t}\n\n\tprivate StringBuilder threadsStats() {\n\t\tStringBuilder sb = new StringBuilder();\n\n\t\tThreadDiagnostics threadDiagnostics = node\n\t\t\t.getNodeDiagnostics()\n\t\t\t.getThreadDiagnostics();\n\n\t\tList<NodeThreadInfo> threads = threadDiagnostics.getThreads();\n\t\tthreads.sort(Comparator.comparing(NodeThreadInfo::getCpuTime).reversed());\n\n\t\tdouble totalCpuTime = Math.max(1, threads\n\t\t\t.stream()\n\t\t\t.mapToDouble(NodeThreadInfo::getCpuTime)\n\t\t\t.sum());\n\n\t\tsb.append(String.format(\"Threads (%d):%n\", threads.size()));\n\n\t\t// ID, Name, Priority, Group (system, main), Status, % CPU\n\t\tsb.append(\n\t\t\tString.format(\n\t\t\t\t\"%5s %-60s %5s %10s %-20s %-5s%n\",\n\t\t\t\t\"ID\",\n\t\t\t\t\"Name\",\n\t\t\t\t\"Prio.\",\n\t\t\t\t\"Group\",\n\t\t\t\t\"Status\",\n\t\t\t\t\"% CPU\"\n\t\t\t)\n\t\t);\n\n\t\tfor (NodeThreadInfo thread : threads) {\n\t\t\tString line = String.format(\n\t\t\t\t\"%5s %-60s %5s %10s %-20s %.2f%n\",\n\t\t\t\tthread.getId(),\n\t\t\t\tthread.getName().substring(0, Math.min(60, thread.getName().length())),\n\t\t\t\tthread.getPrio(),\n\t\t\t\tthread.getGroupName().substring(0, Math.min(10, thread.getGroupName().length())),\n\t\t\t\tthread.getState(),\n\t\t\t\tthread.getCpuTime() / totalCpuTime * 100\n\t\t\t);\n\t\t\tsb.append(line);\n\t\t}\n\n\t\treturn sb;\n\t}\n\n\tprivate int getPeerStatusCount(PeerNodeStatus[] peerNodeStatuses, int status) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(!peerNodeStatus.recordStatus())\n\t\t\t\tcontinue;\n\t\t\tif (peerNodeStatus.getStatusValue() == status) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}\n\t\n\tprivate int getCountSeedServers(PeerNodeStatus[] peerNodeStatuses) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(peerNodeStatus.isSeedServer()) count++;\n\t\t}\n\t\treturn count;\n\t}\n\n\tprivate int getCountSeedClients(PeerNodeStatus[] peerNodeStatuses) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(peerNodeStatus.isSeedClient()) count++;\n\t\t}\n\t\treturn count;\n\t}\n\n\tprivate String l10n(String key) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key);\n\t}\n\n\tprivate String l10nDark(String key) {\n\t\treturn baseL10n.getString(\"DarknetConnectionsToadlet.\"+key);\n\t}\n\n\tprivate String l10n(String key, String pattern, String value) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key, new String[] { pattern }, new String[] { value });\n\t}\n\n\tprivate String l10n(String key, String[] patterns, String[] values) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key, patterns, values);\n\t}\n\n\t@Override\n\tpublic String path() {\n\t\treturn TOADLET_URL;\n\t}\n}\n","Method after Refactoring":"package freenet.clients.http;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.lang.management.*;\nimport java.net.URI;\nimport java.text.DecimalFormat;\nimport java.text.NumberFormat;\nimport java.util.*;\nimport java.util.stream.*;\n\nimport freenet.client.HighLevelSimpleClient;\nimport freenet.client.async.PersistenceDisabledException;\nimport freenet.clients.fcp.DownloadRequestStatus;\nimport freenet.clients.fcp.FCPServer;\nimport freenet.clients.fcp.RequestStatus;\nimport freenet.clients.fcp.UploadDirRequestStatus;\nimport freenet.clients.fcp.UploadFileRequestStatus;\nimport freenet.config.SubConfig;\nimport freenet.io.xfer.BlockReceiver;\nimport freenet.io.xfer.BlockTransmitter;\nimport freenet.l10n.BaseL10n;\nimport freenet.node.Node;\nimport freenet.node.NodeClientCore;\nimport freenet.node.NodeStarter;\nimport freenet.node.NodeStats;\nimport freenet.node.OpennetManager;\nimport freenet.node.PeerManager;\nimport freenet.node.PeerNodeStatus;\nimport freenet.node.RequestTracker;\nimport freenet.node.Version;\nimport freenet.node.diagnostics.*;\nimport freenet.node.diagnostics.threads.*;\nimport freenet.node.stats.DataStoreInstanceType;\nimport freenet.node.stats.DataStoreStats;\nimport freenet.node.stats.StatsNotAvailableException;\nimport freenet.node.stats.StoreAccessStats;\nimport freenet.pluginmanager.PluginInfoWrapper;\nimport freenet.pluginmanager.PluginManager;\nimport freenet.support.BandwidthStatsContainer;\nimport freenet.support.SizeUtil;\nimport freenet.support.api.HTTPRequest;\n\npublic class DiagnosticToadlet extends Toadlet {\n\n\tprivate final Node node;\n\tprivate final NodeClientCore core;\n\tprivate final NodeStats stats;\n\tprivate final PeerManager peers;\n\tprivate final NumberFormat thousandPoint = NumberFormat.getInstance();\n\tprivate final FCPServer fcp;\n\t//private final DecimalFormat fix1p1 = new DecimalFormat(\"0.0\");\n\t//private final DecimalFormat fix1p2 = new DecimalFormat(\"0.00\");\n\tprivate final DecimalFormat fix1p4 = new DecimalFormat(\"0.0000\");\n\t//private final DecimalFormat fix1p6sci = new DecimalFormat(\"0.######E0\");\n\tprivate final DecimalFormat fix3p1pct = new DecimalFormat(\"##0.0%\");\n\t//private final DecimalFormat fix3p1US = new DecimalFormat(\"##0.0\", new DecimalFormatSymbols(Locale.US));\n\t//private final DecimalFormat fix3pctUS = new DecimalFormat(\"##0%\", new DecimalFormatSymbols(Locale.US));\n\t//private final DecimalFormat fix6p6 = new DecimalFormat(\"#####0.0#####\");\n\tpublic static final String TOADLET_URL = \"/diagnostic/\";\n\tprivate final BaseL10n baseL10n;\n\n\tprotected DiagnosticToadlet(Node n, NodeClientCore core, FCPServer fcp, HighLevelSimpleClient client) {\n\t\tsuper(client);\n\t\tthis.node = n;\n\t\tthis.core = core;\n\t\tthis.fcp = fcp;\n\t\tstats = node.nodeStats;\n\t\tpeers = node.peers;\n\t\t/* copied from NodeL10n constructor. */\n\t\tbaseL10n = new BaseL10n(\"freenet/l10n/\", \"freenet.l10n.${lang}.properties\", new File(\".\").getPath()+File.separator+\"freenet.l10n.${lang}.override.properties\", BaseL10n.LANGUAGE.ENGLISH);\n\t}\n\n\tpublic void handleMethodGET(URI uri, HTTPRequest request, ToadletContext ctx) throws ToadletContextClosedException, IOException, RedirectException {\n        if(!ctx.checkFullAccess(this))\n            return;\n\n\t\tnode.clientCore.bandwidthStatsPutter.updateData(node);\n\n\t\tfinal SubConfig nodeConfig = node.config.get(\"node\");\n\n\t\tStringBuilder textBuilder = new StringBuilder();\n\n\t\t// Synchronize to avoid problems with DecimalFormat.\n\t\tsynchronized(this) {\n\t\t// drawNodeVersionBox\n\t\ttextBuilder.append(\"Freenet Version:\\n\");\n\t\ttextBuilder.append(baseL10n.getString(\"WelcomeToadlet.version\", new String[] { \"fullVersion\", \"build\", \"rev\" },\n\t\t\t\tnew String[] { Version.publicVersion(), Integer.toString(Version.buildNumber()), Version.cvsRevision() })).append(\"\\n\");\n\t\ttextBuilder.append(baseL10n.getString(\"WelcomeToadlet.extVersion\", new String[] { \"build\", \"rev\" },\n\t\t\t\tnew String[] { Integer.toString(NodeStarter.extBuildNumber), NodeStarter.extRevisionNumber }));\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawNodeVersionBox\n\t\ttextBuilder.append(\"System Information:\\n\");\n\t\tRuntime rt = Runtime.getRuntime();\n\t\tlong freeMemory = rt.freeMemory();\n\t\tlong totalMemory = rt.totalMemory();\n\t\tlong maxMemory = rt.maxMemory();\n\t\tlong usedJavaMem = totalMemory - freeMemory;\n\t\tlong allocatedJavaMem = totalMemory;\n\t\tlong maxJavaMem = maxMemory;\n\t\tint availableCpus = rt.availableProcessors();\n\t\tint threadCount = stats.getActiveThreadCount();\n\t\t\ttextBuilder.append(l10n(\"usedMemory\", \"memory\", SizeUtil.formatSize(usedJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"allocMemory\", \"memory\", SizeUtil.formatSize(allocatedJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"maxMemory\", \"memory\", SizeUtil.formatSize(maxJavaMem, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"threads\", new String[] { \"running\", \"max\" },\n\t\t\t\tnew String[] { thousandPoint.format(threadCount), Integer.toString(stats.getThreadLimit()) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"cpus\", \"count\", Integer.toString(availableCpus))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"javaVersion\", \"version\", System.getProperty(\"java.version\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmVendor\", \"vendor\", System.getProperty(\"java.vendor\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmName\", \"name\", System.getProperty(\"java.vm.name\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"jvmVersion\", \"version\", System.getProperty(\"java.vm.version\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osName\", \"name\", System.getProperty(\"os.name\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osVersion\", \"version\", System.getProperty(\"os.version\"))).append(\"\\n\");\n\t\ttextBuilder.append(l10n(\"osArch\", \"arch\", System.getProperty(\"os.arch\"))).append(\"\\n\");\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawStoreSizeBox\n\t\ttextBuilder.append(\"Store Size:\\n\");\n\t\tMap<DataStoreInstanceType, DataStoreStats> storeStats = node.getDataStoreStats();\n\t\tfor (Map.Entry<DataStoreInstanceType, DataStoreStats> entry : storeStats.entrySet()) {\n\t\t\tDataStoreInstanceType instance = entry.getKey();\n\t\t\tDataStoreStats stats = entry.getValue();\n\t\t\tStoreAccessStats sessionAccess = stats.getSessionAccessStats();\n\t\t\tStoreAccessStats totalAccess;\n\t\t\ttry {\n\t\t\t\ttotalAccess = stats.getTotalAccessStats();\n\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t\ttotalAccess = null;\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(instance.store.name())).append(\": (\").append(l10n(instance.key.name())).append(\")\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"keys\")).append(\": \").append(thousandPoint.format(stats.keys())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"capacity\")).append(\": \").append(thousandPoint.format(stats.capacity())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"datasize\")).append(\": \").append(SizeUtil.formatSize(stats.dataSize())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"utilization\")).append(\": \").append(fix3p1pct.format(stats.utilization())).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"readRequests\")).append(\": \").append(thousandPoint.format(sessionAccess.readRequests()) +\n\t\t\t\t\t(totalAccess == null ? \"\" : (\" (\"+thousandPoint.format(totalAccess.readRequests())+\")\"))).append(\"\\n\");\n\t\t\ttextBuilder.append(\"  \").append(l10n(\"successfulReads\")).append(\": \").append(thousandPoint.format(sessionAccess.successfulReads()) +\n\t\t\t\t\t(totalAccess == null ? \"\" : (\" (\"+thousandPoint.format(totalAccess.successfulReads())+\")\"))).append(\"\\n\");\n\t\t\ttry {\n\t\t\t\ttextBuilder.append(fix1p4.format(sessionAccess.successRate())).append(\"%\");\n\t\t\t\tif(totalAccess != null) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\ttextBuilder.append(\" (\").append(fix1p4.format(totalAccess.successRate())).append(\"%)\");\n\t\t\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t\t\t\t// Ignore\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(\"\\n\");\n\t\t\t} catch (StatsNotAvailableException e) {\n\t\t\t}\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawActivity\n\t\ttextBuilder.append(\"Activity:\\n\");\n\t\tRequestTracker tracker = node.tracker;\n\t\tint numLocalCHKInserts = tracker.getNumLocalCHKInserts();\n\t\tint numRemoteCHKInserts = tracker.getNumRemoteCHKInserts();\n\t\tint numLocalSSKInserts = tracker.getNumLocalSSKInserts();\n\t\tint numRemoteSSKInserts = tracker.getNumRemoteSSKInserts();\n\t\tint numLocalCHKRequests = tracker.getNumLocalCHKRequests();\n\t\tint numRemoteCHKRequests = tracker.getNumRemoteCHKRequests();\n\t\tint numLocalSSKRequests = tracker.getNumLocalSSKRequests();\n\t\tint numRemoteSSKRequests = tracker.getNumRemoteSSKRequests();\n\t\tint numTransferringRequests = tracker.getNumTransferringRequestSenders();\n\t\tint numTransferringRequestHandlers = tracker.getNumTransferringRequestHandlers();\n\t\tint numCHKOfferReplys = tracker.getNumCHKOfferReplies();\n\t\tint numSSKOfferReplys = tracker.getNumSSKOfferReplies();\n\t\tint numCHKRequests = numLocalCHKRequests + numRemoteCHKRequests;\n\t\tint numSSKRequests = numLocalSSKRequests + numRemoteSSKRequests;\n\t\tint numCHKInserts = numLocalCHKInserts + numRemoteCHKInserts;\n\t\tint numSSKInserts = numLocalSSKInserts + numRemoteSSKInserts;\n\t\tif ((numTransferringRequests == 0) &&\n\t\t\t\t(numCHKRequests == 0) && (numSSKRequests == 0) &&\n\t\t\t\t(numCHKInserts == 0) && (numSSKInserts == 0) &&\n\t\t\t\t(numTransferringRequestHandlers == 0) && \n\t\t\t\t(numCHKOfferReplys == 0) && (numSSKOfferReplys == 0)) {\n\t\t\ttextBuilder.append(l10n(\"noRequests\")).append(\"\\n\");\n\t\t} else {\n\t\t\tif (numCHKInserts > 0 || numSSKInserts > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"activityInserts\",\n\t\t\t\t\t\tnew String[] { \"CHKhandlers\", \"SSKhandlers\", \"local\" } ,\n\t\t\t\t\t\tnew String[] { Integer.toString(numCHKInserts), Integer.toString(numSSKInserts), Integer.toString(numLocalCHKInserts)+\"/\" + Integer.toString(numLocalSSKInserts)})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numCHKRequests > 0 || numSSKRequests > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"activityRequests\",\n\t\t\t\t\t\tnew String[] { \"CHKhandlers\", \"SSKhandlers\", \"local\" } ,\n\t\t\t\t\t\tnew String[] { Integer.toString(numCHKRequests), Integer.toString(numSSKRequests), Integer.toString(numLocalCHKRequests)+\"/\" + Integer.toString(numLocalSSKRequests)})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numTransferringRequests > 0 || numTransferringRequestHandlers > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"transferringRequests\",\n\t\t\t\t\t\tnew String[] { \"senders\", \"receivers\", \"turtles\" }, new String[] { Integer.toString(numTransferringRequests), Integer.toString(numTransferringRequestHandlers), \"0\"})\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\tif (numCHKOfferReplys > 0 || numSSKOfferReplys > 0) {\n\t\t\t\ttextBuilder.append(l10n(\"offerReplys\",\n\t\t\t\t\t\tnew String[] { \"chk\", \"ssk\" }, new String[] { Integer.toString(numCHKOfferReplys), Integer.toString(numSSKOfferReplys) })\n\t\t\t\t\t\t+ \"\\n\");\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(\"runningBlockTransfers\",\n\t\t\t\t\tnew String[] { \"sends\", \"receives\" }, new String[] { Integer.toString(BlockTransmitter.getRunningSends()), Integer.toString(BlockReceiver.getRunningReceives()) })\n\t\t\t\t\t+ \"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawPeerStatsBox\n\t\ttextBuilder.append(\"Peer Statistics:\\n\");\n\t\tPeerNodeStatus[] peerNodeStatuses = peers.getPeerNodeStatuses(true);\n\t\tArrays.sort(peerNodeStatuses, new Comparator<PeerNodeStatus>() {\n\t\t\t@Override\n\t\t\tpublic int compare(PeerNodeStatus firstNode, PeerNodeStatus secondNode) {\n\t\t\t\tint statusDifference = firstNode.getStatusValue() - secondNode.getStatusValue();\n\t\t\t\tif (statusDifference != 0) {\n\t\t\t\t\treturn statusDifference;\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t});\n\t\tint numberOfConnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CONNECTED);\n\t\tint numberOfRoutingBackedOff = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_ROUTING_BACKED_OFF);\n\t\tint numberOfTooNew = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_TOO_NEW);\n\t\tint numberOfTooOld = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_TOO_OLD);\n\t\tint numberOfDisconnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISCONNECTED);\n\t\tint numberOfNeverConnected = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_NEVER_CONNECTED);\n\t\tint numberOfDisabled = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISABLED);\n\t\tint numberOfBursting = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_BURSTING);\n\t\tint numberOfListening = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_LISTENING);\n\t\tint numberOfListenOnly = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_LISTEN_ONLY);\n\t\tint numberOfSeedServers = getCountSeedServers(peerNodeStatuses);\n\t\tint numberOfSeedClients = getCountSeedClients(peerNodeStatuses);\n\t\tint numberOfRoutingDisabled = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_ROUTING_DISABLED);\n\t\tint numberOfClockProblem = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CLOCK_PROBLEM);\n\t\tint numberOfConnError = getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_CONN_ERROR);\n\t\tint numberOfDisconnecting = PeerNodeStatus.getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_DISCONNECTING);\n\t\tint numberOfNoLoadStats = PeerNodeStatus.getPeerStatusCount(peerNodeStatuses, PeerManager.PEER_NODE_STATUS_NO_LOAD_STATS);\n\t\tif (numberOfConnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"connectedShort\")).append(\": \").append(numberOfConnected).append(\"\\n\");\n\t\tif (numberOfRoutingBackedOff > 0)\n\t\t\ttextBuilder.append(l10nDark(\"backedOffShort\")).append(\": \").append(numberOfRoutingBackedOff).append(\"\\n\");\n\t\tif (numberOfTooNew > 0)\n\t\t\ttextBuilder.append(l10nDark(\"tooNewShort\")).append(\": \").append(numberOfTooNew).append(\"\\n\");\n\t\tif (numberOfTooOld > 0)\n\t\t\ttextBuilder.append(l10nDark(\"tooOldShort\")).append(\": \").append(numberOfTooOld).append(\"\\n\");\n\t\tif (numberOfDisconnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"notConnectedShort\")).append(\": \").append(numberOfDisconnected).append(\"\\n\");\n\t\tif (numberOfNeverConnected > 0)\n\t\t\ttextBuilder.append(l10nDark(\"neverConnectedShort\")).append(\": \").append(numberOfNeverConnected).append(\"\\n\");\n\t\tif (numberOfDisabled > 0)\n\t\t\ttextBuilder.append(l10nDark(\"disabledShort\")).append(\": \").append(numberOfDisabled).append(\"\\n\");\n\t\tif (numberOfBursting > 0)\n\t\t\ttextBuilder.append(l10nDark(\"burstingShort\")).append(\": \").append(numberOfBursting).append(\"\\n\");\n\t\tif (numberOfListening > 0)\n\t\t\ttextBuilder.append(l10nDark(\"listeningShort\")).append(\": \").append(numberOfListening).append(\"\\n\");\n\t\tif (numberOfListenOnly > 0)\n\t\t\ttextBuilder.append(l10nDark(\"listenOnlyShort\")).append(\": \").append(numberOfListenOnly).append(\"\\n\");\n\t\tif (numberOfClockProblem > 0)\n\t\t\ttextBuilder.append(l10nDark(\"clockProblemShort\")).append(\": \").append(numberOfClockProblem).append(\"\\n\");\n\t\tif (numberOfConnError > 0)\n\t\t\ttextBuilder.append(l10nDark(\"connErrorShort\")).append(\": \").append(numberOfConnError).append(\"\\n\");\n\t\tif (numberOfDisconnecting > 0)\n\t\t\ttextBuilder.append(l10nDark(\"disconnectingShort\")).append(\": \").append(numberOfDisconnecting).append(\"\\n\");\n\t\tif (numberOfSeedServers > 0)\n\t\t\ttextBuilder.append(l10nDark(\"seedServersShort\")).append(\": \").append(numberOfSeedServers).append(\"\\n\");\n\t\tif (numberOfSeedClients > 0)\n\t\t\ttextBuilder.append(l10nDark(\"seedClientsShort\")).append(\": \").append(numberOfSeedClients).append(\"\\n\");\n\t\tif (numberOfRoutingDisabled > 0)\n\t\t\ttextBuilder.append(l10nDark(\"routingDisabledShort\")).append(\": \").append(numberOfRoutingDisabled).append(\"\\n\");\n\t\tif (numberOfNoLoadStats > 0)\n\t\t\ttextBuilder.append(l10nDark(\"noLoadStatsShort\")).append(\": \").append(numberOfNoLoadStats).append(\"\\n\");\n\t\tOpennetManager om = node.getOpennet();\n\t\tif(om != null) {\n\t\t\ttextBuilder.append(l10n(\"maxTotalPeers\")+\": \"+om.getNumberOfConnectedPeersToAimIncludingDarknet()).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"maxOpennetPeers\")+\": \"+om.getNumberOfConnectedPeersToAim()).append(\"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawBandwidth\n\t\ttextBuilder.append(\"Bandwidth:\\n\");\n\t\tlong[] total = node.collector.getTotalIO();\n\t\tif(total[0] == 0 || total[1] == 0)\n\t\t\ttextBuilder.append(\"bandwidth error\\n\");\n\t\telse  {\n\t\t\tfinal long now = System.currentTimeMillis();\n\t\t\tfinal long nodeUptimeSeconds = (now - node.startupTime) / 1000;\n\t\t\tlong total_output_rate = (total[0]) / nodeUptimeSeconds;\n\t\t\tlong total_input_rate = (total[1]) / nodeUptimeSeconds;\n\t\t\tlong totalPayload = node.getTotalPayloadSent();\n\t\t\tlong total_payload_rate = totalPayload / nodeUptimeSeconds;\n\t\t\tif(node.clientCore == null) throw new NullPointerException();\n\t\t\tBandwidthStatsContainer stats = node.clientCore.bandwidthStatsPutter.getLatestBWData();\n\t\t\tif(stats == null) throw new NullPointerException();\n\t\t\tlong overall_total_out = stats.totalBytesOut;\n\t\t\tlong overall_total_in = stats.totalBytesIn;\n\t\t\tint percent = (int) (100 * totalPayload / total[0]);\n\t\t\tlong[] rate = node.nodeStats.getNodeIOStats();\n\t\t\tlong delta = (rate[5] - rate[2]) / 1000;\n\t\t\tif(delta > 0) {\n\t\t\t\tlong output_rate = (rate[3] - rate[0]) / delta;\n\t\t\t\tlong input_rate = (rate[4] - rate[1]) / delta;\n\t\t\t\tint outputBandwidthLimit = nodeConfig.getInt(\"outputBandwidthLimit\");\n\t\t\t\tint inputBandwidthLimit = nodeConfig.getInt(\"inputBandwidthLimit\");\n\t\t\t\tif(inputBandwidthLimit == -1) {\n\t\t\t\t\tinputBandwidthLimit = outputBandwidthLimit * 4;\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(l10n(\"inputRate\", new String[] { \"rate\", \"max\" }, new String[] { SizeUtil.formatSize(input_rate, true), SizeUtil.formatSize(inputBandwidthLimit, true) })).append(\"\\n\");\n\t\t\t\ttextBuilder.append(l10n(\"outputRate\", new String[] { \"rate\", \"max\" }, new String[] { SizeUtil.formatSize(output_rate, true), SizeUtil.formatSize(outputBandwidthLimit, true) })).append(\"\\n\");\n\t\t\t}\n\t\t\ttextBuilder.append(l10n(\"totalInputSession\", new String[] { \"total\", \"rate\" }, new String[] { SizeUtil.formatSize(total[1], true), SizeUtil.formatSize(total_input_rate, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalOutputSession\", new String[] { \"total\", \"rate\" }, new String[] { SizeUtil.formatSize(total[0], true), SizeUtil.formatSize(total_output_rate, true) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"payloadOutput\", new String[] { \"total\", \"rate\", \"percent\" }, new String[] { SizeUtil.formatSize(totalPayload, true), SizeUtil.formatSize(total_payload_rate, true), Integer.toString(percent) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalInput\", new String[] { \"total\" }, new String[] { SizeUtil.formatSize(overall_total_in, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"totalOutput\", new String[] { \"total\" }, new String[] { SizeUtil.formatSize(overall_total_out, true) } )).append(\"\\n\");\n\t\t\tlong totalBytesSentCHKRequests = node.nodeStats.getCHKRequestTotalBytesSent();\n\t\t\tlong totalBytesSentSSKRequests = node.nodeStats.getSSKRequestTotalBytesSent();\n\t\t\tlong totalBytesSentCHKInserts = node.nodeStats.getCHKInsertTotalBytesSent();\n\t\t\tlong totalBytesSentSSKInserts = node.nodeStats.getSSKInsertTotalBytesSent();\n\t\t\tlong totalBytesSentOfferedKeys = node.nodeStats.getOfferedKeysTotalBytesSent();\n\t\t\tlong totalBytesSendOffers = node.nodeStats.getOffersSentBytesSent();\n\t\t\tlong totalBytesSentSwapOutput = node.nodeStats.getSwappingTotalBytesSent();\n\t\t\tlong totalBytesSentAuth = node.nodeStats.getTotalAuthBytesSent();\n\t\t\tlong totalBytesSentAckOnly = node.nodeStats.getNotificationOnlyPacketsSentBytes();\n\t\t\tlong totalBytesSentResends = node.nodeStats.getResendBytesSent();\n\t\t\tlong totalBytesSentUOM = node.nodeStats.getUOMBytesSent();\n\t\t\tlong totalBytesSentAnnounce = node.nodeStats.getAnnounceBytesSent();\n\t\t\tlong totalBytesSentAnnouncePayload = node.nodeStats.getAnnounceBytesPayloadSent();\n\t\t\tlong totalBytesSentRoutingStatus = node.nodeStats.getRoutingStatusBytes();\n\t\t\tlong totalBytesSentNetworkColoring = node.nodeStats.getNetworkColoringSentBytes();\n\t\t\tlong totalBytesSentPing = node.nodeStats.getPingSentBytes();\n\t\t\tlong totalBytesSentProbeRequest = node.nodeStats.getProbeRequestSentBytes();\n\t\t\tlong totalBytesSentRouted = node.nodeStats.getRoutedMessageSentBytes();\n\t\t\tlong totalBytesSentDisconn = node.nodeStats.getDisconnBytesSent();\n\t\t\tlong totalBytesSentInitial = node.nodeStats.getInitialMessagesBytesSent();\n\t\t\tlong totalBytesSentChangedIP = node.nodeStats.getChangedIPBytesSent();\n\t\t\tlong totalBytesSentNodeToNode = node.nodeStats.getNodeToNodeBytesSent();\n\t\t\tlong totalBytesSentAllocationNotices = node.nodeStats.getAllocationNoticesBytesSent();\n\t\t\tlong totalBytesSentFOAF = node.nodeStats.getFOAFBytesSent();\n\t\t\tlong totalBytesSentRemaining = total[0] - \n\t\t\t\t(totalPayload + totalBytesSentCHKRequests + totalBytesSentSSKRequests +\n\t\t\t\ttotalBytesSentCHKInserts + totalBytesSentSSKInserts +\n\t\t\t\ttotalBytesSentOfferedKeys + totalBytesSendOffers + totalBytesSentSwapOutput + \n\t\t\t\ttotalBytesSentAuth + totalBytesSentAckOnly + totalBytesSentResends +\n\t\t\t\ttotalBytesSentUOM + totalBytesSentAnnounce + \n\t\t\t\ttotalBytesSentRoutingStatus + totalBytesSentNetworkColoring + totalBytesSentPing +\n\t\t\t\ttotalBytesSentProbeRequest + totalBytesSentRouted + totalBytesSentDisconn + \n\t\t\t\ttotalBytesSentInitial + totalBytesSentChangedIP + totalBytesSentNodeToNode + totalBytesSentAllocationNotices + totalBytesSentFOAF);\n\t\t\ttextBuilder.append(l10n(\"requestOutput\", new String[] { \"chk\", \"ssk\" }, new String[] { SizeUtil.formatSize(totalBytesSentCHKRequests, true), SizeUtil.formatSize(totalBytesSentSSKRequests, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"insertOutput\", new String[] { \"chk\", \"ssk\" }, new String[] { SizeUtil.formatSize(totalBytesSentCHKInserts, true), SizeUtil.formatSize(totalBytesSentSSKInserts, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"offeredKeyOutput\", new String[] { \"total\", \"offered\" }, new String[] { SizeUtil.formatSize(totalBytesSentOfferedKeys, true), SizeUtil.formatSize(totalBytesSendOffers, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"swapOutput\", \"total\", SizeUtil.formatSize(totalBytesSentSwapOutput, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"authBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAuth, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"ackOnlyBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAckOnly, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"resendBytes\", new String[] { \"total\", \"percent\" }, new String[] { SizeUtil.formatSize(totalBytesSentResends, true), Long.toString((100 * totalBytesSentResends) / Math.max(1, total[0])) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"uomBytes\", \"total\",  SizeUtil.formatSize(totalBytesSentUOM, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"announceBytes\", new String[] { \"total\", \"payload\" }, new String[] { SizeUtil.formatSize(totalBytesSentAnnounce, true), SizeUtil.formatSize(totalBytesSentAnnouncePayload, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"adminBytes\", new String[] { \"routingStatus\", \"disconn\", \"initial\", \"changedIP\" }, new String[] { SizeUtil.formatSize(totalBytesSentRoutingStatus, true), SizeUtil.formatSize(totalBytesSentDisconn, true), SizeUtil.formatSize(totalBytesSentInitial, true), SizeUtil.formatSize(totalBytesSentChangedIP, true) })).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"debuggingBytes\", new String[] { \"netColoring\", \"ping\", \"probe\", \"routed\" }, new String[] { SizeUtil.formatSize(totalBytesSentNetworkColoring, true), SizeUtil.formatSize(totalBytesSentPing, true), SizeUtil.formatSize(totalBytesSentProbeRequest, true), SizeUtil.formatSize(totalBytesSentRouted, true) } )).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"nodeToNodeBytes\", \"total\", SizeUtil.formatSize(totalBytesSentNodeToNode, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"loadAllocationNoticesBytes\", \"total\", SizeUtil.formatSize(totalBytesSentAllocationNotices, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"foafBytes\", \"total\", SizeUtil.formatSize(totalBytesSentFOAF, true))).append(\"\\n\");\n\t\t\ttextBuilder.append(l10n(\"unaccountedBytes\", new String[] { \"total\", \"percent\" },\n\t\t\t\t\tnew String[] { SizeUtil.formatSize(totalBytesSentRemaining, true), Integer.toString((int)(totalBytesSentRemaining*100 / total[0])) })).append(\"\\n\");\n\t\t\tdouble sentOverheadPerSecond = node.nodeStats.getSentOverheadPerSecond();\n\t\t\ttextBuilder.append(l10n(\"totalOverhead\", new String[] { \"rate\", \"percent\" },\n\t\t\t\t\tnew String[] { SizeUtil.formatSize((long)sentOverheadPerSecond), Integer.toString((int)((100 * sentOverheadPerSecond) / total_output_rate)) })).append(\"\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// showStartingPlugins\n\t\ttextBuilder.append(\"Plugins:\\n\");\n\t\tPluginManager pm = node.pluginManager;\n\t\tif (!pm.getPlugins().isEmpty()) {\n\t\t\ttextBuilder.append(baseL10n.getString(\"PluginToadlet.pluginListTitle\")).append(\"\\n\");\n\t\t\tfor(PluginInfoWrapper pi: pm.getPlugins()) {\n\t\t\t\tlong ver = pi.getPluginLongVersion();\n\t\t\t\tif (ver != -1)\n\t\t\t\t\ttextBuilder.append(pi.getFilename()).append(\" (\").append(pi.getPluginClassName()).append(\") - \" ).append(pi.getPluginVersion()+ \" (\"+ver+\")\").append(\" \").append(pi.getThreadName()).append(\"\\n\");\n\t\t\t\telse\n\t\t\t\t\ttextBuilder.append(pi.getFilename()).append(\" (\").append(pi.getPluginClassName()).append(\") - \").append(pi.getPluginVersion()).append(\" \").append(pi.getThreadName()).append(\"\\n\");\n\t\t\t}\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// handleGetInner\n\t\ttextBuilder.append(\"Queue:\\n\");\n\t\ttry {\n\t\t\tRequestStatus[] reqs = fcp.getGlobalRequests();\n\t\t\tif(reqs.length < 1)\n\t\t\t\ttextBuilder.append(baseL10n.getString(\"QueueToadlet.globalQueueIsEmpty\")).append(\"\\n\");\n\t\t\telse {\n\t\t\t\tlong totalQueuedDownload = 0;\n\t\t\t\tlong totalQueuedUpload = 0;\n\t\t\t\tfor(RequestStatus req: reqs) {\n\t\t\t\t\tif(req instanceof DownloadRequestStatus) {\n\t\t\t\t\t\ttotalQueuedDownload++;\n\t\t\t\t\t} else if(req instanceof UploadFileRequestStatus) {\n\t\t\t\t\t\ttotalQueuedUpload++;\n\t\t\t\t\t} else if(req instanceof UploadDirRequestStatus) {\n\t\t\t\t\t\ttotalQueuedUpload++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttextBuilder.append(\"Downloads Queued: \").append(totalQueuedDownload).append(\" (\").append(totalQueuedDownload).append(\")\\n\");\n\t\t\t\ttextBuilder.append(\"Uploads Queued: \").append(totalQueuedUpload).append(\" (\").append(totalQueuedUpload).append(\")\\n\");\n\t\t\t}\n\t\t} catch (PersistenceDisabledException e) {\n\t\t\ttextBuilder.append(\"DatabaseDisabledException\\n\");\n\t\t}\n\t\ttextBuilder.append(\"\\n\");\n\n\t\t// drawThreadPriorityStatsBox\n\t\ttextBuilder.append(threadsStats());\n\n\t\ttextBuilder.append(\"\\n\");\n\t\t}\n\n\t\tthis.writeTextReply(ctx, 200, \"OK\", textBuilder.toString());\n\t}\n\n\tprivate StringBuilder threadsStats() {\n\t\tStringBuilder sb = new StringBuilder();\n\n\t\tThreadDiagnostics threadDiagnostics = node\n\t\t\t.getNodeDiagnostics()\n\t\t\t.getThreadDiagnostics();\n\n\t\tNodeThreadSnapshot threadSnapshot = threadDiagnostics.getThreadSnapshot();\n\t\tdouble totalCpuTime = threadSnapshot.getTotalCpuTime();\n\n\t\tList<NodeThreadInfo> threads = threadSnapshot.getThreads();\n\t\tthreads.sort(Comparator.comparing(NodeThreadInfo::getCpuTime).reversed());\n\n\t\tsb.append(String.format(\"Threads (%d):%n\", threads.size()));\n\n\t\t// ID, Name, Priority, Group (system, main), Status, % CPU\n\t\tsb.append(\n\t\t\tString.format(\n\t\t\t\t\"%5s %-60s %5s %10s %-20s %-5s%n\",\n\t\t\t\t\"ID\",\n\t\t\t\t\"Name\",\n\t\t\t\t\"Prio.\",\n\t\t\t\t\"Group\",\n\t\t\t\t\"Status\",\n\t\t\t\t\"% CPU\"\n\t\t\t)\n\t\t);\n\n\t\tfor (NodeThreadInfo thread : threads) {\n\t\t\tString line = String.format(\n\t\t\t\t\"%5s %-60s %5s %10s %-20s %.2f%n\",\n\t\t\t\tthread.getId(),\n\t\t\t\tthread.getName().substring(0, Math.min(60, thread.getName().length())),\n\t\t\t\tthread.getPrio(),\n\t\t\t\tthread.getGroupName().substring(0, Math.min(10, thread.getGroupName().length())),\n\t\t\t\tthread.getState(),\n\t\t\t\tthread.getCpuTime() / totalCpuTime * 100\n\t\t\t);\n\t\t\tsb.append(line);\n\t\t}\n\n\t\treturn sb;\n\t}\n\n\tprivate int getPeerStatusCount(PeerNodeStatus[] peerNodeStatuses, int status) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(!peerNodeStatus.recordStatus())\n\t\t\t\tcontinue;\n\t\t\tif (peerNodeStatus.getStatusValue() == status) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}\n\t\n\tprivate int getCountSeedServers(PeerNodeStatus[] peerNodeStatuses) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(peerNodeStatus.isSeedServer()) count++;\n\t\t}\n\t\treturn count;\n\t}\n\n\tprivate int getCountSeedClients(PeerNodeStatus[] peerNodeStatuses) {\n\t\tint count = 0;\n\t\tfor (PeerNodeStatus peerNodeStatus: peerNodeStatuses) {\n\t\t\tif(peerNodeStatus.isSeedClient()) count++;\n\t\t}\n\t\treturn count;\n\t}\n\n\tprivate String l10n(String key) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key);\n\t}\n\n\tprivate String l10nDark(String key) {\n\t\treturn baseL10n.getString(\"DarknetConnectionsToadlet.\"+key);\n\t}\n\n\tprivate String l10n(String key, String pattern, String value) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key, new String[] { pattern }, new String[] { value });\n\t}\n\n\tprivate String l10n(String key, String[] patterns, String[] values) {\n\t\treturn baseL10n.getString(\"StatisticsToadlet.\"+key, patterns, values);\n\t}\n\n\t@Override\n\tpublic String path() {\n\t\treturn TOADLET_URL;\n\t}\n}\n","lineNo":430}
{"Smelly Sample":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.node.diagnostics.threads;\n\nimport freenet.node.*;\nimport freenet.node.diagnostics.*;\nimport freenet.support.*;\n\nimport java.lang.management.*;\nimport java.util.*;\nimport java.util.concurrent.atomic.*;\nimport java.util.stream.*;\n\n/**\n * Runnable thread to retrieve node thread's information and compiling it into\n * an array of NodeThreadInfo objects.\n */\npublic class DefaultThreadDiagnostics implements Runnable, ThreadDiagnostics {\n    private final String name;\n    private final int monitorInterval;\n\n    private final NodeStats nodeStats;\n    private final Ticker ticker;\n\n    /** Sleep interval to calculate % CPU used by each thread */\n    private static final int MONITOR_INTERVAL = 1000;\n    private static final String MONITOR_THREAD_NAME = \"NodeDiagnostics: thread monitor\";\n\n    private final AtomicReference<List<NodeThreadInfo>> nodeThreadInfo = new AtomicReference<>(new ArrayList<>());\n\n    private final ThreadMXBean threadMxBean               = ManagementFactory.getThreadMXBean();\n\n    /**\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     * @param name Thread name\n     * @param monitorInterval Sleep intervals to retrieve CPU usage\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker, String name, int monitorInterval) {\n        this.nodeStats = nodeStats;\n        this.ticker = ticker;\n        this.name = name;\n        this.monitorInterval = monitorInterval;\n    }\n\n    /*\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker) {\n        this(nodeStats, ticker, MONITOR_THREAD_NAME, MONITOR_INTERVAL);\n    }\n\n    private void scheduleNext(int interval) {\n        ticker.queueTimedJob(\n            this,\n            name,\n            interval,\n            false,\n            true\n        );\n    }\n\n    public void start() {\n        scheduleNext(0);\n    }\n\n    private void scheduleNext() {\n        scheduleNext(monitorInterval);\n    }\n\n    @Override\n    public void run() {\n        nodeThreadInfo.set(\n            Arrays.stream(nodeStats.getThreads())\n            .filter(Objects::nonNull)\n            .map(thread ->\n                new NodeThreadInfo(\n                    thread.getId(),\n                    thread.getName(),\n                    thread.getPriority(),\n                    thread.getThreadGroup().getName(),\n                    thread.getState().toString(),\n                    threadMxBean.getThreadCpuTime(thread.getId())\n                )\n            )\n            .collect(Collectors.toList())\n        );\n\n        scheduleNext();\n    }\n\n    /**\n     * @return List of Node threads\n     */\n    public List<NodeThreadInfo> getThreads() {\n        return nodeThreadInfo.get();\n    }\n}\n","Method after Refactoring":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.node.diagnostics.threads;\n\nimport freenet.node.*;\nimport freenet.node.diagnostics.*;\nimport freenet.support.*;\n\nimport java.lang.management.*;\nimport java.util.*;\nimport java.util.concurrent.atomic.*;\nimport java.util.stream.*;\n\n/**\n * Runnable thread to retrieve node thread's information and compiling it into\n * an array of NodeThreadInfo objects.\n */\npublic class DefaultThreadDiagnostics implements Runnable, ThreadDiagnostics {\n    private final String name;\n    private final int monitorInterval;\n\n    private final NodeStats nodeStats;\n    private final Ticker ticker;\n\n    /** Sleep interval to calculate % CPU used by each thread */\n    private static final int MONITOR_INTERVAL = 1000;\n    private static final String MONITOR_THREAD_NAME = \"NodeDiagnostics: thread monitor\";\n\n    private final AtomicReference<List<NodeThreadInfo>> nodeThreadInfo = new AtomicReference<>(new ArrayList<>());\n\n    private final ThreadMXBean threadMxBean               = ManagementFactory.getThreadMXBean();\n\n    /**\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     * @param name Thread name\n     * @param monitorInterval Sleep intervals to retrieve CPU usage\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker, String name, int monitorInterval) {\n        this.nodeStats = nodeStats;\n        this.ticker = ticker;\n        this.name = name;\n        this.monitorInterval = monitorInterval;\n    }\n\n    /*\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker) {\n        this(nodeStats, ticker, MONITOR_THREAD_NAME, MONITOR_INTERVAL);\n    }\n\n    private void scheduleNext(int interval) {\n        ticker.queueTimedJob(\n            this,\n            name,\n            interval,\n            false,\n            true\n        );\n    }\n\n    public void start() {\n        scheduleNext(0);\n    }\n\n    private void scheduleNext() {\n        scheduleNext(monitorInterval);\n    }\n\n    @Override\n    public void run() {\n        List<NodeThreadInfo> threads = Arrays.stream(nodeStats.getThreads())\n            .filter(Objects::nonNull)\n            .map(thread ->\n                new NodeThreadInfo(\n                    thread.getId(),\n                    thread.getName(),\n                    thread.getPriority(),\n                    thread.getThreadGroup().getName(),\n                    thread.getState().toString(),\n                    threadMxBean.getThreadCpuTime(thread.getId())\n                )\n            )\n            .collect(Collectors.toList());\n\n        nodeThreadInfo.set(threads);\n\n        scheduleNext();\n    }\n\n    /**\n     * @return List of Node threads\n     */\n    public List<NodeThreadInfo> getThreads() {\n        return nodeThreadInfo.get();\n    }\n}\n","lineNo":75}
{"Smelly Sample":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.node.diagnostics.threads;\n\nimport freenet.node.*;\nimport freenet.node.diagnostics.*;\nimport freenet.support.*;\n\nimport java.lang.management.*;\nimport java.util.*;\nimport java.util.concurrent.atomic.*;\n\n/**\n * Runnable thread to retrieve node thread's information and compiling it into\n * an array of NodeThreadInfo objects.\n */\npublic class DefaultThreadDiagnostics implements Runnable, ThreadDiagnostics {\n    private final String name;\n    private final int monitorInterval;\n\n    private final NodeStats nodeStats;\n    private final Ticker ticker;\n\n    /** Sleep interval to calculate % CPU used by each thread */\n    private static final int MONITOR_INTERVAL = 1000;\n    private static final String MONITOR_THREAD_NAME = \"NodeDiagnostics: thread monitor\";\n\n    private final AtomicReference<List<NodeThreadInfo>> nodeThreadInfo = new AtomicReference<>(new ArrayList<>());\n\n    private final OperatingSystemMXBean operatingSystemMXBean = ManagementFactory.getOperatingSystemMXBean();\n    private final ThreadMXBean threadMxBean               = ManagementFactory.getThreadMXBean();\n    private final RuntimeMXBean runtimeMxBean             = ManagementFactory.getRuntimeMXBean();\n\n    /**\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     * @param name Thread name\n     * @param monitorInterval Sleep intervals to retrieve CPU usage\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker, String name, int monitorInterval) {\n        this.nodeStats = nodeStats;\n        this.ticker = ticker;\n        this.name = name;\n        this.monitorInterval = monitorInterval;\n    }\n\n    /*\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker) {\n        this(nodeStats, ticker, MONITOR_THREAD_NAME, MONITOR_INTERVAL);\n    }\n\n    private void scheduleNext(int interval) {\n        ticker.queueTimedJob(\n            this,\n            name,\n            interval,\n            false,\n            true\n        );\n    }\n\n    public void start() {\n        scheduleNext(0);\n    }\n\n    private void scheduleNext() {\n        scheduleNext(monitorInterval);\n    }\n\n    /** Map<ThreadId, ThreadCpuTimeNs> */\n    private final Map<Long, Long> threadCPU = new HashMap<>();\n    private long initialUptime = -1;\n\n    @Override\n    public void run() {\n        if (initialUptime == -1) {\n            initialUptime = runtimeMxBean.getUptime();\n\n            for (ThreadInfo info : threadMxBean.dumpAllThreads(false, false)) {\n                threadCPU.put(\n                    info.getThreadId(),\n                    threadMxBean.getThreadCpuTime(\n                        info.getThreadId()\n                    )\n                );\n            }\n\n            scheduleNext();\n            return;\n        }\n\n        for (ThreadInfo info : threadMxBean.dumpAllThreads(false, false)) {\n            Long prev = threadCPU.get(info.getThreadId());\n            if (prev == null) {\n                continue;\n            }\n\n            threadCPU.put(\n                info.getThreadId(),\n                threadMxBean.getThreadCpuTime(info.getThreadId()) - prev\n            );\n        }\n\n        nodeThreadInfo.set(buildThreadList());\n\n        initialUptime = -1;\n        threadCPU.clear();\n\n        scheduleNext();\n    }\n\n    /**\n     * @return List of NodeThreadInfo\n     */\n    private List<NodeThreadInfo> buildThreadList() {\n        List<NodeThreadInfo> threads = new ArrayList<>();\n        double elapsedUptime = runtimeMxBean.getUptime() - initialUptime;\n        double totalElapsedUptime = elapsedUptime * operatingSystemMXBean.getAvailableProcessors();\n\n        for (Thread thread : nodeStats.getThreads()) {\n            if (thread == null) {\n                continue;\n            }\n\n            double cpuUsage = (threadCPU.getOrDefault(thread.getId(), 0L) / 1000000d) / totalElapsedUptime * 100;\n            NodeThreadInfo nodeThreadInfo = new NodeThreadInfo(\n                thread.getId(),\n                thread.getName(),\n                thread.getPriority(),\n                thread.getThreadGroup().getName(),\n                thread.getState().toString(),\n                cpuUsage\n            );\n\n            threads.add(nodeThreadInfo);\n        }\n\n        return threads;\n    }\n\n    /**\n     * @return List of Node threads\n     */\n    public List<NodeThreadInfo> getThreads() {\n        return nodeThreadInfo.get();\n    }\n}\n","Method after Refactoring":"/* This code is part of Freenet. It is distributed under the GNU General\n * Public License, version 2 (or at your option any later version). See\n * http://www.gnu.org/ for further details of the GPL. */\npackage freenet.node.diagnostics.threads;\n\nimport freenet.node.*;\nimport freenet.node.diagnostics.*;\nimport freenet.support.*;\n\nimport java.lang.management.*;\nimport java.util.*;\nimport java.util.concurrent.atomic.*;\n\n/**\n * Runnable thread to retrieve node thread's information and compiling it into\n * an array of NodeThreadInfo objects.\n */\npublic class DefaultThreadDiagnostics implements Runnable, ThreadDiagnostics {\n    private final String name;\n    private final int monitorInterval;\n\n    private final NodeStats nodeStats;\n    private final Ticker ticker;\n\n    /** Sleep interval to calculate % CPU used by each thread */\n    private static final int MONITOR_INTERVAL = 1000;\n    private static final String MONITOR_THREAD_NAME = \"NodeDiagnostics: thread monitor\";\n\n    private final AtomicReference<List<NodeThreadInfo>> nodeThreadInfo = new AtomicReference<>(new ArrayList<>());\n\n    private final OperatingSystemMXBean operatingSystemMXBean = ManagementFactory.getOperatingSystemMXBean();\n    private final ThreadMXBean threadMxBean               = ManagementFactory.getThreadMXBean();\n    private final RuntimeMXBean runtimeMxBean             = ManagementFactory.getRuntimeMXBean();\n\n    /**\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     * @param name Thread name\n     * @param monitorInterval Sleep intervals to retrieve CPU usage\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker, String name, int monitorInterval) {\n        this.nodeStats = nodeStats;\n        this.ticker = ticker;\n        this.name = name;\n        this.monitorInterval = monitorInterval;\n    }\n\n    /*\n     * @param nodeStats Used to retrieve data points\n     * @param ticker Used to queue timed jobs\n     */\n    public DefaultThreadDiagnostics(NodeStats nodeStats, Ticker ticker) {\n        this(nodeStats, ticker, MONITOR_THREAD_NAME, MONITOR_INTERVAL);\n    }\n\n    private void scheduleNext(int interval) {\n        ticker.queueTimedJob(\n            this,\n            name,\n            interval,\n            false,\n            true\n        );\n    }\n\n    public void start() {\n        scheduleNext(0);\n    }\n\n    private void scheduleNext() {\n        scheduleNext(monitorInterval);\n    }\n\n    private final AtomicReference<Map<Long, Long>> threadCPU = new AtomicReference<>(new HashMap<>());\n    private long lastCycle = -1;\n\n    @Override\n    public void run() {\n        Map<Long, Long> delta = new HashMap<>(threadCPU.get());\n        Map<Long, Long> threads = new HashMap<>();\n        for (ThreadInfo info : threadMxBean.dumpAllThreads(false, false)) {\n            long threadId = info.getThreadId();\n            long cpuTime = threadMxBean.getThreadCpuTime(threadId);\n\n            delta.put(threadId, cpuTime - delta.getOrDefault(threadId, 0L));\n            threads.put(threadId, cpuTime);\n        }\n\n        threadCPU.set(threads);\n        nodeThreadInfo.set(buildThreadList(delta));\n        lastCycle = runtimeMxBean.getUptime();\n\n        scheduleNext();\n    }\n\n    /**\n     * @return List of NodeThreadInfo\n     */\n    private List<NodeThreadInfo> buildThreadList(Map<Long, Long> delta) {\n        List<NodeThreadInfo> threads = new ArrayList<>();\n        double elapsedUptime = runtimeMxBean.getUptime() - lastCycle;\n        double totalElapsedUptime = elapsedUptime * operatingSystemMXBean.getAvailableProcessors();\n        for (Thread thread : nodeStats.getThreads()) {\n            if (thread == null) {\n                continue;\n            }\n\n            double cpuUsage = (delta.getOrDefault(thread.getId(), 0L) / 1000000d) / totalElapsedUptime * 100;\n            NodeThreadInfo nodeThreadInfo = new NodeThreadInfo(\n                thread.getId(),\n                thread.getName(),\n                thread.getPriority(),\n                thread.getThreadGroup().getName(),\n                thread.getState().toString(),\n                cpuUsage\n            );\n\n            threads.add(nodeThreadInfo);\n        }\n\n        return threads;\n    }\n\n    /**\n     * @return List of Node threads\n     */\n    public List<NodeThreadInfo> getThreads() {\n        return nodeThreadInfo.get();\n    }\n}\n","lineNo":82}
